import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Optional, Tuple
import time
import random
import json
import sqlite3
import uuid
import zipfile
import psutil
import os
import re

# å…¼å®¹æ€§å‡½æ•¸
def rerun_app():
    """å…¼å®¹ä¸åŒ Streamlit ç‰ˆæœ¬çš„é‡æ–°é‹è¡Œå‡½æ•¸"""
    if hasattr(st, 'rerun'):
        st.rerun()
    elif hasattr(st, 'experimental_rerun'):
        st.experimental_rerun()
    else:
        st.stop()

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="Flux AI åœ–åƒç”Ÿæˆå™¨ Pro - Auto Models",
    page_icon="ğŸ¨",
    layout="wide"
)

# API æä¾›å•†é…ç½®
API_PROVIDERS = {
    "OpenAI Compatible": {
        "name": "OpenAI Compatible API",
        "base_url_default": "https://api.openai.com/v1",
        "key_prefix": "sk-",
        "description": "OpenAI å®˜æ–¹æˆ–å…¼å®¹çš„ API æœå‹™",
        "icon": "ğŸ¤–"
    },
    "Navy": {
        "name": "Navy API",
        "base_url_default": "https://api.navy/v1", 
        "key_prefix": "sk-",
        "description": "Navy æä¾›çš„ AI åœ–åƒç”Ÿæˆæœå‹™",
        "icon": "âš“"
    },
    "Hugging Face": {
        "name": "Hugging Face Inference",
        "base_url_default": "https://api-inference.huggingface.co",
        "key_prefix": "hf_",
        "description": "Hugging Face Inference API",
        "icon": "ğŸ¤—"
    },
    "Together AI": {
        "name": "Together AI",
        "base_url_default": "https://api.together.xyz/v1",
        "key_prefix": "",
        "description": "Together AI å¹³å°",
        "icon": "ğŸ¤"
    },
    "Fireworks AI": {
        "name": "Fireworks AI",
        "base_url_default": "https://api.fireworks.ai/inference/v1",
        "key_prefix": "",
        "description": "Fireworks AI å¿«é€Ÿæ¨ç†",
        "icon": "ğŸ†"
    },
    "Custom": {
        "name": "è‡ªå®šç¾© API",
        "base_url_default": "",
        "key_prefix": "",
        "description": "è‡ªå®šç¾©çš„ API ç«¯é»",
        "icon": "ğŸ”§"
    }
}

# åŸºç¤ Flux æ¨¡å‹é…ç½®ï¼ˆæ‰‹å‹•ç¶­è­·çš„æ ¸å¿ƒæ¨¡å‹ï¼‰
BASE_FLUX_MODELS = {
    "flux.1-schnell": {
        "name": "FLUX.1 Schnell",
        "description": "æœ€å¿«çš„ç”Ÿæˆé€Ÿåº¦ï¼Œé–‹æºæ¨¡å‹",
        "icon": "âš¡",
        "type": "å¿«é€Ÿç”Ÿæˆ",
        "test_prompt": "A simple cat sitting on a table",
        "expected_size": "1024x1024",
        "priority": 1,
        "source": "base"
    },
    "flux.1-dev": {
        "name": "FLUX.1 Dev", 
        "description": "é–‹ç™¼ç‰ˆæœ¬ï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡è³ªé‡",
        "icon": "ğŸ”§",
        "type": "é–‹ç™¼ç‰ˆæœ¬",
        "test_prompt": "A beautiful landscape with mountains",
        "expected_size": "1024x1024",
        "priority": 2,
        "source": "base"
    },
    "flux.1.1-pro": {
        "name": "FLUX.1.1 Pro",
        "description": "æ”¹é€²çš„æ——è‰¦æ¨¡å‹ï¼Œæœ€ä½³å“è³ª",
        "icon": "ğŸ‘‘",
        "type": "æ——è‰¦ç‰ˆæœ¬",
        "test_prompt": "Professional portrait of a person in business attire",
        "expected_size": "1024x1024",
        "priority": 3,
        "source": "base"
    },
    "flux.1-kontext-pro": {
        "name": "FLUX.1 Kontext Pro",
        "description": "æ”¯æŒåœ–åƒç·¨è¼¯å’Œä¸Šä¸‹æ–‡ç†è§£",
        "icon": "ğŸ¯",
        "type": "ç·¨è¼¯å°ˆç”¨",
        "test_prompt": "Abstract geometric shapes in vibrant colors",
        "expected_size": "1024x1024",
        "priority": 4,
        "source": "base"
    }
}

# æ¨¡å‹è‡ªå‹•ç™¼ç¾è¦å‰‡
FLUX_MODEL_PATTERNS = {
    # åŸºæœ¬ Flux æ¨¡å‹æ¨¡å¼
    r'flux[\.\-]?1[\.\-]?schnell': {
        "name_template": "FLUX.1 Schnell",
        "icon": "âš¡",
        "type": "å¿«é€Ÿç”Ÿæˆ",
        "priority_base": 100
    },
    r'flux[\.\-]?1[\.\-]?dev': {
        "name_template": "FLUX.1 Dev",
        "icon": "ğŸ”§", 
        "type": "é–‹ç™¼ç‰ˆæœ¬",
        "priority_base": 200
    },
    r'flux[\.\-]?1[\.\-]?pro': {
        "name_template": "FLUX.1 Pro",
        "icon": "ğŸ‘‘",
        "type": "å°ˆæ¥­ç‰ˆæœ¬",
        "priority_base": 300
    },
    r'flux[\.\-]?1[\.\-]?kontext': {
        "name_template": "FLUX.1 Kontext",
        "icon": "ğŸ¯",
        "type": "ä¸Šä¸‹æ–‡ç†è§£",
        "priority_base": 400
    },
    r'flux[\.\-]?2': {
        "name_template": "FLUX.2",
        "icon": "ğŸš€",
        "type": "ä¸‹ä¸€ä»£",
        "priority_base": 500
    },
    # è‡ªå®šç¾©å’Œå¾®èª¿æ¨¡å‹
    r'flux.*krea': {
        "name_template": "FLUX Krea",
        "icon": "ğŸ¨",
        "type": "å‰µæ„å¢å¼·",
        "priority_base": 600
    },
    r'flux.*anime': {
        "name_template": "FLUX Anime",
        "icon": "ğŸŒ¸",
        "type": "å‹•æ¼«é¢¨æ ¼",
        "priority_base": 700
    },
    r'flux.*realism': {
        "name_template": "FLUX Realism",
        "icon": "ğŸ“·",
        "type": "å¯«å¯¦é¢¨æ ¼",
        "priority_base": 800
    },
    r'flux.*art': {
        "name_template": "FLUX Art",
        "icon": "ğŸ–¼ï¸",
        "type": "è—è¡“é¢¨æ ¼",
        "priority_base": 900
    }
}

# æä¾›å•†ç‰¹å®šçš„æ¨¡å‹ç«¯é»
HF_FLUX_ENDPOINTS = [
    "black-forest-labs/FLUX.1-schnell",
    "black-forest-labs/FLUX.1-dev",
    "black-forest-labs/FLUX.1.1-pro",
    "XLabs-AI/flux-RealismLora",
    "Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro",
    "multimodalart/FLUX.1-merged",
]

def auto_discover_flux_models(client, provider: str, api_key: str, base_url: str) -> Dict[str, Dict]:
    """è‡ªå‹•ç™¼ç¾ Flux æ¨¡å‹"""
    discovered_models = {}
    
    try:
        if provider == "Hugging Face":
            # Hugging Face ç‰¹æ®Šè™•ç†
            for endpoint in HF_FLUX_ENDPOINTS:
                model_id = endpoint.split('/')[-1]
                model_info = analyze_model_name(model_id, endpoint)
                model_info['source'] = 'huggingface'
                model_info['endpoint'] = endpoint
                discovered_models[model_id] = model_info
        
        else:
            # OpenAI å…¼å®¹ API
            response = client.models.list()
            
            for model in response.data:
                model_id = model.id.lower()
                
                # æª¢æŸ¥æ˜¯å¦æ˜¯ Flux ç›¸é—œæ¨¡å‹
                if is_flux_model(model_id):
                    model_info = analyze_model_name(model.id)
                    model_info['source'] = 'api_discovery'
                    discovered_models[model.id] = model_info
        
        return discovered_models
    
    except Exception as e:
        st.warning(f"æ¨¡å‹è‡ªå‹•ç™¼ç¾å¤±æ•—: {str(e)}")
        return {}

def is_flux_model(model_name: str) -> bool:
    """æª¢æŸ¥æ¨¡å‹åç¨±æ˜¯å¦ç‚º Flux æ¨¡å‹"""
    model_lower = model_name.lower()
    flux_keywords = ['flux', 'black-forest-labs']
    return any(keyword in model_lower for keyword in flux_keywords)

def analyze_model_name(model_id: str, full_path: str = None) -> Dict:
    """åˆ†ææ¨¡å‹åç¨±ä¸¦ç”Ÿæˆæ¨¡å‹ä¿¡æ¯"""
    model_lower = model_id.lower()
    
    # å˜—è©¦åŒ¹é…å·²çŸ¥æ¨¡å¼
    for pattern, info in FLUX_MODEL_PATTERNS.items():
        if re.search(pattern, model_lower):
            analyzed_info = {
                "name": info["name_template"],
                "icon": info["icon"],
                "type": info["type"],
                "description": f"è‡ªå‹•ç™¼ç¾çš„ {info['name_template']} æ¨¡å‹",
                "test_prompt": "A beautiful scene with detailed elements",
                "expected_size": "1024x1024",
                "priority": info["priority_base"] + hash(model_id) % 100,
                "auto_discovered": True
            }
            
            # å¦‚æœæœ‰å®Œæ•´è·¯å¾‘ï¼Œæå–æ›´å¤šä¿¡æ¯
            if full_path:
                analyzed_info["full_path"] = full_path
                # å˜—è©¦å¾è·¯å¾‘æå–ä½œè€…ä¿¡æ¯
                if '/' in full_path:
                    author = full_path.split('/')[0]
                    analyzed_info["name"] += f" ({author})"
            
            return analyzed_info
    
    # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°æ¨¡å¼ï¼Œå‰µå»ºé€šç”¨ä¿¡æ¯
    return {
        "name": model_id.replace('-', ' ').replace('_', ' ').title(),
        "icon": "ğŸ¤–",
        "type": "è‡ªå‹•ç™¼ç¾",
        "description": f"è‡ªå‹•ç™¼ç¾çš„æ¨¡å‹: {model_id}",
        "test_prompt": "A detailed and beautiful image",
        "expected_size": "1024x1024", 
        "priority": 999,
        "auto_discovered": True,
        "full_path": full_path if full_path else model_id
    }

def merge_models() -> Dict[str, Dict]:
    """åˆä½µåŸºç¤æ¨¡å‹å’Œè‡ªå‹•ç™¼ç¾çš„æ¨¡å‹"""
    # å¾æœƒè©±ç‹€æ…‹ç²å–è‡ªå‹•ç™¼ç¾çš„æ¨¡å‹
    discovered = st.session_state.get('discovered_models', {})
    
    # åˆä½µæ¨¡å‹
    merged_models = BASE_FLUX_MODELS.copy()
    
    for model_id, model_info in discovered.items():
        if model_id not in merged_models:
            merged_models[model_id] = model_info
    
    return merged_models

def show_model_discovery_panel():
    """é¡¯ç¤ºæ¨¡å‹è‡ªå‹•ç™¼ç¾é¢æ¿"""
    st.subheader("ğŸ” æ¨¡å‹è‡ªå‹•ç™¼ç¾")
    
    col_info, col_controls = st.columns([2, 1])
    
    with col_info:
        st.markdown("""
        **è‡ªå‹•ç™¼ç¾åŠŸèƒ½:**
        - ğŸ” æƒæ API ç«¯é»å¯ç”¨æ¨¡å‹
        - ğŸ¤– æ™ºèƒ½è­˜åˆ¥ Flux ç›¸é—œæ¨¡å‹
        - ğŸ“‹ è‡ªå‹•åˆ†é¡å’Œæ¨™è¨»
        - âš¡ å¯¦æ™‚æ›´æ–°æ¨¡å‹åˆ—è¡¨
        """)
        
        # é¡¯ç¤ºç™¼ç¾çµ±è¨ˆ
        if 'discovered_models' in st.session_state:
            total_discovered = len(st.session_state.discovered_models)
            new_models = len([m for m in st.session_state.discovered_models.values() if m.get('auto_discovered')])
            
            col_stat1, col_stat2 = st.columns(2)
            with col_stat1:
                st.metric("ç™¼ç¾æ¨¡å‹", total_discovered)
            with col_stat2:
                st.metric("æ–°å¢æ¨¡å‹", new_models)
    
    with col_controls:
        if st.button("ğŸ” é–‹å§‹è‡ªå‹•ç™¼ç¾", type="primary", use_container_width=True):
            auto_discover_models()
        
        if st.button("ğŸ”„ é‡æ–°ç™¼ç¾", use_container_width=True):
            st.session_state.discovered_models = {}
            auto_discover_models()
        
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ç™¼ç¾", use_container_width=True):
            st.session_state.discovered_models = {}
            st.success("å·²æ¸…é™¤è‡ªå‹•ç™¼ç¾çš„æ¨¡å‹")
            rerun_app()
        
        # è‡ªå‹•ç™¼ç¾è¨­ç½®
        with st.expander("âš™ï¸ ç™¼ç¾è¨­ç½®"):
            auto_test = st.checkbox("ç™¼ç¾å¾Œè‡ªå‹•æ¸¬è©¦", value=True)
            include_experimental = st.checkbox("åŒ…å«å¯¦é©—æ€§æ¨¡å‹", value=False)
            max_models = st.slider("æœ€å¤§ç™¼ç¾æ•¸é‡", 5, 50, 20)

def auto_discover_models():
    """åŸ·è¡Œè‡ªå‹•æ¨¡å‹ç™¼ç¾"""
    if 'api_config' not in st.session_state or not st.session_state.api_config.get('api_key'):
        st.error("âŒ è«‹å…ˆé…ç½® API å¯†é‘°")
        return
    
    config = st.session_state.api_config
    
    with st.spinner("ğŸ” æ­£åœ¨è‡ªå‹•ç™¼ç¾ Flux æ¨¡å‹..."):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # æ­¥é©Ÿ 1: é€£æ¥ API
        status_text.text("ğŸ“¡ é€£æ¥ API æœå‹™...")
        progress_bar.progress(0.2)
        
        if config['provider'] == "Hugging Face":
            client = None
        else:
            client = OpenAI(
                api_key=config['api_key'],
                base_url=config['base_url']
            )
        
        # æ­¥é©Ÿ 2: ç™¼ç¾æ¨¡å‹
        status_text.text("ğŸ” æƒæå¯ç”¨æ¨¡å‹...")
        progress_bar.progress(0.4)
        
        discovered = auto_discover_flux_models(
            client, config['provider'], config['api_key'], config['base_url']
        )
        
        # æ­¥é©Ÿ 3: åˆ†æå’Œåˆ†é¡
        status_text.text("ğŸ¤– åˆ†ææ¨¡å‹ä¿¡æ¯...")
        progress_bar.progress(0.6)
        
        # ä¿å­˜åˆ°æœƒè©±ç‹€æ…‹
        if 'discovered_models' not in st.session_state:
            st.session_state.discovered_models = {}
        
        new_count = 0
        for model_id, model_info in discovered.items():
            if model_id not in st.session_state.discovered_models:
                new_count += 1
            st.session_state.discovered_models[model_id] = model_info
        
        # æ­¥é©Ÿ 4: å®Œæˆ
        status_text.text("âœ… ç™¼ç¾å®Œæˆ")
        progress_bar.progress(1.0)
        
        time.sleep(1)
        progress_bar.empty()
        status_text.empty()
        
        if new_count > 0:
            st.success(f"âœ… ç™¼ç¾ {new_count} å€‹æ–°çš„ Flux æ¨¡å‹ï¼")
        else:
            st.info("â„¹ï¸ æœªç™¼ç¾æ–°çš„ Flux æ¨¡å‹")
        
        # è‡ªå‹•æ¸¬è©¦æ–°ç™¼ç¾çš„æ¨¡å‹ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if new_count > 0:
            if st.checkbox("æ˜¯å¦æ¸¬è©¦æ–°ç™¼ç¾çš„æ¨¡å‹ï¼Ÿ", value=True):
                test_discovered_models(list(discovered.keys())[:5])  # é™åˆ¶æ¸¬è©¦æ•¸é‡

def test_discovered_models(model_ids: List[str]):
    """æ¸¬è©¦è‡ªå‹•ç™¼ç¾çš„æ¨¡å‹"""
    if not model_ids:
        return
    
    config = st.session_state.api_config
    
    if config['provider'] == "Hugging Face":
        client = None
    else:
        client = OpenAI(
            api_key=config['api_key'],
            base_url=config['base_url']
        )
    
    with st.spinner(f"ğŸ§ª æ¸¬è©¦ {len(model_ids)} å€‹æ–°ç™¼ç¾çš„æ¨¡å‹..."):
        test_results = {}
        progress_bar = st.progress(0)
        
        for i, model_id in enumerate(model_ids):
            progress = (i + 1) / len(model_ids)
            progress_bar.progress(progress)
            
            try:
                result = test_model_availability(
                    client, model_id, config['provider'],
                    config['api_key'], config['base_url']
                )
                test_results[model_id] = result
                
                # çŸ­æš«å»¶é²é¿å…éæ–¼é »ç¹çš„è«‹æ±‚
                time.sleep(0.5)
            except Exception as e:
                st.warning(f"æ¸¬è©¦æ¨¡å‹ {model_id} æ™‚å‡ºéŒ¯: {str(e)}")
        
        progress_bar.empty()
        
        # æ›´æ–°æ¸¬è©¦çµæœ
        if 'model_test_results' not in st.session_state:
            st.session_state.model_test_results = {}
        
        st.session_state.model_test_results.update(test_results)
        
        # é¡¯ç¤ºçµæœæ‘˜è¦
        available_count = sum(1 for r in test_results.values() if r.get('available'))
        st.success(f"âœ… æ¸¬è©¦å®Œæˆï¼š{available_count}/{len(test_results)} å€‹æ¨¡å‹å¯ç”¨")

def show_discovered_models_list():
    """é¡¯ç¤ºå·²ç™¼ç¾çš„æ¨¡å‹åˆ—è¡¨"""
    if 'discovered_models' not in st.session_state or not st.session_state.discovered_models:
        st.info("ğŸ” å°šæœªç™¼ç¾ä»»ä½•æ¨¡å‹ï¼Œé»æ“Šã€Œé–‹å§‹è‡ªå‹•ç™¼ç¾ã€ä¾†æƒæå¯ç”¨æ¨¡å‹")
        return
    
    st.subheader("ğŸ“‹ å·²ç™¼ç¾çš„æ¨¡å‹")
    
    # æŒ‰ä¾†æºå’Œå„ªå…ˆç´šæ’åº
    sorted_models = sorted(
        st.session_state.discovered_models.items(),
        key=lambda x: (
            x[1].get('source', 'unknown'),
            x[1].get('priority', 999),
            x[0]
        )
    )
    
    # æŒ‰ä¾†æºåˆ†çµ„é¡¯ç¤º
    sources = {}
    for model_id, model_info in sorted_models:
        source = model_info.get('source', 'unknown')
        if source not in sources:
            sources[source] = []
        sources[source].append((model_id, model_info))
    
    for source, models in sources.items():
        source_names = {
            'base': 'ğŸ  åŸºç¤æ¨¡å‹',
            'api_discovery': 'ğŸ¤– API ç™¼ç¾',
            'huggingface': 'ğŸ¤— Hugging Face',
            'unknown': 'â“ æœªçŸ¥ä¾†æº'
        }
        
        st.markdown(f"### {source_names.get(source, source)}")
        
        for model_id, model_info in models:
            with st.expander(f"{model_info.get('icon', 'ğŸ¤–')} {model_info.get('name', model_id)}"):
                col_info, col_actions = st.columns([2, 1])
                
                with col_info:
                    st.markdown(f"**æ¨¡å‹ ID**: `{model_id}`")
                    st.markdown(f"**æè¿°**: {model_info.get('description', 'N/A')}")
                    st.markdown(f"**é¡å‹**: {model_info.get('type', 'N/A')}")
                    st.markdown(f"**ä¾†æº**: {source}")
                    
                    if model_info.get('full_path'):
                        st.markdown(f"**å®Œæ•´è·¯å¾‘**: `{model_info['full_path']}`")
                    
                    # é¡¯ç¤ºæ¸¬è©¦çµæœ
                    if model_id in st.session_state.get('model_test_results', {}):
                        result = st.session_state.model_test_results[model_id]
                        if result.get('available'):
                            st.success(f"âœ… æ¨¡å‹å¯ç”¨ (éŸ¿æ‡‰æ™‚é–“: {result.get('response_time', 0):.2f}s)")
                        else:
                            st.error(f"âŒ æ¨¡å‹ä¸å¯ç”¨: {result.get('error', 'Unknown error')}")
                
                with col_actions:
                    # æ¸¬è©¦å–®å€‹æ¨¡å‹
                    if st.button(f"ğŸ§ª æ¸¬è©¦", key=f"test_discovered_{model_id}"):
                        test_single_discovered_model(model_id)
                    
                    # ç§»é™¤æ¨¡å‹
                    if st.button(f"ğŸ—‘ï¸ ç§»é™¤", key=f"remove_discovered_{model_id}"):
                        del st.session_state.discovered_models[model_id]
                        st.success(f"å·²ç§»é™¤æ¨¡å‹: {model_id}")
                        rerun_app()
                    
                    # åŠ å…¥æ”¶è—
                    if st.button(f"â­ æ”¶è—", key=f"favorite_discovered_{model_id}"):
                        add_model_to_favorites(model_id, model_info)

def test_single_discovered_model(model_id: str):
    """æ¸¬è©¦å–®å€‹å·²ç™¼ç¾çš„æ¨¡å‹"""
    config = st.session_state.api_config
    
    if config['provider'] == "Hugging Face":
        client = None
    else:
        client = OpenAI(
            api_key=config['api_key'],
            base_url=config['base_url']
        )
    
    with st.spinner(f"ğŸ§ª æ¸¬è©¦æ¨¡å‹ {model_id}..."):
        result = test_model_availability(
            client, model_id, config['provider'],
            config['api_key'], config['base_url']
        )
        
        if 'model_test_results' not in st.session_state:
            st.session_state.model_test_results = {}
        
        st.session_state.model_test_results[model_id] = result
        
        if result.get('available'):
            st.success(f"âœ… æ¨¡å‹ {model_id} æ¸¬è©¦æˆåŠŸï¼")
        else:
            st.error(f"âŒ æ¨¡å‹ {model_id} æ¸¬è©¦å¤±æ•—: {result.get('error')}")
        
        rerun_app()

def add_model_to_favorites(model_id: str, model_info: Dict):
    """å°‡æ¨¡å‹åŠ å…¥æ”¶è—"""
    if 'favorite_models' not in st.session_state:
        st.session_state.favorite_models = []
    
    # æª¢æŸ¥æ˜¯å¦å·²ç¶“æ”¶è—
    if not any(fav['id'] == model_id for fav in st.session_state.favorite_models):
        favorite_item = {
            'id': model_id,
            'info': model_info,
            'added_at': datetime.datetime.now()
        }
        st.session_state.favorite_models.append(favorite_item)
        st.success(f"â­ å·²å°‡ {model_info.get('name', model_id)} åŠ å…¥æ”¶è—")
    else:
        st.info("è©²æ¨¡å‹å·²åœ¨æ”¶è—åˆ—è¡¨ä¸­")

# åŸæœ‰çš„å‡½æ•¸ä¿æŒä¸è®Š...
def validate_api_key(api_key: str, base_url: str, provider: str) -> Tuple[bool, str]:
    """é©—è­‰ API å¯†é‘°æ˜¯å¦æœ‰æ•ˆ"""
    try:
        if provider == "Hugging Face":
            headers = {"Authorization": f"Bearer {api_key}"}
            test_url = f"{base_url}/models/black-forest-labs/FLUX.1-schnell"
            response = requests.get(test_url, headers=headers, timeout=10)
            if response.status_code == 200:
                return True, "Hugging Face API å¯†é‘°é©—è­‰æˆåŠŸ"
            else:
                return False, f"HTTP {response.status_code}: é©—è­‰å¤±æ•—"
        else:
            test_client = OpenAI(api_key=api_key, base_url=base_url)
            response = test_client.models.list()
            return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "Unauthorized" in error_msg:
            return False, "API å¯†é‘°ç„¡æ•ˆæˆ–å·²éæœŸ"
        elif "403" in error_msg or "Forbidden" in error_msg:
            return False, "API å¯†é‘°æ²’æœ‰è¶³å¤ æ¬Šé™"
        elif "404" in error_msg:
            return False, "API ç«¯é»ä¸å­˜åœ¨æˆ–ä¸æ­£ç¢º"
        elif "timeout" in error_msg.lower():
            return False, "API é€£æ¥è¶…æ™‚"
        else:
            return False, f"API é©—è­‰å¤±æ•—: {error_msg[:100]}"

def test_model_availability(client, model_name: str, provider: str, api_key: str, base_url: str, test_prompt: str = None) -> Dict:
    """æ¸¬è©¦ç‰¹å®šæ¨¡å‹çš„å¯ç”¨æ€§"""
    if test_prompt is None:
        # å¾åˆä½µçš„æ¨¡å‹é…ç½®ä¸­ç²å–æ¸¬è©¦æç¤ºè©
        all_models = merge_models()
        test_prompt = all_models.get(model_name, {}).get('test_prompt', 'A simple test image')
    
    test_result = {
        'model': model_name,
        'available': False,
        'response_time': 0,
        'error': None,
        'details': {}
    }
    
    try:
        start_time = time.time()
        
        if provider == "Hugging Face":
            # Hugging Face API èª¿ç”¨
            headers = {"Authorization": f"Bearer {api_key}"}
            data = {"inputs": test_prompt}
            
            # è™•ç†å®Œæ•´è·¯å¾‘
            all_models = merge_models()
            model_info = all_models.get(model_name, {})
            endpoint_path = model_info.get('full_path', f"black-forest-labs/{model_name}")
            
            response = requests.post(
                f"{base_url}/models/{endpoint_path}",
                headers=headers,
                json=data,
                timeout=30
            )
            end_time = time.time()
            response_time = end_time - start_time
            
            if response.status_code == 200:
                test_result.update({
                    'available': True,
                    'response_time': response_time,
                    'details': {
                        'status_code': response.status_code,
                        'test_prompt': test_prompt,
                        'endpoint': endpoint_path
                    }
                })
            else:
                test_result.update({
                    'available': False,
                    'error': f"HTTP {response.status_code}",
                    'details': {'status_code': response.status_code}
                })
        else:
            # OpenAI Compatible API èª¿ç”¨
            response = client.images.generate(
                model=model_name,
                prompt=test_prompt,
                n=1,
                size="1024x1024"
            )
            end_time = time.time()
            response_time = end_time - start_time
            
            test_result.update({
                'available': True,
                'response_time': response_time,
                'details': {
                    'image_count': len(response.data),
                    'test_prompt': test_prompt,
                    'image_url': response.data[0].url if response.data else None
                }
            })
            
    except Exception as e:
        error_msg = str(e)
        test_result.update({
            'available': False,
            'error': error_msg,
            'details': {
                'error_type': 'generation_failed',
                'test_prompt': test_prompt
            }
        })
    
    return test_result

# å…¶é¤˜åŸæœ‰å‡½æ•¸ä¿æŒä¸è®Šï¼Œä½†éœ€è¦æ›´æ–°æ¨¡å‹å¼•ç”¨...
def init_session_state():
    """åˆå§‹åŒ–æœƒè©±ç‹€æ…‹"""
    if 'api_config' not in st.session_state:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
    
    if 'generation_history' not in st.session_state:
        st.session_state.generation_history = []
    
    if 'favorite_images' not in st.session_state:
        st.session_state.favorite_images = []
    
    if 'model_test_results' not in st.session_state:
        st.session_state.model_test_results = {}
    
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "ç”Ÿæˆå™¨"
    
    if 'discovered_models' not in st.session_state:
        st.session_state.discovered_models = {}
    
    if 'favorite_models' not in st.session_state:
        st.session_state.favorite_models = []

def init_api_client():
    """åˆå§‹åŒ– API å®¢æˆ¶ç«¯"""
    if 'api_config' in st.session_state and st.session_state.api_config.get('api_key'):
        config = st.session_state.api_config
        if config['provider'] == "Hugging Face":
            return None  # Hugging Face ä½¿ç”¨ç›´æ¥è«‹æ±‚
        try:
            return OpenAI(
                api_key=config['api_key'],
                base_url=config['base_url']
            )
        except Exception:
            return None
    return None

def show_api_settings():
    """é¡¯ç¤º API è¨­ç½®ç•Œé¢"""
    st.subheader("ğŸ”‘ API è¨­ç½®")
    
    provider_options = list(API_PROVIDERS.keys())
    current_provider = st.session_state.api_config.get('provider', 'Navy')
    selected_provider = st.selectbox(
        "é¸æ“‡ API æä¾›å•†",
        options=provider_options,
        index=provider_options.index(current_provider) if current_provider in provider_options else 1,
        format_func=lambda x: f"{API_PROVIDERS[x]['icon']} {API_PROVIDERS[x]['name']}"
    )
    
    provider_info = API_PROVIDERS[selected_provider]
    st.info(f"ğŸ“‹ {provider_info['description']}")
    
    current_key = st.session_state.api_config.get('api_key', '')
    masked_key = '*' * 20 + current_key[-8:] if len(current_key) > 8 else ''
    
    api_key_input = st.text_input(
        "API å¯†é‘°",
        value="",
        type="password",
        placeholder=f"è«‹è¼¸å…¥ {provider_info['name']} çš„ API å¯†é‘°...",
        help=f"API å¯†é‘°é€šå¸¸ä»¥ '{provider_info['key_prefix']}' é–‹é ­"
    )
    
    if current_key and not api_key_input:
        st.caption(f"ğŸ” ç•¶å‰å¯†é‘°: {masked_key}")
    
    base_url_input = st.text_input(
        "API ç«¯é» URL",
        value=st.session_state.api_config.get('base_url', provider_info['base_url_default']),
        placeholder=provider_info['base_url_default'],
        help="API æœå‹™çš„åŸºç¤ URL"
    )
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        save_btn = st.button("ğŸ’¾ ä¿å­˜è¨­ç½®", type="primary")
    
    with col2:
        test_btn = st.button("ğŸ§ª æ¸¬è©¦é€£æ¥")
    
    with col3:
        clear_btn = st.button("ğŸ—‘ï¸ æ¸…é™¤è¨­ç½®", type="secondary")
    
    if save_btn:
        if not api_key_input and not current_key:
            st.error("âŒ è«‹è¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            final_api_key = api_key_input if api_key_input else current_key
            st.session_state.api_config = {
                'provider': selected_provider,
                'api_key': final_api_key,
                'base_url': base_url_input,
                'validated': False
            }
            st.success("âœ… API è¨­ç½®å·²ä¿å­˜")
            # æ¸…é™¤èˆŠçš„æ¨¡å‹æ¸¬è©¦çµæœå’Œç™¼ç¾çµæœ
            st.session_state.model_test_results = {}
            st.session_state.discovered_models = {}
            rerun_app()
    
    if test_btn:
        test_api_key = api_key_input if api_key_input else current_key
        if not test_api_key:
            st.error("âŒ è«‹å…ˆè¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            with st.spinner("æ­£åœ¨æ¸¬è©¦ API é€£æ¥..."):
                is_valid, message = validate_api_key(test_api_key, base_url_input, selected_provider)
                if is_valid:
                    st.success(f"âœ… {message}")
                    st.session_state.api_config['validated'] = True
                    
                    # API é©—è­‰æˆåŠŸå¾Œï¼Œæä¾›è‡ªå‹•ç™¼ç¾é¸é …
                    if st.button("ğŸ” ç«‹å³ç™¼ç¾å¯ç”¨æ¨¡å‹", key="auto_discover_after_test"):
                        st.session_state.api_config = {
                            'provider': selected_provider,
                            'api_key': test_api_key,
                            'base_url': base_url_input,
                            'validated': True
                        }
                        auto_discover_models()
                else:
                    st.error(f"âŒ {message}")
                    st.session_state.api_config['validated'] = False
    
    if clear_btn:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
        st.session_state.model_test_results = {}
        st.session_state.discovered_models = {}
        st.success("ğŸ—‘ï¸ API è¨­ç½®å·²æ¸…é™¤")
        rerun_app()
    
    # é¡¯ç¤ºç•¶å‰ç‹€æ…‹
    if st.session_state.api_config['api_key']:
        status_col1, status_col2 = st.columns(2)
        with status_col1:
            if st.session_state.api_config.get('validated', False):
                st.success("ğŸŸ¢ API å·²é©—è­‰")
            else:
                st.warning("ğŸŸ¡ API æœªé©—è­‰")
        
        with status_col2:
            st.info(f"ğŸ”§ ä½¿ç”¨: {provider_info['name']}")

# åˆå§‹åŒ–
init_session_state()

# åˆå§‹åŒ– API å®¢æˆ¶ç«¯
client = init_api_client()
api_configured = client is not None or (st.session_state.api_config.get('provider') == "Hugging Face" and st.session_state.api_config.get('api_key'))

# å´é‚Šæ¬„
with st.sidebar:
    show_api_settings()
    st.markdown("---")
    
    # API ç‹€æ…‹é¡¯ç¤º
    if api_configured:
        st.success("ğŸŸ¢ API å·²é…ç½®")
        provider = st.session_state.api_config.get('provider', 'Unknown')
        st.caption(f"ä½¿ç”¨: {API_PROVIDERS.get(provider, {}).get('name', provider)}")
    else:
        st.error("ğŸ”´ API æœªé…ç½®")
    
    # å¿«é€Ÿç™¼ç¾æŒ‰éˆ•
    st.markdown("### ğŸ” å¿«é€Ÿæ“ä½œ")
    if api_configured:
        if st.button("ğŸ” ç™¼ç¾æ¨¡å‹", use_container_width=True):
            auto_discover_models()
    else:
        st.info("é…ç½® API å¾Œå¯ç™¼ç¾æ¨¡å‹")
    
    # æ¨¡å‹çµ±è¨ˆ
    st.markdown("### ğŸ“Š æ¨¡å‹çµ±è¨ˆ")
    all_models = merge_models()
    base_count = len([m for m in all_models.values() if m.get('source') == 'base'])
    discovered_count = len([m for m in all_models.values() if m.get('auto_discovered')])
    
    st.metric("åŸºç¤æ¨¡å‹", base_count)
    st.metric("ç™¼ç¾æ¨¡å‹", discovered_count)
    st.metric("ç¸½æ¨¡å‹æ•¸", len(all_models))

# ä¸»æ¨™é¡Œ
st.title("ğŸ¨ Flux AI åœ–åƒç”Ÿæˆå™¨ Pro - è‡ªå‹•æ¨¡å‹ç™¼ç¾")

# é é¢å°èˆª
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸš€ åœ–åƒç”Ÿæˆ", 
    "ğŸ” æ¨¡å‹ç™¼ç¾", 
    "ğŸ“‹ æ¨¡å‹åˆ—è¡¨",
    "ğŸ§ª æ¨¡å‹æ¸¬è©¦", 
    "ğŸ’¡ å¹«åŠ©"
])

# åœ–åƒç”Ÿæˆé é¢
with tab1:
    st.subheader("ğŸš€ åœ–åƒç”Ÿæˆ")
    if not api_configured:
        st.warning("âš ï¸ è«‹å…ˆåœ¨å´é‚Šæ¬„é…ç½® API å¯†é‘°")
        st.info("é…ç½®å®Œæˆå¾Œå³å¯é–‹å§‹ç”Ÿæˆåœ–åƒ")
    else:
        # ä½¿ç”¨åˆä½µå¾Œçš„æ¨¡å‹åˆ—è¡¨
        all_models = merge_models()
        
        st.success(f"ğŸ“‹ ç•¶å‰å¯ç”¨ {len(all_models)} å€‹ Flux æ¨¡å‹")
        
        # æ¨¡å‹é¸æ“‡
        model_options = list(all_models.keys())
        if 'selected_model' not in st.session_state:
            st.session_state.selected_model = model_options[0] if model_options else None
        
        if st.session_state.selected_model not in model_options:
            st.session_state.selected_model = model_options[0] if model_options else None
        
        selected_model = st.selectbox(
            "é¸æ“‡æ¨¡å‹:",
            options=model_options,
            index=model_options.index(st.session_state.selected_model) if st.session_state.selected_model in model_options else 0,
            format_func=lambda x: f"{all_models[x].get('icon', 'ğŸ¤–')} {all_models[x].get('name', x)}"
        )
        
        st.session_state.selected_model = selected_model
        
        # é¡¯ç¤ºæ¨¡å‹ä¿¡æ¯
        model_info = all_models[selected_model]
        col_info1, col_info2 = st.columns(2)
        
        with col_info1:
            st.info(f"**æè¿°**: {model_info.get('description', 'N/A')}")
        with col_info2:
            source_labels = {
                'base': 'ğŸ  åŸºç¤',
                'api_discovery': 'ğŸ¤– APIç™¼ç¾',
                'huggingface': 'ğŸ¤— HuggingFace',
                'auto_discovered': 'ğŸ” è‡ªå‹•ç™¼ç¾'
            }
            source = model_info.get('source', 'unknown')
            st.info(f"**ä¾†æº**: {source_labels.get(source, source)}")
        
        # æç¤ºè©è¼¸å…¥
        prompt = st.text_area(
            "è¼¸å…¥æç¤ºè©:",
            height=100,
            placeholder="æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„åœ–åƒ..."
        )
        
        # ç”ŸæˆæŒ‰éˆ•
        if st.button("ğŸš€ ç”Ÿæˆåœ–åƒ", type="primary", use_container_width=True):
            if not prompt.strip():
                st.error("è«‹è¼¸å…¥æç¤ºè©")
            else:
                st.info("ğŸš§ åœ–åƒç”ŸæˆåŠŸèƒ½æ­£åœ¨é–‹ç™¼ä¸­ï¼Œç•¶å‰ä¸»è¦å±•ç¤ºè‡ªå‹•æ¨¡å‹ç™¼ç¾åŠŸèƒ½")

# æ¨¡å‹ç™¼ç¾é é¢
with tab2:
    show_model_discovery_panel()

# æ¨¡å‹åˆ—è¡¨é é¢  
with tab3:
    show_discovered_models_list()

# æ¨¡å‹æ¸¬è©¦é é¢
with tab4:
    st.subheader("ğŸ§ª æ¨¡å‹æ¸¬è©¦")
    if not api_configured:
        st.warning("âš ï¸ è«‹å…ˆé…ç½® API å¯†é‘°")
    else:
        all_models = merge_models()
        if all_models:
            # æ‰¹é‡æ¸¬è©¦
            if st.button("ğŸ§ª æ¸¬è©¦æ‰€æœ‰æ¨¡å‹", type="primary"):
                model_ids = list(all_models.keys())[:10]  # é™åˆ¶æ¸¬è©¦æ•¸é‡
                test_discovered_models(model_ids)
            
            # é¡¯ç¤ºæ¸¬è©¦çµæœ
            if st.session_state.get('model_test_results'):
                st.subheader("ğŸ“Š æ¸¬è©¦çµæœ")
                for model_id, result in st.session_state.model_test_results.items():
                    model_info = all_models.get(model_id, {})
                    
                    col_model, col_status, col_time = st.columns([2, 1, 1])
                    
                    with col_model:
                        st.write(f"{model_info.get('icon', 'ğŸ¤–')} {model_info.get('name', model_id)}")
                    
                    with col_status:
                        if result.get('available'):
                            st.success("âœ… å¯ç”¨")
                        else:
                            st.error("âŒ ä¸å¯ç”¨")
                    
                    with col_time:
                        if result.get('response_time'):
                            st.metric("éŸ¿æ‡‰æ™‚é–“", f"{result['response_time']:.2f}s")
        else:
            st.info("è«‹å…ˆç™¼ç¾ä¸€äº›æ¨¡å‹")

# å¹«åŠ©é é¢
with tab5:
    st.subheader("ğŸ’¡ ä½¿ç”¨å¹«åŠ©")
    
    st.markdown("### ğŸ” è‡ªå‹•æ¨¡å‹ç™¼ç¾")
    st.markdown("""
    **åŠŸèƒ½ç‰¹è‰²:**
    - **æ™ºèƒ½æƒæ**: è‡ªå‹•æƒæ API ç«¯é»çš„æ‰€æœ‰å¯ç”¨æ¨¡å‹
    - **æ¨¡å¼è­˜åˆ¥**: æ™ºèƒ½è­˜åˆ¥ Flux ç›¸é—œæ¨¡å‹ä¸¦åˆ†é¡
    - **å¯¦æ™‚æ›´æ–°**: å‹•æ…‹æ›´æ–°æ¨¡å‹åˆ—è¡¨ï¼Œç„¡éœ€æ‰‹å‹•ç¶­è­·
    - **å¤šå¹³å°æ”¯æŒ**: æ”¯æŒ OpenAIã€Hugging Faceã€Together AI ç­‰å¤šå€‹å¹³å°
    
    **ä½¿ç”¨æ­¥é©Ÿ:**
    1. é…ç½® API å¯†é‘°
    2. é»æ“Šã€Œé–‹å§‹è‡ªå‹•ç™¼ç¾ã€
    3. ç³»çµ±è‡ªå‹•æƒæå’Œåˆ†ææ¨¡å‹
    4. æŸ¥çœ‹ç™¼ç¾çš„æ¨¡å‹åˆ—è¡¨
    5. æ¸¬è©¦æ¨¡å‹å¯ç”¨æ€§
    6. é–‹å§‹ç”Ÿæˆåœ–åƒ
    """)
    
    st.markdown("### ğŸ¯ æ”¯æŒçš„æ¨¡å‹æ¨¡å¼")
    st.markdown("""
    ç³»çµ±èƒ½è‡ªå‹•è­˜åˆ¥ä»¥ä¸‹é¡å‹çš„ Flux æ¨¡å‹ï¼š
    - **FLUX.1 Schnell**: å¿«é€Ÿç”Ÿæˆæ¨¡å‹
    - **FLUX.1 Dev**: é–‹ç™¼ç‰ˆæœ¬æ¨¡å‹  
    - **FLUX.1 Pro**: å°ˆæ¥­ç‰ˆæœ¬æ¨¡å‹
    - **FLUX.1 Kontext**: ä¸Šä¸‹æ–‡ç†è§£æ¨¡å‹
    - **FLUX.2**: ä¸‹ä¸€ä»£æ¨¡å‹
    - **è‡ªå®šç¾©å¾®èª¿**: Animeã€Realismã€Art ç­‰é¢¨æ ¼åŒ–æ¨¡å‹
    """)
    
    st.markdown("### ğŸš€ Koyeb éƒ¨ç½²å„ªå‹¢")
    st.markdown("""
    - **Scale-to-Zero**: é–’ç½®æ™‚è‡ªå‹•ç¸®æ¸›æˆæœ¬
    - **å…¨çƒéƒ¨ç½²**: 50+ å€‹åœ°å€å¯é¸
    - **è‡ªå‹•ç¸®æ”¾**: æ ¹æ“šéœ€æ±‚è‡ªå‹•èª¿æ•´è³‡æº
    - **å®‰å…¨å¯é **: è‡ªå‹• HTTPS å’Œç’°å¢ƒè®Šé‡åŠ å¯†
    """)

# é è…³
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666;">
    ğŸš€ Koyeb éƒ¨ç½² | ğŸ” è‡ªå‹•æ¨¡å‹ç™¼ç¾ | ğŸ¨ Flux AI Pro
</div>
""", unsafe_allow_html=True)
