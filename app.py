import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Optional, Tuple
import time
import random
import json
import sqlite3
import uuid
import zipfile
import psutil
import os

# æª¢æŸ¥ Streamlit ç‰ˆæœ¬ä¸¦å®šç¾©é‡æ–°é‹è¡Œå‡½æ•¸
def rerun_app():
    """å…¼å®¹ä¸åŒ Streamlit ç‰ˆæœ¬çš„é‡æ–°é‹è¡Œå‡½æ•¸"""
    if hasattr(st, 'rerun'):
        st.rerun()
    elif hasattr(st, 'experimental_rerun'):
        st.experimental_rerun()
    else:
        # ä½œç‚ºæœ€å¾Œçš„å›é€€
        st.stop()

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="Flux AI åœ–åƒç”Ÿæˆå™¨ Pro - Koyeb Edition",
    page_icon="ğŸ¨",
    layout="wide"
)

# API æä¾›å•†é…ç½®
API_PROVIDERS = {
    "OpenAI Compatible": {
        "name": "OpenAI Compatible API",
        "base_url_default": "https://api.openai.com/v1",
        "key_prefix": "sk-",
        "description": "OpenAI å®˜æ–¹æˆ–å…¼å®¹çš„ API æœå‹™",
        "icon": "ğŸ¤–"
    },
    "Navy": {
        "name": "Navy API",
        "base_url_default": "https://api.navy/v1", 
        "key_prefix": "sk-",
        "description": "Navy æä¾›çš„ AI åœ–åƒç”Ÿæˆæœå‹™",
        "icon": "âš“"
    },
    "Hugging Face": {
        "name": "Hugging Face Inference",
        "base_url_default": "https://api-inference.huggingface.co",
        "key_prefix": "hf_",
        "description": "Hugging Face Inference API",
        "icon": "ğŸ¤—"
    },
    "Custom": {
        "name": "è‡ªå®šç¾© API",
        "base_url_default": "",
        "key_prefix": "",
        "description": "è‡ªå®šç¾©çš„ API ç«¯é»",
        "icon": "ğŸ”§"
    }
}

# Flux æ¨¡å‹é…ç½®ï¼ˆå¢å¼·ç‰ˆï¼‰
FLUX_MODELS = {
    "flux.1-schnell": {
        "name": "FLUX.1 Schnell",
        "description": "æœ€å¿«çš„ç”Ÿæˆé€Ÿåº¦ï¼Œé–‹æºæ¨¡å‹",
        "icon": "âš¡",
        "type": "å¿«é€Ÿç”Ÿæˆ",
        "test_prompt": "A simple cat sitting on a table",
        "expected_size": "1024x1024",
        "priority": 1
    },
    "flux.1-dev": {
        "name": "FLUX.1 Dev", 
        "description": "é–‹ç™¼ç‰ˆæœ¬ï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡è³ªé‡",
        "icon": "ğŸ”§",
        "type": "é–‹ç™¼ç‰ˆæœ¬",
        "test_prompt": "A beautiful landscape with mountains",
        "expected_size": "1024x1024",
        "priority": 2
    },
    "flux.1.1-pro": {
        "name": "FLUX.1.1 Pro",
        "description": "æ”¹é€²çš„æ——è‰¦æ¨¡å‹ï¼Œæœ€ä½³å“è³ª",
        "icon": "ğŸ‘‘",
        "type": "æ——è‰¦ç‰ˆæœ¬",
        "test_prompt": "Professional portrait of a person in business attire",
        "expected_size": "1024x1024",
        "priority": 3
    },
    "flux.1-kontext-pro": {
        "name": "FLUX.1 Kontext Pro",
        "description": "æ”¯æŒåœ–åƒç·¨è¼¯å’Œä¸Šä¸‹æ–‡ç†è§£",
        "icon": "ğŸ¯",
        "type": "ç·¨è¼¯å°ˆç”¨",
        "test_prompt": "Abstract geometric shapes in vibrant colors",
        "expected_size": "1024x1024",
        "priority": 4
    }
}

# æ•¸æ“šåº«åˆå§‹åŒ–
def init_database():
    """åˆå§‹åŒ– SQLite æ•¸æ“šåº«"""
    conn = sqlite3.connect('flux_ai_pro.db')
    cursor = conn.cursor()
    
    # å‰µå»º API é…ç½®è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS api_configs (
            id TEXT PRIMARY KEY,
            provider TEXT NOT NULL,
            api_key TEXT NOT NULL,
            base_url TEXT NOT NULL,
            validated BOOLEAN DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # å‰µå»ºæ¨¡å‹æ¸¬è©¦çµæœè¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS model_test_results (
            id TEXT PRIMARY KEY,
            model_name TEXT NOT NULL,
            available BOOLEAN,
            response_time REAL,
            error_message TEXT,
            test_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # å‰µå»ºç”Ÿæˆæ­·å²è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS generation_history (
            id TEXT PRIMARY KEY,
            prompt TEXT NOT NULL,
            model_name TEXT,
            api_provider TEXT,
            image_urls TEXT,
            metadata TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # å‰µå»ºæ”¶è—è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS favorites (
            id TEXT PRIMARY KEY,
            image_url TEXT NOT NULL,
            prompt TEXT,
            model_name TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()

def validate_api_key(api_key: str, base_url: str, provider: str) -> Tuple[bool, str]:
    """é©—è­‰ API å¯†é‘°æ˜¯å¦æœ‰æ•ˆ"""
    try:
        if provider == "Hugging Face":
            headers = {"Authorization": f"Bearer {api_key}"}
            test_url = f"{base_url}/models/black-forest-labs/FLUX.1-schnell"
            response = requests.get(test_url, headers=headers, timeout=10)
            if response.status_code == 200:
                return True, "Hugging Face API å¯†é‘°é©—è­‰æˆåŠŸ"
            else:
                return False, f"HTTP {response.status_code}: é©—è­‰å¤±æ•—"
        else:
            test_client = OpenAI(api_key=api_key, base_url=base_url)
            response = test_client.models.list()
            return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "Unauthorized" in error_msg:
            return False, "API å¯†é‘°ç„¡æ•ˆæˆ–å·²éæœŸ"
        elif "403" in error_msg or "Forbidden" in error_msg:
            return False, "API å¯†é‘°æ²’æœ‰è¶³å¤ æ¬Šé™"
        elif "404" in error_msg:
            return False, "API ç«¯é»ä¸å­˜åœ¨æˆ–ä¸æ­£ç¢º"
        elif "timeout" in error_msg.lower():
            return False, "API é€£æ¥è¶…æ™‚"
        else:
            return False, f"API é©—è­‰å¤±æ•—: {error_msg[:100]}"

def get_available_models(client: OpenAI) -> Tuple[bool, List[str]]:
    """ç²å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        response = client.models.list()
        model_ids = [model.id for model in response.data]
        return True, model_ids
    except Exception as e:
        return False, [str(e)]

def test_model_availability(client, model_name: str, provider: str, api_key: str, base_url: str, test_prompt: str = None) -> Dict:
    """æ¸¬è©¦ç‰¹å®šæ¨¡å‹çš„å¯ç”¨æ€§"""
    if test_prompt is None:
        test_prompt = FLUX_MODELS.get(model_name, {}).get('test_prompt', 'A simple test image')
    
    test_result = {
        'model': model_name,
        'available': False,
        'response_time': 0,
        'error': None,
        'details': {}
    }
    
    try:
        start_time = time.time()
        
        if provider == "Hugging Face":
            # Hugging Face API èª¿ç”¨
            headers = {"Authorization": f"Bearer {api_key}"}
            data = {"inputs": test_prompt}
            response = requests.post(
                f"{base_url}/models/black-forest-labs/{model_name}",
                headers=headers,
                json=data,
                timeout=30
            )
            end_time = time.time()
            response_time = end_time - start_time
            
            if response.status_code == 200:
                test_result.update({
                    'available': True,
                    'response_time': response_time,
                    'details': {
                        'status_code': response.status_code,
                        'test_prompt': test_prompt
                    }
                })
            else:
                test_result.update({
                    'available': False,
                    'error': f"HTTP {response.status_code}",
                    'details': {'status_code': response.status_code}
                })
        else:
            # OpenAI Compatible API èª¿ç”¨
            response = client.images.generate(
                model=model_name,
                prompt=test_prompt,
                n=1,
                size="1024x1024"
            )
            end_time = time.time()
            response_time = end_time - start_time
            
            test_result.update({
                'available': True,
                'response_time': response_time,
                'details': {
                    'image_count': len(response.data),
                    'test_prompt': test_prompt,
                    'image_url': response.data[0].url if response.data else None
                }
            })
            
    except Exception as e:
        error_msg = str(e)
        test_result.update({
            'available': False,
            'error': error_msg,
            'details': {
                'error_type': 'generation_failed',
                'test_prompt': test_prompt
            }
        })
    
    return test_result

def batch_test_models(client, provider: str, api_key: str, base_url: str, models_to_test: List[str] = None) -> Dict[str, Dict]:
    """æ‰¹é‡æ¸¬è©¦å¤šå€‹æ¨¡å‹çš„å¯ç”¨æ€§"""
    if models_to_test is None:
        models_to_test = list(FLUX_MODELS.keys())
    
    results = {}
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, model_name in enumerate(models_to_test):
        progress = (i + 1) / len(models_to_test)
        progress_bar.progress(progress)
        status_text.text(f"ğŸ§ª æ­£åœ¨æ¸¬è©¦ {FLUX_MODELS.get(model_name, {}).get('name', model_name)}... ({i+1}/{len(models_to_test)})")
        
        result = test_model_availability(client, model_name, provider, api_key, base_url)
        results[model_name] = result
        
        # é¿å…è«‹æ±‚éæ–¼é »ç¹
        time.sleep(1)
    
    progress_bar.empty()
    status_text.empty()
    return results

def show_model_status_dashboard():
    """é¡¯ç¤ºæ¨¡å‹ç‹€æ…‹å„€è¡¨æ¿"""
    if 'model_test_results' not in st.session_state:
        st.session_state.model_test_results = {}
    
    st.subheader("ğŸ¯ æ¨¡å‹å¯ç”¨æ€§ç‹€æ…‹")
    
    # æ§åˆ¶æŒ‰éˆ•
    col_btn1, col_btn2, col_btn3 = st.columns(3)
    
    with col_btn1:
        test_all_btn = st.button("ğŸ§ª æ¸¬è©¦æ‰€æœ‰æ¨¡å‹", type="primary")
    
    with col_btn2:
        refresh_btn = st.button("ğŸ”„ åˆ·æ–°ç‹€æ…‹")
    
    with col_btn3:
        clear_cache_btn = st.button("ğŸ—‘ï¸ æ¸…é™¤ç·©å­˜")
    
    # åŸ·è¡Œæ‰¹é‡æ¸¬è©¦
    if test_all_btn:
        if 'api_config' in st.session_state and st.session_state.api_config.get('api_key'):
            config = st.session_state.api_config
            
            if config['provider'] == "Hugging Face":
                client = None
            else:
                client = OpenAI(
                    api_key=config['api_key'],
                    base_url=config['base_url']
                )
            
            with st.spinner("æ­£åœ¨æ‰¹é‡æ¸¬è©¦æ‰€æœ‰æ¨¡å‹..."):
                st.session_state.model_test_results = batch_test_models(
                    client, config['provider'], config['api_key'], config['base_url']
                )
                st.session_state.last_test_time = datetime.datetime.now()
            st.success("âœ… æ‰¹é‡æ¸¬è©¦å®Œæˆï¼")
            rerun_app()
        else:
            st.error("âŒ è«‹å…ˆé…ç½® API å¯†é‘°")
    
    # åˆ·æ–°ç‹€æ…‹
    if refresh_btn:
        rerun_app()
    
    # æ¸…é™¤ç·©å­˜
    if clear_cache_btn:
        st.session_state.model_test_results = {}
        if 'last_test_time' in st.session_state:
            del st.session_state.last_test_time
        st.success("ç·©å­˜å·²æ¸…é™¤")
        rerun_app()
    
    # é¡¯ç¤ºæ¸¬è©¦çµæœ
    if st.session_state.model_test_results:
        # é¡¯ç¤ºæœ€å¾Œæ¸¬è©¦æ™‚é–“
        if 'last_test_time' in st.session_state:
            st.caption(f"æœ€å¾Œæ¸¬è©¦æ™‚é–“: {st.session_state.last_test_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # çµ±è¨ˆæ¦‚è¦½
        total_models = len(st.session_state.model_test_results)
        available_models = sum(1 for result in st.session_state.model_test_results.values() if result.get('available', False))
        
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        with col_stat1:
            st.metric("ç¸½æ¨¡å‹æ•¸", total_models)
        with col_stat2:
            st.metric("å¯ç”¨æ¨¡å‹", available_models)
        with col_stat3:
            availability_rate = (available_models / total_models * 100) if total_models > 0 else 0
            st.metric("å¯ç”¨ç‡", f"{availability_rate:.1f}%")
        
        # è©³ç´°çµæœè¡¨æ ¼
        st.subheader("ğŸ“Š è©³ç´°æ¸¬è©¦çµæœ")
        
        # æŒ‰å¯ç”¨æ€§å’Œå„ªå…ˆç´šæ’åº
        sorted_results = sorted(
            st.session_state.model_test_results.items(),
            key=lambda x: (
                not x[1].get('available', False),
                FLUX_MODELS.get(x[0], {}).get('priority', 999)
            )
        )
        
        for model_name, result in sorted_results:
            model_info = FLUX_MODELS.get(model_name, {})
            
            # å‰µå»ºå±•é–‹æ¡†
            status_icon = "âœ…" if result.get('available', False) else "âŒ"
            response_time = result.get('response_time', 0)
            time_display = f" ({response_time:.2f}s)" if response_time > 0 else ""
            
            with st.expander(
                f"{status_icon} {model_info.get('icon', 'ğŸ”§')} {model_info.get('name', model_name)}{time_display}"
            ):
                col_info, col_test = st.columns([2, 1])
                
                with col_info:
                    st.markdown(f"**æ¨¡å‹ID**: `{model_name}`")
                    st.markdown(f"**æè¿°**: {model_info.get('description', 'N/A')}")
                    st.markdown(f"**é¡å‹**: {model_info.get('type', 'N/A')}")
                    
                    if result.get('available', False):
                        st.success("âœ… æ¨¡å‹å¯ç”¨")
                        st.markdown(f"**éŸ¿æ‡‰æ™‚é–“**: {response_time:.2f} ç§’")
                    else:
                        st.error("âŒ æ¨¡å‹ä¸å¯ç”¨")
                        error_msg = result.get('error', 'Unknown error')
                        st.markdown(f"**éŒ¯èª¤ä¿¡æ¯**: {error_msg}")
                        
                        # æ ¹æ“šéŒ¯èª¤é¡å‹æä¾›å»ºè­°
                        if "401" in error_msg or "403" in error_msg:
                            st.warning("ğŸ’¡ å»ºè­°æª¢æŸ¥ API å¯†é‘°æ¬Šé™")
                        elif "404" in error_msg:
                            st.warning("ğŸ’¡ æ¨¡å‹å¯èƒ½ä¸å­˜åœ¨æˆ–æš«æ™‚ä¸å¯ç”¨")
                        elif "429" in error_msg:
                            st.warning("ğŸ’¡ è«‹æ±‚éæ–¼é »ç¹ï¼Œç¨å¾Œå†è©¦")
                        elif "500" in error_msg:
                            st.warning("ğŸ’¡ æœå‹™å™¨éŒ¯èª¤ï¼Œæ¨¡å‹å¯èƒ½æš«æ™‚é›¢ç·š")
                
                with col_test:
                    st.markdown("**å–®ç¨æ¸¬è©¦**")
                    custom_prompt = st.text_input(
                        "è‡ªå®šç¾©æ¸¬è©¦æç¤ºè©",
                        value=model_info.get('test_prompt', 'A simple test image'),
                        key=f"test_prompt_{model_name}"
                    )
                    
                    if st.button(f"ğŸ”¬ æ¸¬è©¦æ­¤æ¨¡å‹", key=f"test_{model_name}"):
                        if 'api_config' in st.session_state and st.session_state.api_config.get('api_key'):
                            config = st.session_state.api_config
                            
                            if config['provider'] == "Hugging Face":
                                client = None
                            else:
                                client = OpenAI(
                                    api_key=config['api_key'],
                                    base_url=config['base_url']
                                )
                            
                            with st.spinner(f"æ­£åœ¨æ¸¬è©¦ {model_name}..."):
                                test_result = test_model_availability(
                                    client, model_name, config['provider'], 
                                    config['api_key'], config['base_url'], custom_prompt
                                )
                                st.session_state.model_test_results[model_name] = test_result
                            rerun_app()
                        else:
                            st.error("è«‹å…ˆé…ç½® API å¯†é‘°")
    
    else:
        st.info("ğŸ§ª é»æ“Š 'æ¸¬è©¦æ‰€æœ‰æ¨¡å‹' é–‹å§‹æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§")

def get_recommended_models() -> List[str]:
    """åŸºæ–¼æ¸¬è©¦çµæœæ¨è–¦æœ€ä½³æ¨¡å‹"""
    if 'model_test_results' not in st.session_state:
        return []
    
    # ç¯©é¸å¯ç”¨çš„æ¨¡å‹
    available_models = [
        model_name for model_name, result in st.session_state.model_test_results.items()
        if result.get('available', False)
    ]
    
    # æŒ‰å„ªå…ˆç´šå’ŒéŸ¿æ‡‰æ™‚é–“æ’åº
    recommended = sorted(
        available_models,
        key=lambda x: (
            FLUX_MODELS.get(x, {}).get('priority', 999),
            st.session_state.model_test_results[x].get('response_time', 999)
        )
    )
    
    return recommended[:3]

def show_model_recommendations():
    """é¡¯ç¤ºæ¨¡å‹æ¨è–¦"""
    recommended = get_recommended_models()
    if recommended:
        st.subheader("â­ æ¨è–¦æ¨¡å‹")
        for i, model_name in enumerate(recommended):
            model_info = FLUX_MODELS.get(model_name, {})
            result = st.session_state.model_test_results.get(model_name, {})
            
            col_icon, col_info, col_metrics = st.columns([1, 3, 2])
            
            with col_icon:
                st.markdown(f"### {i+1}. {model_info.get('icon', 'ğŸ”§')}")
            
            with col_info:
                st.markdown(f"**{model_info.get('name', model_name)}**")
                st.caption(model_info.get('description', 'N/A'))
            
            with col_metrics:
                response_time = result.get('response_time', 0)
                st.metric("éŸ¿æ‡‰æ™‚é–“", f"{response_time:.2f}s")
        
        # è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹
        if st.button("ğŸš€ ä½¿ç”¨æ¨è–¦çš„æœ€ä½³æ¨¡å‹"):
            st.session_state.recommended_model = recommended[0]
            st.success(f"å·²é¸æ“‡: {FLUX_MODELS.get(recommended[0], {}).get('name', recommended[0])}")
            rerun_app()
    else:
        st.info("è«‹å…ˆæ¸¬è©¦æ¨¡å‹å¯ç”¨æ€§ä»¥ç²å–æ¨è–¦")

def init_api_client():
    """åˆå§‹åŒ– API å®¢æˆ¶ç«¯"""
    if 'api_config' in st.session_state and st.session_state.api_config.get('api_key'):
        config = st.session_state.api_config
        if config['provider'] == "Hugging Face":
            return None  # Hugging Face ä½¿ç”¨ç›´æ¥è«‹æ±‚
        try:
            return OpenAI(
                api_key=config['api_key'],
                base_url=config['base_url']
            )
        except Exception:
            return None
    return None

def show_api_settings():
    """é¡¯ç¤º API è¨­ç½®ç•Œé¢"""
    st.subheader("ğŸ”‘ API è¨­ç½®")
    
    provider_options = list(API_PROVIDERS.keys())
    current_provider = st.session_state.api_config.get('provider', 'Navy')
    selected_provider = st.selectbox(
        "é¸æ“‡ API æä¾›å•†",
        options=provider_options,
        index=provider_options.index(current_provider) if current_provider in provider_options else 1,
        format_func=lambda x: f"{API_PROVIDERS[x]['icon']} {API_PROVIDERS[x]['name']}"
    )
    
    provider_info = API_PROVIDERS[selected_provider]
    st.info(f"ğŸ“‹ {provider_info['description']}")
    
    current_key = st.session_state.api_config.get('api_key', '')
    masked_key = '*' * 20 + current_key[-8:] if len(current_key) > 8 else ''
    
    api_key_input = st.text_input(
        "API å¯†é‘°",
        value="",
        type="password",
        placeholder=f"è«‹è¼¸å…¥ {provider_info['name']} çš„ API å¯†é‘°...",
        help=f"API å¯†é‘°é€šå¸¸ä»¥ '{provider_info['key_prefix']}' é–‹é ­"
    )
    
    if current_key and not api_key_input:
        st.caption(f"ğŸ” ç•¶å‰å¯†é‘°: {masked_key}")
    
    base_url_input = st.text_input(
        "API ç«¯é» URL",
        value=st.session_state.api_config.get('base_url', provider_info['base_url_default']),
        placeholder=provider_info['base_url_default'],
        help="API æœå‹™çš„åŸºç¤ URL"
    )
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        save_btn = st.button("ğŸ’¾ ä¿å­˜è¨­ç½®", type="primary")
    
    with col2:
        test_btn = st.button("ğŸ§ª æ¸¬è©¦é€£æ¥")
    
    with col3:
        clear_btn = st.button("ğŸ—‘ï¸ æ¸…é™¤è¨­ç½®", type="secondary")
    
    if save_btn:
        if not api_key_input and not current_key:
            st.error("âŒ è«‹è¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            final_api_key = api_key_input if api_key_input else current_key
            st.session_state.api_config = {
                'provider': selected_provider,
                'api_key': final_api_key,
                'base_url': base_url_input,
                'validated': False
            }
            st.success("âœ… API è¨­ç½®å·²ä¿å­˜")
            # æ¸…é™¤èˆŠçš„æ¨¡å‹æ¸¬è©¦çµæœ
            st.session_state.model_test_results = {}
            rerun_app()
    
    if test_btn:
        test_api_key = api_key_input if api_key_input else current_key
        if not test_api_key:
            st.error("âŒ è«‹å…ˆè¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            with st.spinner("æ­£åœ¨æ¸¬è©¦ API é€£æ¥..."):
                is_valid, message = validate_api_key(test_api_key, base_url_input, selected_provider)
                if is_valid:
                    st.success(f"âœ… {message}")
                    st.session_state.api_config['validated'] = True
                else:
                    st.error(f"âŒ {message}")
                    st.session_state.api_config['validated'] = False
    
    if clear_btn:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
        st.session_state.model_test_results = {}
        st.success("ğŸ—‘ï¸ API è¨­ç½®å·²æ¸…é™¤")
        rerun_app()
    
    # é¡¯ç¤ºç•¶å‰ç‹€æ…‹
    if st.session_state.api_config['api_key']:
        status_col1, status_col2 = st.columns(2)
        with status_col1:
            if st.session_state.api_config.get('validated', False):
                st.success("ğŸŸ¢ API å·²é©—è­‰")
            else:
                st.warning("ğŸŸ¡ API æœªé©—è­‰")
        
        with status_col2:
            st.info(f"ğŸ”§ ä½¿ç”¨: {provider_info['name']}")

def generate_images_with_retry(client, provider: str, api_key: str, base_url: str, **params) -> Tuple[bool, any]:
    """å¸¶é‡è©¦æ©Ÿåˆ¶çš„åœ–åƒç”Ÿæˆ"""
    max_retries = 3
    base_delay = 2
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                st.info(f"ğŸ”„ å˜—è©¦é‡æ–°ç”Ÿæˆ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡)")
            
            if provider == "Hugging Face":
                # Hugging Face API èª¿ç”¨
                headers = {"Authorization": f"Bearer {api_key}"}
                data = {"inputs": params.get("prompt", "")}
                
                model_name = params.get("model", "FLUX.1-schnell")
                response = requests.post(
                    f"{base_url}/models/black-forest-labs/{model_name}",
                    headers=headers,
                    json=data,
                    timeout=60
                )
                
                if response.status_code == 200:
                    # æ¨¡æ“¬ OpenAI éŸ¿æ‡‰æ ¼å¼
                    class MockResponse:
                        def __init__(self, image_data):
                            self.data = [type('obj', (object,), {'url': f"data:image/png;base64,{base64.b64encode(image_data).decode()}"})()]
                    
                    return True, MockResponse(response.content)
                else:
                    raise Exception(f"HTTP {response.status_code}: {response.text}")
            else:
                # OpenAI Compatible API èª¿ç”¨
                response = client.images.generate(**params)
                return True, response
            
        except Exception as e:
            error_msg = str(e)
            if attempt < max_retries - 1:
                should_retry = False
                if "500" in error_msg or "502" in error_msg or "503" in error_msg:
                    should_retry = True
                elif "429" in error_msg:
                    should_retry = True
                elif "timeout" in error_msg.lower():
                    should_retry = True
                
                if should_retry:
                    delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                    st.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å˜—è©¦å¤±æ•—ï¼Œ{delay:.1f} ç§’å¾Œé‡è©¦...")
                    time.sleep(delay)
                    continue
                else:
                    return False, error_msg
            else:
                return False, error_msg
    
    return False, "æ‰€æœ‰é‡è©¦å‡å¤±æ•—"

# åˆå§‹åŒ–æœƒè©±ç‹€æ…‹
def init_session_state():
    """åˆå§‹åŒ–æœƒè©±ç‹€æ…‹"""
    if 'api_config' not in st.session_state:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
    
    if 'generation_history' not in st.session_state:
        st.session_state.generation_history = []
    
    if 'favorite_images' not in st.session_state:
        st.session_state.favorite_images = []
    
    if 'model_test_results' not in st.session_state:
        st.session_state.model_test_results = {}
    
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "ç”Ÿæˆå™¨"

def add_to_history(prompt: str, model: str, images: List[str], metadata: Dict):
    """æ·»åŠ ç”Ÿæˆè¨˜éŒ„åˆ°æ­·å²"""
    history_item = {
        "timestamp": datetime.datetime.now(),
        "prompt": prompt,
        "model": model,
        "images": images,
        "metadata": metadata,
        "id": len(st.session_state.generation_history)
    }
    st.session_state.generation_history.insert(0, history_item)
    
    # é™åˆ¶æ­·å²è¨˜éŒ„æ•¸é‡
    if len(st.session_state.generation_history) > 50:
        st.session_state.generation_history = st.session_state.generation_history[:50]

def display_image_with_actions(image_url: str, image_id: str, history_item: Dict = None):
    """é¡¯ç¤ºåœ–åƒå’Œç›¸é—œæ“ä½œ"""
    try:
        # è™•ç† base64 åœ–åƒ
        if image_url.startswith('data:image'):
            # æå– base64 æ•¸æ“š
            base64_data = image_url.split(',')[1]
            img_data = base64.b64decode(base64_data)
            img = Image.open(BytesIO(img_data))
        else:
            # æ™®é€š URL
            img_response = requests.get(image_url, timeout=10)
            img = Image.open(BytesIO(img_response.content))
            img_data = img_response.content
        
        st.image(img, use_column_width=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            img_buffer = BytesIO()
            img.save(img_buffer, format='PNG')
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰",
                data=img_buffer.getvalue(),
                file_name=f"flux_generated_{image_id}.png",
                mime="image/png",
                key=f"download_{image_id}",
                use_container_width=True
            )
        
        with col2:
            is_favorite = any(fav['id'] == image_id for fav in st.session_state.favorite_images)
            if st.button(
                "â­ å·²æ”¶è—" if is_favorite else "â˜† æ”¶è—",
                key=f"favorite_{image_id}",
                use_container_width=True
            ):
                if is_favorite:
                    st.session_state.favorite_images = [
                        fav for fav in st.session_state.favorite_images if fav['id'] != image_id
                    ]
                    st.success("å·²å–æ¶ˆæ”¶è—")
                else:
                    favorite_item = {
                        "id": image_id,
                        "image_url": image_url,
                        "timestamp": datetime.datetime.now(),
                        "history_item": history_item
                    }
                    st.session_state.favorite_images.append(favorite_item)
                    st.success("å·²åŠ å…¥æ”¶è—")
                rerun_app()
        
        with col3:
            if history_item and st.button(
                "ğŸ”„ é‡æ–°ç”Ÿæˆ",
                key=f"regenerate_{image_id}",
                use_container_width=True
            ):
                st.session_state.regenerate_prompt = history_item['prompt']
                st.session_state.regenerate_model = history_item['model']
                st.session_state.current_page = "ç”Ÿæˆå™¨"
                rerun_app()
    
    except Exception as e:
        st.error(f"åœ–åƒé¡¯ç¤ºéŒ¯èª¤: {str(e)}")

def get_system_metrics():
    """ç²å–ç³»çµ±è³‡æºä¿¡æ¯"""
    try:
        # CPU ä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=0.1)
        cpu_count = psutil.cpu_count()
        
        # å…§å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        memory_used_mb = memory.used / (1024**2)
        memory_total_mb = memory.total / (1024**2)
        memory_percent = memory.percent
        
        return {
            "cpu": {"percent": cpu_percent, "count": cpu_count},
            "memory": {
                "used_mb": memory_used_mb,
                "total_mb": memory_total_mb,
                "percent": memory_percent
            }
        }
    except Exception as e:
        return {"error": str(e)}

# åˆå§‹åŒ–
init_session_state()
init_database()

# åˆå§‹åŒ– API å®¢æˆ¶ç«¯
client = init_api_client()
api_configured = client is not None or (st.session_state.api_config.get('provider') == "Hugging Face" and st.session_state.api_config.get('api_key'))

# å´é‚Šæ¬„
with st.sidebar:
    show_api_settings()
    st.markdown("---")
    
    # API ç‹€æ…‹é¡¯ç¤º
    if api_configured:
        st.success("ğŸŸ¢ API å·²é…ç½®")
        provider = st.session_state.api_config.get('provider', 'Unknown')
        st.caption(f"ä½¿ç”¨: {API_PROVIDERS.get(provider, {}).get('name', provider)}")
    else:
        st.error("ğŸ”´ API æœªé…ç½®")
    
    # ç³»çµ±è³‡æºç›£æ§
    st.markdown("### ğŸ“Š Koyeb è³‡æºç›£æ§")
    metrics = get_system_metrics()
    if "error" not in metrics:
        st.metric("CPU ä½¿ç”¨ç‡", f"{metrics['cpu']['percent']:.1f}%")
        st.metric("å…§å­˜ä½¿ç”¨", f"{metrics['memory']['used_mb']:.0f}MB")
        st.metric("å…§å­˜ä½¿ç”¨ç‡", f"{metrics['memory']['percent']:.1f}%")
    
    # æ¨¡å‹ç‹€æ…‹æ¦‚è¦½
    st.markdown("### ğŸ¯ æ¨¡å‹ç‹€æ…‹")
    if st.session_state.model_test_results:
        available_count = sum(1 for result in st.session_state.model_test_results.values() if result.get('available', False))
        total_count = len(st.session_state.model_test_results)
        st.metric("å¯ç”¨æ¨¡å‹", f"{available_count}/{total_count}")
        
        # é¡¯ç¤ºæ¨è–¦æ¨¡å‹
        recommended = get_recommended_models()
        if recommended:
            st.markdown("**æ¨è–¦æ¨¡å‹:**")
            for model in recommended[:2]:
                model_name = FLUX_MODELS.get(model, {}).get('name', model)
                st.write(f"â€¢ {model_name}")
    else:
        st.info("æœªé€²è¡Œæ¨¡å‹æ¸¬è©¦")
    
    # ä½¿ç”¨çµ±è¨ˆ
    st.markdown("### ğŸ“Š ä½¿ç”¨çµ±è¨ˆ")
    total_generations = len(st.session_state.generation_history)
    total_favorites = len(st.session_state.favorite_images)
    st.metric("ç¸½ç”Ÿæˆæ•¸", total_generations)
    st.metric("æ”¶è—æ•¸é‡", total_favorites)

# ä¸»æ¨™é¡Œ
st.title("ğŸ¨ Flux AI åœ–åƒç”Ÿæˆå™¨ Pro - Koyeb Edition")

# API ç‹€æ…‹è­¦å‘Š
if not api_configured:
    st.error("âš ï¸ è«‹å…ˆé…ç½® API å¯†é‘°æ‰èƒ½ä½¿ç”¨åœ–åƒç”ŸæˆåŠŸèƒ½")
    st.info("ğŸ‘ˆ é»æ“Šå´é‚Šæ¬„çš„ 'API è¨­ç½®' ä¾†é…ç½®ä½ çš„å¯†é‘°")

# é é¢å°èˆª
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸš€ åœ–åƒç”Ÿæˆ", 
    "ğŸ§ª æ¨¡å‹æ¸¬è©¦", 
    "ğŸ“š æ­·å²è¨˜éŒ„", 
    "â­ æ”¶è—å¤¾", 
    "ğŸ’¡ å¹«åŠ©"
])

# åœ–åƒç”Ÿæˆé é¢
with tab1:
    if not api_configured:
        st.warning("âš ï¸ è«‹å…ˆåœ¨å´é‚Šæ¬„é…ç½® API å¯†é‘°")
        st.info("é…ç½®å®Œæˆå¾Œå³å¯é–‹å§‹ç”Ÿæˆåœ–åƒ")
    else:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # æ™ºèƒ½æ¨¡å‹é¸æ“‡
            st.subheader("ğŸ¯ æ™ºèƒ½æ¨¡å‹é¸æ“‡")
            
            # é¡¯ç¤ºæ¨è–¦æ¨¡å‹
            recommended = get_recommended_models()
            if recommended:
                st.success("ğŸŒŸ åŸºæ–¼å¯ç”¨æ€§æ¸¬è©¦çš„æ¨è–¦æ¨¡å‹:")
                rec_cols = st.columns(len(recommended))
                selected_model = None
                
                for i, model_name in enumerate(recommended):
                    with rec_cols[i]:
                        model_info = FLUX_MODELS.get(model_name, {})
                        result = st.session_state.model_test_results.get(model_name, {})
                        response_time = result.get('response_time', 0)
                        
                        if st.button(
                            f"{model_info.get('icon', 'ğŸ”§')}\n{model_info.get('name', model_name)}\nâš¡{response_time:.1f}s",
                            key=f"rec_model_{model_name}",
                            use_container_width=True,
                            help=f"{model_info.get('description', '')} (éŸ¿æ‡‰æ™‚é–“: {response_time:.2f}s)"
                        ):
                            selected_model = model_name
                
                # å¦‚æœé»æ“Šäº†æ¨è–¦æ¨¡å‹ï¼Œæ›´æ–°é¸æ“‡
                if selected_model:
                    st.session_state.selected_model = selected_model
            
            # å‚³çµ±æ¨¡å‹é¸æ“‡ï¼ˆå‚™ç”¨ï¼‰
            with st.expander("ğŸ”§ æ‰‹å‹•é¸æ“‡æ¨¡å‹"):
                model_cols = st.columns(len(FLUX_MODELS))
                for i, (model_key, model_info) in enumerate(FLUX_MODELS.items()):
                    with model_cols[i]:
                        # é¡¯ç¤ºæ¨¡å‹ç‹€æ…‹
                        if model_key in st.session_state.model_test_results:
                            result = st.session_state.model_test_results[model_key]
                            if result.get('available', False):
                                status = f"âœ… {result.get('response_time', 0):.1f}s"
                            else:
                                status = "âŒ ä¸å¯ç”¨"
                        else:
                            status = "â“ æœªæ¸¬è©¦"
                        
                        if st.button(
                            f"{model_info['icon']} {model_info['name']}\n{model_info['type']}\n{status}",
                            key=f"manual_model_{model_key}",
                            use_container_width=True,
                            help=model_info['description']
                        ):
                            st.session_state.selected_model = model_key
            
            # æœ€çµ‚æ¨¡å‹é¸æ“‡
            if 'selected_model' not in st.session_state:
                if recommended:
                    st.session_state.selected_model = recommended[0]
                else:
                    st.session_state.selected_model = list(FLUX_MODELS.keys())[0]
            
            final_selected_model = st.session_state.selected_model
            model_info = FLUX_MODELS[final_selected_model]
            
            # é¡¯ç¤ºé¸ä¸­æ¨¡å‹çš„è©³ç´°ä¿¡æ¯
            if final_selected_model in st.session_state.model_test_results:
                result = st.session_state.model_test_results[final_selected_model]
                if result.get('available', False):
                    st.success(f"âœ… å·²é¸æ“‡: {model_info['icon']} {model_info['name']} (éŸ¿æ‡‰æ™‚é–“: {result.get('response_time', 0):.2f}s)")
                else:
                    st.error(f"âŒ é¸ä¸­æ¨¡å‹ä¸å¯ç”¨: {model_info['name']}")
                    st.warning("å»ºè­°å…ˆæ¸¬è©¦æ¨¡å‹å¯ç”¨æ€§æˆ–é¸æ“‡å…¶ä»–æ¨¡å‹")
            else:
                st.info(f"ğŸ“ å·²é¸æ“‡: {model_info['icon']} {model_info['name']} - {model_info['description']}")
                st.warning("âš ï¸ æœªæ¸¬è©¦æ­¤æ¨¡å‹å¯ç”¨æ€§ï¼Œå»ºè­°å…ˆé€²è¡Œæ¸¬è©¦")
            
            # æç¤ºè©è¼¸å…¥
            st.subheader("âœï¸ è¼¸å…¥æç¤ºè©")
            
            # é‡æ–°ç”Ÿæˆæª¢æŸ¥
            default_prompt = ""
            if hasattr(st.session_state, 'regenerate_prompt'):
                default_prompt = st.session_state.regenerate_prompt
                if hasattr(st.session_state, 'regenerate_model'):
                    st.session_state.selected_model = st.session_state.regenerate_model
                delattr(st.session_state, 'regenerate_prompt')
                if hasattr(st.session_state, 'regenerate_model'):
                    delattr(st.session_state, 'regenerate_model')
            
            prompt = st.text_area(
                "æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„åœ–åƒ",
                value=default_prompt,
                height=120,
                placeholder="ä¾‹å¦‚ï¼šA cute cat wearing a wizard hat in a magical forest..."
            )
            
            # é«˜ç´šè¨­å®š
            with st.expander("ğŸ”§ é«˜ç´šè¨­å®š"):
                col_size, col_num = st.columns(2)
                
                with col_size:
                    size_options = {
                        "1024x1024": "æ­£æ–¹å½¢ (1:1)",
                        "1152x896": "æ©«å‘ (4:3.5)",
                        "896x1152": "ç›´å‘ (3.5:4)",
                        "1344x768": "å¯¬å± (16:9)",
                        "768x1344": "è¶…é«˜ (9:16)"
                    }
                    selected_size = st.selectbox(
                        "åœ–åƒå°ºå¯¸",
                        options=list(size_options.keys()),
                        format_func=lambda x: f"{x} - {size_options[x]}",
                        index=0
                    )
                
                with col_num:
                    num_images = st.slider("ç”Ÿæˆæ•¸é‡", 1, 4, 1)
            
            # å¿«é€Ÿæç¤ºè©
            st.subheader("ğŸ’¡ å¿«é€Ÿæç¤ºè©")
            
            model_type = model_info.get('type', '')
            if 'å¿«é€Ÿ' in model_type:
                category_default = "äººç‰©è‚–åƒ"
            elif 'å‰µæ„' in model_type:
                category_default = "è—è¡“å‰µæ„"
            else:
                category_default = "è‡ªç„¶é¢¨æ™¯"
            
            prompt_categories = {
                "äººç‰©è‚–åƒ": [
                    "Professional headshot of a businesswoman in modern office",
                    "Portrait of an elderly man with wise eyes and gentle smile",
                    "Young artist with paint-splattered apron in studio"
                ],
                "è‡ªç„¶é¢¨æ™¯": [
                    "Sunset over snow-capped mountains with alpine lake",
                    "Tropical beach with crystal clear water and palm trees", 
                    "Autumn forest with golden leaves and morning mist"
                ],
                "è—è¡“å‰µæ„": [
                    "Abstract geometric composition with vibrant colors",
                    "Watercolor painting of blooming cherry blossoms",
                    "Digital art of a dragon made of flowing water"
                ]
            }
            
            category = st.selectbox(
                "é¸æ“‡é¡åˆ¥",
                list(prompt_categories.keys()),
                index=list(prompt_categories.keys()).index(category_default)
            )
            
            prompt_cols = st.columns(len(prompt_categories[category]))
            for i, quick_prompt in enumerate(prompt_categories[category]):
                with prompt_cols[i]:
                    if st.button(
                        quick_prompt[:30] + "...",
                        key=f"quick_{category}_{i}",
                        use_container_width=True,
                        help=quick_prompt
                    ):
                        st.session_state.quick_prompt = quick_prompt
                        rerun_app()
            
            if hasattr(st.session_state, 'quick_prompt'):
                prompt = st.session_state.quick_prompt
                delattr(st.session_state, 'quick_prompt')
            
            # ç”ŸæˆæŒ‰éˆ•
            generate_ready = (
                prompt.strip() and 
                api_configured and 
                (final_selected_model not in st.session_state.model_test_results or 
                 st.session_state.model_test_results[final_selected_model].get('available', True))
            )
            
            generate_btn = st.button(
                "ğŸš€ ç”Ÿæˆåœ–åƒ",
                type="primary",
                use_container_width=True,
                disabled=not generate_ready
            )
            
            # é¡¯ç¤ºç”Ÿæˆæº–å‚™ç‹€æ…‹
            if not generate_ready:
                if not prompt.strip():
                    st.warning("âš ï¸ è«‹è¼¸å…¥æç¤ºè©")
                elif not api_configured:
                    st.error("âŒ è«‹é…ç½® API å¯†é‘°")
                elif (final_selected_model in st.session_state.model_test_results and 
                      not st.session_state.model_test_results[final_selected_model].get('available', True)):
                    st.error("âŒ é¸ä¸­çš„æ¨¡å‹ä¸å¯ç”¨ï¼Œè«‹é¸æ“‡å…¶ä»–æ¨¡å‹æˆ–é‡æ–°æ¸¬è©¦")
        
        with col2:
            # æ¨¡å‹æ¨è–¦é¢æ¿
            if api_configured:
                show_model_recommendations()
            
            st.subheader("ğŸ“‹ ä½¿ç”¨èªªæ˜")
            st.markdown(f"""
            **ç•¶å‰æ¨¡å‹:** {FLUX_MODELS[final_selected_model]['name']}
            
            **Koyeb éƒ¨ç½²ç‰¹è‰²:**
            - ğŸš€ è‡ªå‹•ç¸®æ”¾å’Œ Scale-to-Zero
            - ğŸŒ å…¨çƒ CDN åŠ é€Ÿ
            - ğŸ“Š å¯¦æ™‚è³‡æºç›£æ§
            - ğŸ”’ å®‰å…¨çš„ API å¯†é‘°ç®¡ç†
            
            **å»ºè­°æµç¨‹:**
            1. æ¸¬è©¦æ¨¡å‹å¯ç”¨æ€§
            2. é¸æ“‡æ¨è–¦çš„æœ€ä½³æ¨¡å‹  
            3. è¼¸å…¥è©³ç´°æç¤ºè©
            4. èª¿æ•´ç”Ÿæˆè¨­å®š
            5. é–‹å§‹ç”Ÿæˆ
            """)
        
        # åœ–åƒç”Ÿæˆé‚è¼¯
        if generate_btn and generate_ready:
            config = st.session_state.api_config
            
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {FLUX_MODELS[final_selected_model]['name']} ç”Ÿæˆåœ–åƒ..."):
                generation_params = {
                    "model": final_selected_model,
                    "prompt": prompt,
                    "n": num_images,
                    "size": selected_size
                }
                
                success, result = generate_images_with_retry(
                    client, config['provider'], config['api_key'], 
                    config['base_url'], **generation_params
                )
                
                if success:
                    response = result
                    image_urls = [img.url for img in response.data]
                    
                    metadata = {
                        "size": selected_size,
                        "num_images": num_images,
                        "model_info": FLUX_MODELS[final_selected_model],
                        "api_provider": config['provider'],
                        "success": True,
                        "response_time": st.session_state.model_test_results.get(
                            final_selected_model, {}
                        ).get('response_time', 0)
                    }
                    
                    add_to_history(prompt, final_selected_model, image_urls, metadata)
                    st.success(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(response.data)} å¼µåœ–åƒï¼")
                    
                    # é¡¯ç¤ºåœ–åƒ
                    cols = st.columns(min(num_images, 2))
                    for i, image_data in enumerate(response.data):
                        with cols[i % len(cols)]:
                            st.subheader(f"åœ–åƒ {i+1}")
                            image_id = f"{len(st.session_state.generation_history)-1}_{i}"
                            display_image_with_actions(
                                image_data.url,
                                image_id,
                                st.session_state.generation_history[0]
                            )
                else:
                    st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {result}")
                    # æ›´æ–°æ¨¡å‹ç‹€æ…‹
                    if final_selected_model in st.session_state.model_test_results:
                        st.session_state.model_test_results[final_selected_model]['available'] = False
                        st.session_state.model_test_results[final_selected_model]['error'] = result

# æ¨¡å‹æ¸¬è©¦é é¢
with tab2:
    st.subheader("ğŸ§ª æ¨¡å‹å¯ç”¨æ€§æ¸¬è©¦")
    if not api_configured:
        st.warning("âš ï¸ è«‹å…ˆé…ç½® API å¯†é‘°")
        st.info("é…ç½®å®Œæˆå¾Œå³å¯æ¸¬è©¦æ¨¡å‹å¯ç”¨æ€§")
    else:
        show_model_status_dashboard()

# æ­·å²è¨˜éŒ„é é¢
with tab3:
    st.subheader("ğŸ“š ç”Ÿæˆæ­·å²")
    
    if st.session_state.generation_history:
        # æœç´¢å’Œç¯©é¸
        search_term = st.text_input("ğŸ” æœç´¢æç¤ºè©", placeholder="è¼¸å…¥é—œéµè©æœç´¢...")
        
        filtered_history = st.session_state.generation_history
        if search_term:
            filtered_history = [
                item for item in st.session_state.generation_history
                if search_term.lower() in item['prompt'].lower()
            ]
        
        st.write(f"é¡¯ç¤º {len(filtered_history)} æ¢è¨˜éŒ„")
        
        for item in filtered_history:
            with st.expander(f"ğŸ¨ {item['prompt'][:50]}... | {item['timestamp'].strftime('%m-%d %H:%M')}"):
                st.markdown(f"**æç¤ºè©**: {item['prompt']}")
                st.markdown(f"**æ¨¡å‹**: {FLUX_MODELS.get(item['model'], {}).get('name', item['model'])}")
                st.markdown(f"**ç”Ÿæˆæ™‚é–“**: {item['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                
                # é¡¯ç¤ºåœ–åƒ
                cols = st.columns(min(len(item['images']), 3))
                for i, img_url in enumerate(item['images']):
                    with cols[i % len(cols)]:
                        display_image_with_actions(img_url, f"history_{item['id']}_{i}", item)
    else:
        st.info("å°šç„¡ç”Ÿæˆæ­·å²")

# æ”¶è—å¤¾é é¢
with tab4:
    st.subheader("â­ æˆ‘çš„æ”¶è—")
    
    if st.session_state.favorite_images:
        cols = st.columns(3)
        for i, fav in enumerate(st.session_state.favorite_images):
            with cols[i % 3]:
                display_image_with_actions(fav['image_url'], fav['id'], fav.get('history_item'))
                if fav.get('history_item'):
                    st.caption(f"æç¤ºè©: {fav['history_item']['prompt'][:30]}...")
                st.caption(f"æ”¶è—æ™‚é–“: {fav['timestamp'].strftime('%m-%d %H:%M')}")
    else:
        st.info("å°šç„¡æ”¶è—åœ–åƒ")

# å¹«åŠ©é é¢
with tab5:
    st.subheader("ğŸ’¡ ä½¿ç”¨å¹«åŠ©")
    
    st.markdown("### ğŸš€ Koyeb éƒ¨ç½²å„ªå‹¢")
    st.markdown("""
    **Scale-to-Zero è‡ªå‹•ç¸®æ”¾:**
    - é–’ç½®æ™‚è‡ªå‹•ç¸®æ¸›åˆ°é›¶æˆæœ¬
    - æœ‰è«‹æ±‚æ™‚å¿«é€Ÿå•Ÿå‹• (200ms)
    - æ™ºèƒ½è² è¼‰å‡è¡¡

    **å…¨çƒéƒ¨ç½²:**
    - 50+ å€‹åœ°å€å¯é¸
    - è‡ªå‹• CDN åŠ é€Ÿ
    - å°±è¿‘ç”¨æˆ¶è¨ªå•

    **å®‰å…¨å¯é :**
    - è‡ªå‹• HTTPS/SSL
    - ç’°å¢ƒè®Šé‡åŠ å¯†
    - é«˜å¯ç”¨æ€§ä¿éšœ
    """)
    
    st.markdown("### ğŸ¯ æ¨¡å‹æ¸¬è©¦åŠŸèƒ½")
    st.markdown("""
    **æ¨¡å‹æ¸¬è©¦çš„é‡è¦æ€§:**
    - ğŸ” ç¢ºèªæ¨¡å‹æ˜¯å¦å¯ç”¨
    - âš¡ æ¸¬é‡éŸ¿æ‡‰æ™‚é–“
    - ğŸ¯ ç²å¾—æœ€ä½³æ¨¡å‹æ¨è–¦
    - ğŸ“Š è¿½è¹¤æ¨¡å‹ç‹€æ…‹è®ŠåŒ–

    **å¦‚ä½•ä½¿ç”¨:**
    1. é…ç½® API å¯†é‘°
    2. é»æ“Š "æ¸¬è©¦æ‰€æœ‰æ¨¡å‹"
    3. æŸ¥çœ‹æ¸¬è©¦çµæœ
    4. é¸æ“‡æ¨è–¦çš„æœ€ä½³æ¨¡å‹
    5. é–‹å§‹ç”Ÿæˆåœ–åƒ
    """)
    
    st.markdown("### ğŸ”§ æ•…éšœæ’é™¤")
    st.markdown("""
    **å¸¸è¦‹å•é¡Œ:**

    **æ¨¡å‹ä¸å¯ç”¨ (404 éŒ¯èª¤):**
    - æ¨¡å‹åç¨±å¯èƒ½ä¸æ­£ç¢º
    - API æä¾›å•†å¯èƒ½ä¸æ”¯æŒè©²æ¨¡å‹
    - æ¨¡å‹å¯èƒ½æš«æ™‚é›¢ç·š

    **æ¬Šé™éŒ¯èª¤ (401/403):**
    - æª¢æŸ¥ API å¯†é‘°æ˜¯å¦æ­£ç¢º
    - ç¢ºèªå¸³æˆ¶æ¬Šé™å’Œé¤˜é¡
    - æª¢æŸ¥ API ç«¯é»è¨­ç½®

    **Koyeb éƒ¨ç½²å•é¡Œ:**
    - æª¢æŸ¥ç’°å¢ƒè®Šé‡è¨­ç½®
    - ç¢ºèªç«¯å£é…ç½® (8000)
    - æŸ¥çœ‹æ‡‰ç”¨æ—¥èªŒæ’éŒ¯
    """)

# é è…³
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666;">
    ğŸš€ éƒ¨ç½²åœ¨ Koyeb | ğŸ¨ Powered by Flux AI | 
    âš¡ Scale-to-Zero è‡ªå‹•ç¸®æ”¾ | ğŸŒ å…¨çƒ CDN åŠ é€Ÿ
</div>
""", unsafe_allow_html=True)
