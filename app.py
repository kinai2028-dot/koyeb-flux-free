import streamlit as st
import requests
from PIL import Image
from io import BytesIO
import time
import os
import json
import base64
import psutil
from typing import Dict, Any, Optional

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Flux AI on Koyeb CPU",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Koyeb ä¼˜åŒ–çš„ CSS
st.markdown("""
<style>
.koyeb-header {
    background: linear-gradient(135deg, #2563eb 0%, #1d4ed8 50%, #1e40af 100%);
    padding: 2rem;
    border-radius: 15px;
    color: white;
    text-align: center;
    margin-bottom: 2rem;
    box-shadow: 0 8px 32px rgba(37, 99, 235, 0.3);
}

.resource-card {
    background: #f8fafc;
    padding: 1rem;
    border-radius: 10px;
    border-left: 4px solid #2563eb;
    margin: 1rem 0;
}

.api-status {
    padding: 0.5rem 1rem;
    border-radius: 20px;
    font-size: 0.8rem;
    font-weight: bold;
    margin: 0.25rem;
    display: inline-block;
}

.status-success { background: #dcfce7; color: #166534; }
.status-warning { background: #fef3c7; color: #92400e; }
.status-error { background: #fee2e2; color: #991b1b; }

.metrics-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
    gap: 1rem;
    margin: 1rem 0;
}
</style>
""", unsafe_allow_html=True)

# API æœåŠ¡é…ç½®
API_SERVICES = {
    "Black Forest Labs": {
        "endpoint": "https://api.bfl.ml/v1/flux-pro-1.1",
        "model": "flux-pro-1.1",
        "free_quota": "$1 å…è´¹é¢åº¦",
        "avg_time": "15-30ç§’",
        "quality": "æœ€é«˜å“è´¨",
        "cost_per_image": "$0.05"
    },
    "Hugging Face": {
        "endpoint": "https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-schnell",
        "model": "FLUX.1-schnell",
        "free_quota": "1000æ¬¡/æœˆ",
        "avg_time": "10-20ç§’", 
        "quality": "é«˜å“è´¨",
        "cost_per_image": "å…è´¹"
    },
    "Replicate": {
        "model": "black-forest-labs/flux-schnell",
        "free_quota": "$1 å…è´¹é¢åº¦",
        "avg_time": "20-40ç§’",
        "quality": "é«˜å“è´¨",
        "cost_per_image": "$0.003"
    },
    "Demo Mode": {
        "endpoint": "placeholder",
        "free_quota": "æ— é™åˆ¶",
        "avg_time": "å³æ—¶",
        "quality": "æ¼”ç¤ºå“è´¨",
        "cost_per_image": "$0.00"
    }
}

def get_system_metrics() -> Dict[str, Any]:
    """è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
    try:
        # CPU ä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_count = psutil.cpu_count()
        
        # å†…å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        memory_used_mb = memory.used / (1024**2)
        memory_total_mb = memory.total / (1024**2)
        memory_percent = memory.percent
        
        # ç£ç›˜ä¿¡æ¯
        disk = psutil.disk_usage('/')
        disk_used_gb = disk.used / (1024**3)
        disk_total_gb = disk.total / (1024**3)
        disk_percent = (disk.used / disk.total) * 100
        
        return {
            "cpu": {
                "percent": cpu_percent,
                "count": cpu_count
            },
            "memory": {
                "used_mb": memory_used_mb,
                "total_mb": memory_total_mb,
                "percent": memory_percent
            },
            "disk": {
                "used_gb": disk_used_gb,
                "total_gb": disk_total_gb,
                "percent": disk_percent
            }
        }
    except Exception as e:
        return {"error": str(e)}

def call_huggingface_api(prompt: str, token: str) -> Dict[str, Any]:
    """è°ƒç”¨ Hugging Face Inference API"""
    url = API_SERVICES["Hugging Face"]["endpoint"]
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "inputs": prompt,
        "parameters": {
            "guidance_scale": 0.0,
            "num_inference_steps": 4,
            "max_sequence_length": 512
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        
        if response.status_code == 200:
            return {
                "success": True,
                "data": response.content,
                "service": "Hugging Face",
                "model": "FLUX.1-schnell"
            }
        elif response.status_code == 503:
            return {
                "success": False, 
                "error": "æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•",
                "retry_after": 30
            }
        else:
            return {
                "success": False,
                "error": f"API é”™è¯¯ {response.status_code}: {response.text}"
            }
    except requests.exceptions.Timeout:
        return {"success": False, "error": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•"}
    except Exception as e:
        return {"success": False, "error": str(e)}

def call_replicate_api(prompt: str, token: str) -> Dict[str, Any]:
    """è°ƒç”¨ Replicate API"""
    try:
        import replicate
        
        # è®¾ç½® API token
        os.environ["REPLICATE_API_TOKEN"] = token
        
        output = replicate.run(
            API_SERVICES["Replicate"]["model"],
            input={
                "prompt": prompt,
                "num_outputs": 1,
                "aspect_ratio": "1:1",
                "output_format": "webp",
                "output_quality": 90
            }
        )
        
        # ä¸‹è½½å›¾åƒ
        if isinstance(output, list) and output:
            image_url = output[0]
        else:
            image_url = output
            
        response = requests.get(image_url, timeout=60)
        
        return {
            "success": True,
            "data": response.content,
            "service": "Replicate",
            "model": "flux-schnell"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

def call_bfl_api(prompt: str, token: str) -> Dict[str, Any]:
    """è°ƒç”¨ Black Forest Labs å®˜æ–¹ API"""
    url = "https://api.bfl.ml/v1/flux-pro-1.1"
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "prompt": prompt,
        "width": 1024,
        "height": 1024,
        "prompt_upsampling": False,
        "seed": None,
        "safety_tolerance": 2
    }
    
    try:
        # æäº¤ä»»åŠ¡
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            task_data = response.json()
            task_id = task_data["id"]
            
            # è½®è¯¢ç»“æœ
            result_url = f"https://api.bfl.ml/v1/get_result?id={task_id}"
            
            max_attempts = 60  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
            for attempt in range(max_attempts):
                time.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                
                result_response = requests.get(result_url, headers=headers, timeout=30)
                
                if result_response.status_code == 200:
                    result_data = result_response.json()
                    
                    if result_data["status"] == "Ready":
                        # ä¸‹è½½å›¾åƒ
                        image_url = result_data["result"]["sample"]
                        image_response = requests.get(image_url, timeout=60)
                        
                        return {
                            "success": True,
                            "data": image_response.content,
                            "service": "Black Forest Labs",
                            "model": "flux-pro-1.1"
                        }
                    elif result_data["status"] == "Error":
                        return {
                            "success": False,
                            "error": f"ç”Ÿæˆå¤±è´¥: {result_data.get('error', 'æœªçŸ¥é”™è¯¯')}"
                        }
            
            return {"success": False, "error": "ç”Ÿæˆè¶…æ—¶"}
        else:
            return {"success": False, "error": f"API é”™è¯¯: {response.status_code}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

def create_demo_image(prompt: str) -> Dict[str, Any]:
    """åˆ›å»ºæ¼”ç¤ºå›¾åƒ"""
    try:
        # åˆ›å»ºå¸¦æ–‡å­—çš„å ä½ç¬¦å›¾åƒ
        text = prompt[:30].replace(" ", "+")
        demo_url = f"https://via.placeholder.com/512x512/2563eb/ffffff?text=Demo:+{text}"
        
        response = requests.get(demo_url, timeout=15)
        
        if response.status_code == 200:
            return {
                "success": True,
                "data": response.content,
                "service": "Demo Mode",
                "model": "placeholder"
            }
        else:
            return {"success": False, "error": "æ— æ³•åˆ›å»ºæ¼”ç¤ºå›¾åƒ"}
    except Exception as e:
        return {"success": False, "error": str(e)}

def main():
    # ä¸»æ ‡é¢˜
    st.markdown("""
    <div class="koyeb-header">
        <h1>ğŸš€ Flux AI on Koyeb CPU</h1>
        <p>é«˜æ€§èƒ½ CPU å®ä¾‹ | è‡ªåŠ¨ç¼©æ”¾ | Scale-to-Zero</p>
        <div style="margin-top: 1rem; font-size: 0.9rem; opacity: 0.9;">
            æ”¯æŒå¤šç§ API æœåŠ¡ | å…è´¹é¢åº¦ä¼˜åŒ– | å…¨çƒéƒ¨ç½²
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯
    metrics = get_system_metrics()
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ Koyeb é…ç½®")
        
        # æ˜¾ç¤ºç³»ç»Ÿèµ„æº
        if "error" not in metrics:
            st.markdown(f"""
            <div class="resource-card">
                <h4>ğŸ“Š å®ä¾‹èµ„æº</h4>
                <div class="metrics-grid">
                    <div><strong>CPU:</strong> {metrics['cpu']['percent']:.1f}%</div>
                    <div><strong>å†…å­˜:</strong> {metrics['memory']['percent']:.1f}%</div>
                    <div><strong>ç£ç›˜:</strong> {metrics['disk']['percent']:.1f}%</div>
                </div>
                <div style="font-size: 0.8rem; color: #6b7280; margin-top: 0.5rem;">
                    RAM: {metrics['memory']['used_mb']:.0f}MB / {metrics['memory']['total_mb']:.0f}MB<br>
                    å­˜å‚¨: {metrics['disk']['used_gb']:.1f}GB / {metrics['disk']['total_gb']:.1f}GB
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        st.divider()
        
        # API æœåŠ¡é€‰æ‹©
        st.subheader("ğŸ”Œ API æœåŠ¡")
        
        selected_service = st.selectbox(
            "é€‰æ‹©ç”ŸæˆæœåŠ¡:",
            list(API_SERVICES.keys()),
            help="ä¸åŒæœåŠ¡æœ‰ä¸åŒçš„æˆæœ¬å’Œè´¨é‡ç‰¹ç‚¹"
        )
        
        # æ˜¾ç¤ºæœåŠ¡ä¿¡æ¯
        service_info = API_SERVICES[selected_service]
        
        # çŠ¶æ€æŒ‡ç¤ºå™¨
        status_class = "status-success" if selected_service == "Demo Mode" else "status-warning"
        
        st.markdown(f"""
        <div class="resource-card">
            <h4>{selected_service}</h4>
            <div class="api-status {status_class}">
                {service_info['free_quota']}
            </div>
            <div style="margin-top: 0.5rem; font-size: 0.9rem;">
                <strong>å“åº”æ—¶é—´:</strong> {service_info['avg_time']}<br>
                <strong>å›¾åƒè´¨é‡:</strong> {service_info['quality']}<br>
                <strong>å•å¼ æˆæœ¬:</strong> {service_info['cost_per_image']}
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # API Token è¾“å…¥
        if selected_service != "Demo Mode":
            api_token = st.text_input(
                f"{selected_service} API Token:",
                type="password",
                help="ä»å®˜æ–¹ç½‘ç«™è·å–å…è´¹ API Token",
                placeholder="è¾“å…¥æ‚¨çš„ API Token..."
            )
        else:
            api_token = None
        
        st.divider()
        
        # ç”Ÿæˆè®¾ç½®
        st.subheader("ğŸ¨ ç”Ÿæˆè®¾ç½®")
        
        # å›¾åƒå‚æ•°
        col1, col2 = st.columns(2)
        with col1:
            image_width = st.selectbox("å®½åº¦", [512, 768, 1024], index=2)
        with col2:
            image_height = st.selectbox("é«˜åº¦", [512, 768, 1024], index=2)
        
        image_quality = st.select_slider(
            "è´¨é‡çº§åˆ«:",
            ["å¿«é€Ÿ", "æ ‡å‡†", "é«˜è´¨é‡"],
            value="æ ‡å‡†"
        )
        
        # é«˜çº§é€‰é¡¹
        with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹"):
            enable_upscaling = st.checkbox("å¯ç”¨æç¤ºè¯ä¼˜åŒ–", value=True)
            safety_tolerance = st.slider("å®‰å…¨çº§åˆ«", 1, 5, 2)
            retry_failed = st.checkbox("å¤±è´¥è‡ªåŠ¨é‡è¯•", value=True)
        
        st.divider()
        
        # Koyeb ä¼˜åŠ¿è¯´æ˜
        st.subheader("ğŸš€ Koyeb ä¼˜åŠ¿")
        st.markdown("""
        **Scale-to-Zero:**
        - é—²ç½®æ—¶è‡ªåŠ¨ç¼©å‡åˆ°é›¶
        - è¯·æ±‚æ—¶å¿«é€Ÿå¯åŠ¨ (200ms)
        - å¤§å¹…é™ä½è¿è¡Œæˆæœ¬
        
        **å…¨çƒéƒ¨ç½²:**
        - 50+ ä¸ªåœ°åŒºå¯é€‰
        - è‡ªåŠ¨ CDN åŠ é€Ÿ
        - å°±è¿‘ç”¨æˆ·è®¿é—®
        
        **å¼€å‘å‹å¥½:**
        - Git é©±åŠ¨éƒ¨ç½²
        - è‡ªåŠ¨ HTTPS/SSL
        - å†…å»ºè´Ÿè½½å‡è¡¡
        """)
    
    # ä¸»ç•Œé¢
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ¨ AI å›¾åƒç”Ÿæˆ")
        
        # æç¤ºè¯è¾“å…¥åŒºåŸŸ
        prompt = st.text_area(
            "è¾“å…¥æç¤ºè¯ (æ”¯æŒä¸­è‹±æ–‡):",
            height=120,
            placeholder="ä¾‹å¦‚ï¼šA majestic dragon flying over ancient mountains during sunset, highly detailed, fantasy art style",
            help="è¯¦ç»†çš„æè¿°èƒ½è·å¾—æ›´å¥½çš„ç”Ÿæˆæ•ˆæœ"
        )
        
        # å¿«é€Ÿæç¤ºè¯æ¨¡æ¿
        st.subheader("ğŸ’¡ å¿«é€Ÿæ¨¡æ¿")
        
        template_categories = {
            "è‡ªç„¶é£æ™¯": [
                "A serene mountain landscape with crystal clear lake reflecting the sky",
                "Dense ancient forest with sunlight filtering through tall trees", 
                "Spectacular sunset over rolling hills with wildflowers"
            ],
            "è‰ºæœ¯åˆ›ä½œ": [
                "Abstract geometric composition with vibrant colors and flowing lines",
                "Minimalist design with clean shapes and negative space",
                "Surreal digital art with impossible architecture and floating elements"
            ],
            "ç§‘å¹»æœªæ¥": [
                "Futuristic cityscape with flying vehicles and neon-lit skyscrapers",
                "Advanced space station orbiting a distant planet with nebula background",
                "Cyberpunk street scene with holographic advertisements and rain"
            ],
            "äººç‰©è‚–åƒ": [
                "Professional headshot with soft natural lighting and neutral background",
                "Artistic portrait with dramatic lighting and creative composition",
                "Candid street photography style with urban background bokeh"
            ]
        }
        
        selected_category = st.selectbox("é€‰æ‹©ç±»åˆ«:", list(template_categories.keys()))
        selected_template = st.selectbox(
            "é€‰æ‹©å…·ä½“æ¨¡æ¿:",
            ["è‡ªå®šä¹‰"] + template_categories[selected_category]
        )
        
        if selected_template != "è‡ªå®šä¹‰":
            prompt = selected_template
        
        # æç¤ºè¯ä¼˜åŒ–å»ºè®®
        if prompt and enable_upscaling:
            quality_keywords = ", highly detailed, professional quality, 8k resolution"
            if quality_keywords not in prompt:
                optimized_prompt = prompt + quality_keywords
                with st.expander("ğŸ“ˆ ä¼˜åŒ–åçš„æç¤ºè¯"):
                    st.code(optimized_prompt)
                    if st.button("ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬"):
                        prompt = optimized_prompt
                        st.rerun()
        
        # ç”Ÿæˆæ§åˆ¶é¢æ¿
        col_gen1, col_gen2, col_gen3 = st.columns([2, 1, 1])
        
        with col_gen1:
            generate_btn = st.button(
                f"ğŸš€ ä½¿ç”¨ {selected_service} ç”Ÿæˆ",
                type="primary",
                use_container_width=True,
                disabled=not prompt.strip()
            )
        
        with col_gen2:
            if st.button("ğŸ² éšæœº", use_container_width=True):
                import random
                all_templates = [t for templates in template_categories.values() for t in templates]
                prompt = random.choice(all_templates)
                st.rerun()
        
        with col_gen3:
            est_cost = API_SERVICES[selected_service]['cost_per_image']
            st.metric("é¢„ä¼°æˆæœ¬", est_cost)
        
        # å›¾åƒç”Ÿæˆä¸»é€»è¾‘
        if generate_btn and prompt.strip():
            # éªŒè¯ API Token
            if selected_service != "Demo Mode" and not api_token:
                st.error(f"è¯·è¾“å…¥ {selected_service} çš„ API Token")
                st.info("ğŸ’¡ æ‚¨å¯ä»¥å…ˆä½¿ç”¨æ¼”ç¤ºæ¨¡å¼æµ‹è¯•åº”ç”¨åŠŸèƒ½")
            else:
                with st.spinner(f"ğŸ¨ ä½¿ç”¨ {selected_service} ç”Ÿæˆå›¾åƒä¸­..."):
                    # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
                    progress_placeholder = st.empty()
                    progress_placeholder.info(f"â³ é¢„è®¡ç­‰å¾…æ—¶é—´: {service_info['avg_time']}")
                    
                    start_time = time.time()
                    
                    # è°ƒç”¨ç›¸åº”çš„ API
                    try:
                        if selected_service == "Hugging Face":
                            result = call_huggingface_api(prompt, api_token)
                        elif selected_service == "Replicate":
                            result = call_replicate_api(prompt, api_token)
                        elif selected_service == "Black Forest Labs":
                            result = call_bfl_api(prompt, api_token)
                        else:  # Demo Mode
                            result = create_demo_image(prompt)
                        
                        generation_time = time.time() - start_time
                        progress_placeholder.empty()
                        
                        if result["success"]:
                            st.success(f"âœ… ç”ŸæˆæˆåŠŸï¼è€—æ—¶: {generation_time:.1f}ç§’")
                            
                            # å¤„ç†å›¾åƒæ•°æ®
                            try:
                                image = Image.open(BytesIO(result["data"]))
                                
                                # æ˜¾ç¤ºå›¾åƒ
                                st.image(
                                    image,
                                    caption=f"ğŸ¨ {prompt} | æœåŠ¡: {result['service']} | æ¨¡å‹: {result['model']}",
                                    use_column_width=True
                                )
                                
                                # å›¾åƒä¿¡æ¯
                                col_info1, col_info2, col_info3 = st.columns(3)
                                with col_info1:
                                    st.metric("å›¾åƒå°ºå¯¸", f"{image.width}Ã—{image.height}")
                                with col_info2:
                                    st.metric("æ–‡ä»¶æ ¼å¼", image.format or "PNG")
                                with col_info3:
                                    file_size = len(result["data"]) / 1024
                                    st.metric("æ–‡ä»¶å¤§å°", f"{file_size:.1f}KB")
                                
                                # ä¸‹è½½é€‰é¡¹
                                col_dl1, col_dl2 = st.columns(2)
                                
                                with col_dl1:
                                    # PNG ä¸‹è½½
                                    png_buffer = BytesIO()
                                    image.save(png_buffer, format="PNG", optimize=True)
                                    st.download_button(
                                        "ğŸ“¥ ä¸‹è½½ PNG",
                                        data=png_buffer.getvalue(),
                                        file_name=f"flux_{int(time.time())}.png",
                                        mime="image/png",
                                        use_container_width=True
                                    )
                                
                                with col_dl2:
                                    # JPEG ä¸‹è½½ (æ›´å°æ–‡ä»¶)
                                    jpeg_buffer = BytesIO()
                                    rgb_image = image.convert("RGB")
                                    rgb_image.save(jpeg_buffer, format="JPEG", quality=90, optimize=True)
                                    st.download_button(
                                        "ğŸ“¥ ä¸‹è½½ JPEG",
                                        data=jpeg_buffer.getvalue(),
                                        file_name=f"flux_{int(time.time())}.jpg",
                                        mime="image/jpeg",
                                        use_container_width=True
                                    )
                                
                                # ä¿å­˜åˆ°ä¼šè¯å†å²
                                if 'generation_history' not in st.session_state:
                                    st.session_state.generation_history = []
                                
                                st.session_state.generation_history.append({
                                    'prompt': prompt,
                                    'service': result['service'],
                                    'model': result['model'],
                                    'timestamp': time.strftime('%H:%M:%S'),
                                    'generation_time': f"{generation_time:.1f}s",
                                    'cost': API_SERVICES[selected_service]['cost_per_image']
                                })
                                
                                # é™åˆ¶å†å²è®°å½•æ•°é‡
                                if len(st.session_state.generation_history) > 10:
                                    st.session_state.generation_history.pop(0)
                            
                            except Exception as img_error:
                                st.error(f"âŒ å›¾åƒå¤„ç†å¤±è´¥: {img_error}")
                        
                        else:
                            st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {result['error']}")
                            
                            # è‡ªåŠ¨é‡è¯•é€»è¾‘
                            if retry_failed and "retry_after" in result:
                                st.info(f"ğŸ”„ å°†åœ¨ {result['retry_after']} ç§’åè‡ªåŠ¨é‡è¯•...")
                                time.sleep(result['retry_after'])
                                st.rerun()
                            
                            # é”™è¯¯è§£å†³å»ºè®®
                            st.info("""
                            **å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:**
                            - æ£€æŸ¥ API Token æ˜¯å¦æ­£ç¡®ä¸”æœ‰æ•ˆ
                            - å°è¯•åˆ‡æ¢åˆ°å…¶ä»– API æœåŠ¡
                            - ç®€åŒ–æç¤ºè¯å†…å®¹
                            - ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼æµ‹è¯•åŠŸèƒ½
                            """)
                    
                    except Exception as e:
                        progress_placeholder.empty()
                        st.error(f"âŒ è¯·æ±‚å¤„ç†å¼‚å¸¸: {str(e)}")
    
    with col2:
        st.subheader("ğŸ“Š å®æ—¶çŠ¶æ€")
        
        # å½“å‰ç³»ç»ŸçŠ¶æ€
        if "error" not in metrics:
            st.markdown(f"""
            **ğŸ–¥ï¸ CPU ä½¿ç”¨ç‡**
            ```
            {metrics['cpu']['percent']:.1f}% ({metrics['cpu']['count']} æ ¸å¿ƒ)
            ```
            
            **ğŸ’¾ å†…å­˜ä½¿ç”¨**
            ```
            {metrics['memory']['used_mb']:.0f}MB / {metrics['memory']['total_mb']:.0f}MB
            ({metrics['memory']['percent']:.1f}%)
            ```
            
            **ğŸ’¿ ç£ç›˜ä½¿ç”¨**
            ```
            {metrics['disk']['used_gb']:.1f}GB / {metrics['disk']['total_gb']:.1f}GB
            ({metrics['disk']['percent']:.1f}%)
            ```
            """)
        
        # API æœåŠ¡çŠ¶æ€
        st.subheader("ğŸŒ API æœåŠ¡çŠ¶æ€")
        for service_name, info in API_SERVICES.items():
            if service_name == selected_service:
                status_indicator = "ğŸŸ¢ å½“å‰ä½¿ç”¨"
            elif service_name == "Demo Mode":
                status_indicator = "ğŸŸ¢ å§‹ç»ˆå¯ç”¨"
            else:
                status_indicator = "ğŸŸ¡ éœ€è¦ Token"
            
            st.write(f"**{service_name}**: {status_indicator}")
        
        # ç”Ÿæˆå†å²
        if 'generation_history' in st.session_state and st.session_state.generation_history:
            st.subheader("ğŸ“š ç”Ÿæˆå†å²")
            
            for i, record in enumerate(reversed(st.session_state.generation_history[-5:])):
                with st.expander(f"è®°å½• {i+1} - {record['timestamp']}"):
                    st.write(f"**æç¤ºè¯**: {record['prompt'][:50]}...")
                    st.write(f"**æœåŠ¡**: {record['service']}")
                    st.write(f"**è€—æ—¶**: {record['generation_time']}")
                    st.write(f"**æˆæœ¬**: {record['cost']}")
            
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²"):
                st.session_state.generation_history = []
                st.rerun()
        
        # ä½¿ç”¨ç»Ÿè®¡
        st.subheader("ğŸ“ˆ ä½¿ç”¨ç»Ÿè®¡")
        total_generations = len(st.session_state.get('generation_history', []))
        st.metric("æ€»ç”Ÿæˆæ¬¡æ•°", total_generations)
        
        if total_generations > 0:
            avg_time = sum(float(r['generation_time'].replace('s', '')) 
                          for r in st.session_state.generation_history) / total_generations
            st.metric("å¹³å‡è€—æ—¶", f"{avg_time:.1f}s")
        
        # éƒ¨ç½²ä¿¡æ¯
        st.subheader("ğŸš€ éƒ¨ç½²ä¿¡æ¯")
        st.info(f"""
        **å¹³å°**: Koyeb CPU å®ä¾‹
        **åŒºåŸŸ**: è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜
        **ç¼©æ”¾**: Scale-to-Zero å·²å¯ç”¨
        **SSL**: è‡ªåŠ¨é…ç½®
        **çŠ¶æ€**: âœ… è¿è¡Œæ­£å¸¸
        """)

if __name__ == "__main__":
    main()
