import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Optional, Tuple
import time
import random
import json
import sqlite3
import uuid
import zipfile
import psutil
import os
import re
from urllib.parse import urlencode, quote

# å…¼å®¹æ€§å‡½æ•¸
def rerun_app():
    """å…¼å®¹ä¸åŒ Streamlit ç‰ˆæœ¬çš„é‡æ–°é‹è¡Œå‡½æ•¸"""
    if hasattr(st, 'rerun'):
        st.rerun()
    elif hasattr(st, 'experimental_rerun'):
        st.experimental_rerun()
    else:
        st.stop()

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="Flux AI åœ–åƒç”Ÿæˆå™¨ Pro - å®Œæ•´ç‰ˆ",
    page_icon="ğŸ¨",
    layout="wide"
)

# API æä¾›å•†é…ç½®
API_PROVIDERS = {
    "OpenAI Compatible": {
        "name": "OpenAI Compatible API",
        "base_url_default": "https://api.openai.com/v1",
        "key_prefix": "sk-",
        "description": "OpenAI å®˜æ–¹æˆ–å…¼å®¹çš„ API æœå‹™",
        "icon": "ğŸ¤–"
    },
    "Navy": {
        "name": "Navy API",
        "base_url_default": "https://api.navy/v1",
        "key_prefix": "sk-",
        "description": "Navy æä¾›çš„ AI åœ–åƒç”Ÿæˆæœå‹™",
        "icon": "âš“"
    },
    "Pollinations.ai": {
        "name": "Pollinations.ai",
        "base_url_default": "https://image.pollinations.ai",
        "key_prefix": "",
        "description": "æ”¯æ´å…è²»å’Œèªè­‰æ¨¡å¼çš„åœ–åƒç”Ÿæˆ API",
        "icon": "ğŸŒ¸",
        "auth_modes": ["free", "referrer", "token"]
    },
    "Hugging Face": {
        "name": "Hugging Face Inference",
        "base_url_default": "https://api-inference.huggingface.co",
        "key_prefix": "hf_",
        "description": "Hugging Face Inference API",
        "icon": "ğŸ¤—"
    },
    "Together AI": {
        "name": "Together AI",
        "base_url_default": "https://api.together.xyz/v1",
        "key_prefix": "",
        "description": "Together AI å¹³å°",
        "icon": "ğŸ¤"
    },
    "Fireworks AI": {
        "name": "Fireworks AI",
        "base_url_default": "https://api.fireworks.ai/inference/v1",
        "key_prefix": "",
        "description": "Fireworks AI å¿«é€Ÿæ¨ç†",
        "icon": "ğŸ†"
    },
    "Custom": {
        "name": "è‡ªå®šç¾© API",
        "base_url_default": "",
        "key_prefix": "",
        "description": "è‡ªå®šç¾©çš„ API ç«¯é»",
        "icon": "ğŸ”§"
    }
}

# åŸºç¤ Flux æ¨¡å‹é…ç½®
BASE_FLUX_MODELS = {
    "flux.1-schnell": {
        "name": "FLUX.1 Schnell",
        "description": "æœ€å¿«çš„ç”Ÿæˆé€Ÿåº¦ï¼Œé–‹æºæ¨¡å‹",
        "icon": "âš¡",
        "type": "å¿«é€Ÿç”Ÿæˆ",
        "test_prompt": "A simple cat sitting on a table",
        "expected_size": "1024x1024",
        "priority": 1,
        "source": "base",
        "auth_required": False
    },
    "flux.1-dev": {
        "name": "FLUX.1 Dev",
        "description": "é–‹ç™¼ç‰ˆæœ¬ï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡è³ªé‡",
        "icon": "ğŸ”§",
        "type": "é–‹ç™¼ç‰ˆæœ¬",
        "test_prompt": "A beautiful landscape with mountains",
        "expected_size": "1024x1024",
        "priority": 2,
        "source": "base",
        "auth_required": False
    },
    "flux.1.1-pro": {
        "name": "FLUX.1.1 Pro",
        "description": "æ”¹é€²çš„æ——è‰¦æ¨¡å‹ï¼Œæœ€ä½³å“è³ª",
        "icon": "ğŸ‘‘",
        "type": "æ——è‰¦ç‰ˆæœ¬",
        "test_prompt": "Professional portrait of a person in business attire",
        "expected_size": "1024x1024",
        "priority": 3,
        "source": "base",
        "auth_required": False
    },
    "flux.1-kontext-pro": {
        "name": "FLUX.1 Kontext Pro",
        "description": "æ”¯æŒåœ–åƒç·¨è¼¯å’Œä¸Šä¸‹æ–‡ç†è§£ï¼ˆéœ€èªè­‰ï¼‰",
        "icon": "ğŸ¯",
        "type": "ç·¨è¼¯å°ˆç”¨",
        "test_prompt": "Abstract geometric shapes in vibrant colors",
        "expected_size": "1024x1024",
        "priority": 4,
        "source": "base",
        "auth_required": True
    }
}

# æ¨¡å‹è‡ªå‹•ç™¼ç¾è¦å‰‡
FLUX_MODEL_PATTERNS = {
    r'flux[\.\-]?1[\.\-]?schnell': {
        "name_template": "FLUX.1 Schnell",
        "icon": "âš¡",
        "type": "å¿«é€Ÿç”Ÿæˆ",
        "priority_base": 100,
        "auth_required": False
    },
    r'flux[\.\-]?1[\.\-]?dev': {
        "name_template": "FLUX.1 Dev",
        "icon": "ğŸ”§",
        "type": "é–‹ç™¼ç‰ˆæœ¬",
        "priority_base": 200,
        "auth_required": False
    },
    r'flux[\.\-]?1[\.\-]?pro': {
        "name_template": "FLUX.1 Pro",
        "icon": "ğŸ‘‘",
        "type": "å°ˆæ¥­ç‰ˆæœ¬",
        "priority_base": 300,
        "auth_required": False
    },
    r'flux[\.\-]?1[\.\-]?kontext|kontext': {
        "name_template": "FLUX.1 Kontext",
        "icon": "ğŸ¯",
        "type": "ä¸Šä¸‹æ–‡ç†è§£",
        "priority_base": 400,
        "auth_required": True
    }
}

# æä¾›å•†ç‰¹å®šçš„æ¨¡å‹ç«¯é»
HF_FLUX_ENDPOINTS = [
    "black-forest-labs/FLUX.1-schnell",
    "black-forest-labs/FLUX.1-dev",
    "black-forest-labs/FLUX.1.1-pro",
]

def auto_discover_flux_models(client, provider: str, api_key: str, base_url: str) -> Dict[str, Dict]:
    """è‡ªå‹•ç™¼ç¾æ¨¡å‹ï¼Œç¾å·²æ”¯æŒ Pollinations.ai"""
    discovered_models = {}
    
    try:
        if provider == "Pollinations.ai":
            models_url = f"{base_url}/models"
            response = requests.get(models_url, timeout=10)
            if response.status_code == 200:
                models_list = response.json()
                for model_name in models_list:
                    model_id = model_name
                    model_info = analyze_model_name(model_id)
                    model_info['source'] = 'pollinations'
                    model_info['type'] = 'åœ–åƒå°ˆç”¨'
                    model_info['icon'] = 'ğŸŒ¸'
                    discovered_models[model_id] = model_info
            else:
                st.warning(f"ç„¡æ³•å¾ Pollinations.ai ç²å–æ¨¡å‹åˆ—è¡¨ (HTTP {response.status_code})")

        elif provider == "Hugging Face":
            for endpoint in HF_FLUX_ENDPOINTS:
                model_id = endpoint.split('/')[-1]
                model_info = analyze_model_name(model_id, endpoint)
                model_info['source'] = 'huggingface'
                model_info['endpoint'] = endpoint
                discovered_models[model_id] = model_info
        else:
            response = client.models.list()
            for model in response.data:
                model_id = model.id
                # é™åˆ¶åªé¡¯ç¤ºåŒ…å« 'flux' çš„åœ–åƒæ¨¡å‹
                if is_flux_model(model_id):
                    model_info = analyze_model_name(model.id)
                    model_info['source'] = 'api_discovery'
                    discovered_models[model.id] = model_info

        return discovered_models
    except Exception as e:
        st.warning(f"æ¨¡å‹è‡ªå‹•ç™¼ç¾å¤±æ•—: {str(e)}")
        return {}

def is_flux_model(model_name: str) -> bool:
    """æª¢æŸ¥æ¨¡å‹åç¨±æ˜¯å¦ç‚º Flux æ¨¡å‹"""
    model_lower = model_name.lower()
    flux_keywords = ['flux', 'black-forest-labs', 'kontext']
    return any(keyword in model_lower for keyword in flux_keywords)

def analyze_model_name(model_id: str, full_path: str = None) -> Dict:
    """åˆ†ææ¨¡å‹åç¨±ä¸¦ç”Ÿæˆæ¨¡å‹ä¿¡æ¯"""
    model_lower = model_id.lower()
    
    for pattern, info in FLUX_MODEL_PATTERNS.items():
        if re.search(pattern, model_lower):
            analyzed_info = {
                "name": info["name_template"],
                "icon": info["icon"],
                "type": info["type"],
                "description": f"è‡ªå‹•ç™¼ç¾çš„ {info['name_template']} æ¨¡å‹",
                "test_prompt": "A beautiful scene with detailed elements",
                "expected_size": "1024x1024",
                "priority": info["priority_base"] + hash(model_id) % 100,
                "auto_discovered": True,
                "auth_required": info.get("auth_required", False)
            }
            
            if full_path:
                analyzed_info["full_path"] = full_path
                if '/' in full_path:
                    author = full_path.split('/')[0]
                    analyzed_info["name"] += f" ({author})"
            
            return analyzed_info
    
    return {
        "name": model_id.replace('-', ' ').replace('_', ' ').title(),
        "icon": "ğŸ¤–",
        "type": "è‡ªå‹•ç™¼ç¾",
        "description": f"è‡ªå‹•ç™¼ç¾çš„æ¨¡å‹: {model_id}",
        "test_prompt": "A detailed and beautiful image",
        "expected_size": "1024x1024",
        "priority": 999,
        "auto_discovered": True,
        "auth_required": 'kontext' in model_id.lower(),
        "full_path": full_path if full_path else model_id
    }

def merge_models() -> Dict[str, Dict]:
    """åˆä½µåŸºç¤æ¨¡å‹å’Œè‡ªå‹•ç™¼ç¾çš„æ¨¡å‹"""
    discovered = st.session_state.get('discovered_models', {})
    merged_models = BASE_FLUX_MODELS.copy()
    
    for model_id, model_info in discovered.items():
        if model_id not in merged_models:
            merged_models[model_id] = model_info
            
    # æŒ‰ 'priority' æ’åº
    sorted_models = sorted(merged_models.items(), key=lambda item: item[1].get('priority', 999))
    return dict(sorted_models)


def validate_api_key(api_key: str, base_url: str, provider: str) -> Tuple[bool, str]:
    """é©—è­‰ API å¯†é‘°æ˜¯å¦æœ‰æ•ˆï¼Œæ–°å¢ Pollinations.ai é©—è­‰"""
    try:
        if provider == "Pollinations.ai":
            test_url = f"{base_url}/models"
            response = requests.get(test_url, timeout=10)
            if response.status_code == 200:
                return True, "Pollinations.ai æœå‹™é€£æ¥æˆåŠŸ"
            else:
                return False, f"HTTP {response.status_code}: Pollinations.ai é€£æ¥å¤±æ•—"

        elif provider == "Hugging Face":
            headers = {"Authorization": f"Bearer {api_key}"}
            test_url = f"{base_url}/models/black-forest-labs/FLUX.1-schnell"
            response = requests.get(test_url, headers=headers, timeout=10)
            if response.status_code == 200:
                return True, "Hugging Face API å¯†é‘°é©—è­‰æˆåŠŸ"
            else:
                return False, f"HTTP {response.status_code}: é©—è­‰å¤±æ•—"
        else:
            test_client = OpenAI(api_key=api_key, base_url=base_url)
            response = test_client.models.list()
            return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "Unauthorized" in error_msg:
            return False, "API å¯†é‘°ç„¡æ•ˆæˆ–å·²éæœŸ"
        elif "403" in error_msg or "Forbidden" in error_msg:
            return False, "API å¯†é‘°æ²’æœ‰è¶³å¤ æ¬Šé™"
        elif "404" in error_msg:
            return False, "API ç«¯é»ä¸å­˜åœ¨æˆ–ä¸æ­£ç¢º"
        elif "timeout" in error_msg.lower():
            return False, "API é€£æ¥è¶…æ™‚"
        else:
            return False, f"API é©—è­‰å¤±æ•—: {error_msg[:100]}"

def test_model_availability(client, model_name: str, provider: str, api_key: str, base_url: str, test_prompt: str = None) -> Dict:
    """æ¸¬è©¦ç‰¹å®šæ¨¡å‹çš„å¯ç”¨æ€§"""
    all_models = merge_models()
    if test_prompt is None:
        test_prompt = all_models.get(model_name, {}).get('test_prompt', 'A simple test image')
    
    test_result = {
        'model': model_name,
        'available': False,
        'response_time': 0,
        'error': None,
        'details': {}
    }
    
    try:
        start_time = time.time()
        
        if provider == "Hugging Face":
            headers = {"Authorization": f"Bearer {api_key}"}
            data = {"inputs": test_prompt}
            
            model_info = all_models.get(model_name, {})
            endpoint_path = model_info.get('full_path', f"black-forest-labs/{model_name}")
            
            response = requests.post(
                f"{base_url}/models/{endpoint_path}",
                headers=headers,
                json=data,
                timeout=30
            )
            end_time = time.time()
            response_time = end_time - start_time
            
            if response.status_code == 200:
                test_result.update({
                    'available': True,
                    'response_time': response_time,
                    'details': {
                        'status_code': response.status_code,
                        'test_prompt': test_prompt,
                        'endpoint': endpoint_path
                    }
                })
            else:
                test_result.update({
                    'available': False,
                    'error': f"HTTP {response.status_code}",
                    'details': {'status_code': response.status_code}
                })
        else:
            response = client.images.generate(
                model=model_name,
                prompt=test_prompt,
                n=1,
                size="1024x1024"
            )
            end_time = time.time()
            response_time = end_time - start_time
            
            test_result.update({
                'available': True,
                'response_time': response_time,
                'details': {
                    'image_count': len(response.data),
                    'test_prompt': test_prompt,
                    'image_url': response.data[0].url if response.data else None
                }
            })
            
    except Exception as e:
        error_msg = str(e)
        test_result.update({
            'available': False,
            'error': error_msg,
            'details': {
                'error_type': 'generation_failed',
                'test_prompt': test_prompt
            }
        })
    
    return test_result

def generate_images_with_retry(client, provider: str, api_key: str, base_url: str, **params) -> Tuple[bool, any]:
    """å¸¶é‡è©¦æ©Ÿåˆ¶çš„åœ–åƒç”Ÿæˆï¼Œæ”¯æ´ Pollinations.ai èªè­‰"""
    max_retries = 3
    base_delay = 2
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                st.info(f"ğŸ”„ å˜—è©¦é‡æ–°ç”Ÿæˆ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡)")

            if provider == "Pollinations.ai":
                # Pollinations.ai GET è«‹æ±‚
                prompt = params.get("prompt", "")
                width, height = params.get("size", "1024x1024").split('x')
                
                query_params = {
                    "model": params.get("model"),
                    "width": width,
                    "height": height,
                    "seed": random.randint(0, 1000000),
                    "nologo": "true"
                }
                
                # æ¸…ç† None å€¼
                query_params = {k: v for k, v in query_params.items() if v is not None}
                
                # è™•ç†èªè­‰
                headers = {}
                config = st.session_state.get('api_config', {})
                auth_mode = config.get('pollinations_auth_mode', 'free')
                
                if auth_mode == 'token' and config.get('pollinations_token'):
                    headers['Authorization'] = f"Bearer {config['pollinations_token']}"
                elif auth_mode == 'referrer' and config.get('pollinations_referrer'):
                    headers['Referer'] = config['pollinations_referrer']
                
                encoded_prompt = quote(prompt)
                request_url = f"{base_url}/prompt/{encoded_prompt}?{urlencode(query_params)}"
                
                response = requests.get(request_url, headers=headers, timeout=120)

                if response.status_code == 200:
                    # æ¨¡æ“¬ OpenAI éŸ¿æ‡‰æ ¼å¼
                    class MockResponse:
                        def __init__(self, image_data):
                            self.data = [type('obj', (object,), {
                                'url': f"data:image/png;base64,{base64.b64encode(image_data).decode()}"
                            })()]
                    
                    return True, MockResponse(response.content)
                else:
                    error_text = response.text
                    if "Access to" in error_text and "is limited" in error_text:
                        return False, f"æ­¤æ¨¡å‹éœ€è¦èªè­‰ã€‚è«‹åœ¨å´é‚Šæ¬„é…ç½® Pollinations.ai èªè­‰ä¿¡æ¯ã€‚éŒ¯èª¤: {error_text}"
                    raise Exception(f"HTTP {response.status_code}: {error_text}")
            
            elif provider == "Hugging Face":
                # Hugging Face API èª¿ç”¨
                headers = {"Authorization": f"Bearer {api_key}"}
                data = {"inputs": params.get("prompt", "")}
                
                model_name = params.get("model", "FLUX.1-schnell")
                all_models = merge_models()
                model_info = all_models.get(model_name, {})
                endpoint_path = model_info.get('full_path', f"black-forest-labs/{model_name}")
                
                response = requests.post(
                    f"{base_url}/models/{endpoint_path}",
                    headers=headers,
                    json=data,
                    timeout=60
                )
                
                if response.status_code == 200:
                    # æ¨¡æ“¬ OpenAI éŸ¿æ‡‰æ ¼å¼
                    class MockResponse:
                        def __init__(self, image_data):
                            self.data = [type('obj', (object,), {
                                'url': f"data:image/png;base64,{base64.b64encode(image_data).decode()}"
                            })()]
                    
                    return True, MockResponse(response.content)
                else:
                    raise Exception(f"HTTP {response.status_code}: {response.text}")
            else:
                # OpenAI Compatible API èª¿ç”¨
                response = client.images.generate(**params)
                return True, response
            
        except Exception as e:
            error_msg = str(e)
            if attempt < max_retries - 1:
                should_retry = False
                if any(code in error_msg for code in ["500", "502", "503", "429"]):
                    should_retry = True
                elif "timeout" in error_msg.lower():
                    should_retry = True
                
                if should_retry:
                    delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                    st.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å˜—è©¦å¤±æ•—ï¼Œ{delay:.1f} ç§’å¾Œé‡è©¦...")
                    time.sleep(delay)
                    continue
                else:
                    return False, error_msg
            else:
                return False, error_msg
    
    return False, "æ‰€æœ‰é‡è©¦å‡å¤±æ•—"

def init_session_state():
    """åˆå§‹åŒ–æœƒè©±ç‹€æ…‹"""
    if 'api_config' not in st.session_state:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False,
            'pollinations_auth_mode': 'free',
            'pollinations_token': '',
            'pollinations_referrer': ''
        }
    
    if 'generation_history' not in st.session_state:
        st.session_state.generation_history = []
    
    if 'favorite_images' not in st.session_state:
        st.session_state.favorite_images = []
    
    if 'model_test_results' not in st.session_state:
        st.session_state.model_test_results = {}
    
    if 'discovered_models' not in st.session_state:
        st.session_state.discovered_models = {}
    
    # æ–°å¢ï¼šåˆå§‹åŒ–æ¨¡å‹æ›´æ–°æ¨™èªŒ
    if 'models_updated' not in st.session_state:
        st.session_state.models_updated = False

def add_to_history(prompt: str, model: str, images: List[str], metadata: Dict):
    """æ·»åŠ ç”Ÿæˆè¨˜éŒ„åˆ°æ­·å²"""
    history_item = {
        "timestamp": datetime.datetime.now(),
        "prompt": prompt,
        "model": model,
        "images": images,
        "metadata": metadata,
        "id": str(uuid.uuid4())
    }
    st.session_state.generation_history.insert(0, history_item)
    
    # é™åˆ¶æ­·å²è¨˜éŒ„æ•¸é‡
    if len(st.session_state.generation_history) > 50:
        st.session_state.generation_history = st.session_state.generation_history[:50]

def display_image_with_actions(image_url: str, image_id: str, history_item: Dict = None):
    """é¡¯ç¤ºåœ–åƒå’Œç›¸é—œæ“ä½œ"""
    try:
        # è™•ç† base64 åœ–åƒ
        if image_url.startswith('data:image'):
            base64_data = image_url.split(',')[1]
            img_data = base64.b64decode(base64_data)
            img = Image.open(BytesIO(img_data))
        else:
            img_response = requests.get(image_url, timeout=10)
            img = Image.open(BytesIO(img_response.content))
            img_data = img_response.content
        
        st.image(img, use_column_width=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            img_buffer = BytesIO()
            img.save(img_buffer, format='PNG')
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰",
                data=img_buffer.getvalue(),
                file_name=f"flux_generated_{image_id}.png",
                mime="image/png",
                key=f"download_{image_id}",
                use_container_width=True
            )
        
        with col2:
            is_favorite = any(fav['id'] == image_id for fav in st.session_state.favorite_images)
            if st.button(
                "â­ å·²æ”¶è—" if is_favorite else "â˜† æ”¶è—",
                key=f"favorite_{image_id}",
                use_container_width=True
            ):
                if is_favorite:
                    st.session_state.favorite_images = [
                        fav for fav in st.session_state.favorite_images if fav['id'] != image_id
                    ]
                    st.success("å·²å–æ¶ˆæ”¶è—")
                else:
                    favorite_item = {
                        "id": image_id,
                        "image_url": image_url,
                        "timestamp": datetime.datetime.now(),
                        "history_item": history_item
                    }
                    st.session_state.favorite_images.append(favorite_item)
                    st.success("å·²åŠ å…¥æ”¶è—")
                rerun_app()
        
        with col3:
            if history_item and st.button(
                "ğŸ”„ é‡æ–°ç”Ÿæˆ",
                key=f"regenerate_{image_id}",
                use_container_width=True
            ):
                st.session_state.regenerate_prompt = history_item['prompt']
                st.session_state.regenerate_model = history_item['model']
                rerun_app()
    
    except Exception as e:
        st.error(f"åœ–åƒé¡¯ç¤ºéŒ¯èª¤: {str(e)}")

def init_api_client():
    """åˆå§‹åŒ– API å®¢æˆ¶ç«¯"""
    config = st.session_state.api_config
    if config.get('provider') in ["Hugging Face", "Pollinations.ai"]:
        return None
    if config.get('api_key'):
        try:
            return OpenAI(
                api_key=config['api_key'],
                base_url=config['base_url']
            )
        except Exception:
            return None
    return None

def show_api_settings():
    """é¡¯ç¤º API è¨­ç½®ç•Œé¢"""
    st.subheader("ğŸ”‘ API è¨­ç½®")
    
    provider_options = list(API_PROVIDERS.keys())
    current_provider = st.session_state.api_config.get('provider', 'Navy')
    
    # ç¢ºä¿ç•¶å‰ provider åœ¨é¸é …ä¸­
    provider_index = provider_options.index(current_provider) if current_provider in provider_options else 0
    
    selected_provider = st.selectbox(
        "é¸æ“‡ API æä¾›å•†",
        options=provider_options,
        index=provider_index,
        format_func=lambda x: f"{API_PROVIDERS[x]['icon']} {API_PROVIDERS[x]['name']}"
    )
    
    provider_info = API_PROVIDERS[selected_provider]
    st.info(f"ğŸ“‹ {provider_info['description']}")
    
    # Pollinations.ai ç‰¹æ®Šèªè­‰è¨­ç½®
    if selected_provider == "Pollinations.ai":
        st.markdown("### ğŸŒ¸ Pollinations.ai èªè­‰è¨­ç½®")
        
        auth_mode = st.radio(
            "é¸æ“‡èªè­‰æ¨¡å¼",
            options=["free", "referrer", "token"],
            format_func=lambda x: {
                "free": "ğŸ†“ å…è²»æ¨¡å¼ï¼ˆåŸºç¤æ¨¡å‹ï¼‰",
                "referrer": "ğŸŒ åŸŸåèªè­‰ï¼ˆæ¨è–¦ï¼‰", 
                "token": "ğŸ”‘ Token èªè­‰ï¼ˆé«˜ç´šï¼‰"
            }[x],
            index=["free", "referrer", "token"].index(
                st.session_state.api_config.get('pollinations_auth_mode', 'free')
            )
        )
        
        if auth_mode == "referrer":
            st.info("è¼¸å…¥æ‚¨çš„æ‡‰ç”¨åŸŸåä»¥å­˜å–æ›´å¤šæ¨¡å‹ï¼ˆå¦‚ kontextï¼‰")
            referrer_input = st.text_input(
                "æ‡‰ç”¨åŸŸå",
                value=st.session_state.api_config.get('pollinations_referrer', ''),
                placeholder="ä¾‹å¦‚ï¼šmyapp.vercel.app æˆ– username.github.io",
                help="è¼¸å…¥æ‚¨éƒ¨ç½²æ‡‰ç”¨çš„åŸŸå"
            )
        elif auth_mode == "token":
            st.info("ä½¿ç”¨ Token é€²è¡Œå¾Œç«¯èªè­‰ï¼Œé©åˆæœå‹™ç«¯æ•´åˆ")
            token_input = st.text_input(
                "Pollinations Token",
                value="",
                type="password",
                placeholder="åœ¨ https://auth.pollinations.ai ç²å–æ‚¨çš„ token",
                help="ç²å– tokenï¼šhttps://auth.pollinations.ai"
            )
            current_token = st.session_state.api_config.get('pollinations_token', '')
            if current_token and not token_input:
                st.caption(f"ğŸ” ç•¶å‰ Token: {current_token[:10]}...{current_token[-8:] if len(current_token) > 18 else ''}")
        else:
            st.info("å…è²»æ¨¡å¼ï¼šç„¡éœ€èªè­‰ï¼Œä½†åªèƒ½ä½¿ç”¨åŸºç¤æ¨¡å‹")
    
    is_key_required = selected_provider not in ["Pollinations.ai"]
    
    api_key_input = ""
    current_key = st.session_state.api_config.get('api_key', '')
    
    if is_key_required:
        masked_key = '*' * 20 + current_key[-8:] if len(current_key) > 8 else ''
        api_key_input = st.text_input(
            "API å¯†é‘°",
            value="",
            type="password",
            placeholder=f"è«‹è¼¸å…¥ {provider_info['name']} çš„ API å¯†é‘°...",
            help=f"API å¯†é‘°é€šå¸¸ä»¥ '{provider_info['key_prefix']}' é–‹é ­"
        )
        if current_key and not api_key_input:
            st.caption(f"ğŸ” ç•¶å‰å¯†é‘°: {masked_key}")
    else:
        if selected_provider != "Pollinations.ai":
            st.success("âœ… æ­¤æä¾›å•†ç„¡éœ€ API å¯†é‘°ã€‚")
        current_key = "N/A"

    # è™•ç† Base URL è®ŠåŒ–
    if selected_provider != current_provider:
        base_url_value = provider_info['base_url_default']
    else:
        base_url_value = st.session_state.api_config.get('base_url', provider_info['base_url_default'])

    base_url_input = st.text_input(
        "API ç«¯é» URL",
        value=base_url_value,
        placeholder=provider_info['base_url_default'],
        help="API æœå‹™çš„åŸºç¤ URL"
    )
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        save_btn = st.button("ğŸ’¾ ä¿å­˜è¨­ç½®", type="primary")
    
    with col2:
        test_btn = st.button("ğŸ§ª æ¸¬è©¦é€£æ¥")
    
    with col3:
        clear_btn = st.button("ğŸ—‘ï¸ æ¸…é™¤è¨­ç½®", type="secondary")
    
    if save_btn:
        final_api_key = api_key_input if api_key_input else current_key
        if is_key_required and not final_api_key:
            st.error("âŒ è«‹è¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            config_update = {
                'provider': selected_provider,
                'api_key': final_api_key,
                'base_url': base_url_input,
                'validated': False
            }
            
            # Pollinations.ai ç‰¹æ®Šè¨­ç½®
            if selected_provider == "Pollinations.ai":
                config_update['pollinations_auth_mode'] = auth_mode
                if auth_mode == "referrer":
                    config_update['pollinations_referrer'] = referrer_input
                elif auth_mode == "token":
                    config_update['pollinations_token'] = token_input if token_input else st.session_state.api_config.get('pollinations_token', '')
            
            st.session_state.api_config.update(config_update)
            # æ¸…é™¤èˆŠçš„ç™¼ç¾æ¨¡å‹å’Œé¸æ“‡çš„æ¨¡å‹
            st.session_state.discovered_models = {}
            if 'selected_model' in st.session_state:
                del st.session_state.selected_model
            st.session_state.models_updated = True
            st.success("âœ… API è¨­ç½®å·²ä¿å­˜ï¼Œæ¨¡å‹åˆ—è¡¨å·²é‡ç½®ã€‚")
            time.sleep(0.5)  # çµ¦ç”¨æˆ¶æ™‚é–“çœ‹åˆ°æˆåŠŸæ¶ˆæ¯
            rerun_app()
    
    if test_btn:
        test_api_key = api_key_input if api_key_input else current_key
        if is_key_required and not test_api_key:
            st.error("âŒ è«‹å…ˆè¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            with st.spinner("æ­£åœ¨æ¸¬è©¦ API é€£æ¥..."):
                is_valid, message = validate_api_key(test_api_key, base_url_input, selected_provider)
                if is_valid:
                    st.success(f"âœ… {message}")
                    st.session_state.api_config['validated'] = True
                else:
                    st.error(f"âŒ {message}")
                    st.session_state.api_config['validated'] = False
    
    if clear_btn:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False,
            'pollinations_auth_mode': 'free',
            'pollinations_token': '',
            'pollinations_referrer': ''
        }
        st.session_state.discovered_models = {}
        if 'selected_model' in st.session_state:
            del st.session_state.selected_model
        st.session_state.models_updated = True
        st.success("ğŸ—‘ï¸ API è¨­ç½®å·²æ¸…é™¤ï¼Œæ¨¡å‹åˆ—è¡¨å·²é‡ç½®ã€‚")
        time.sleep(0.5)  # çµ¦ç”¨æˆ¶æ™‚é–“çœ‹åˆ°æˆåŠŸæ¶ˆæ¯
        rerun_app()


def auto_discover_models():
    """åŸ·è¡Œè‡ªå‹•æ¨¡å‹ç™¼ç¾"""
    config = st.session_state.api_config
    provider = config.get('provider')
    is_key_required = provider not in ["Pollinations.ai"]
    
    if is_key_required and not config.get('api_key'):
        st.error("âŒ è«‹å…ˆé…ç½® API å¯†é‘°")
        return
    
    # é¡¯ç¤ºç™¼ç¾é€²åº¦
    progress_placeholder = st.empty()
    
    with progress_placeholder.container():
        with st.spinner("ğŸ” æ­£åœ¨è‡ªå‹•ç™¼ç¾æ¨¡å‹..."):
            client = None
            if provider not in ["Hugging Face", "Pollinations.ai"]:
                client = OpenAI(api_key=config['api_key'], base_url=config['base_url'])
            
            discovered = auto_discover_flux_models(
                client, config['provider'], config['api_key'], config['base_url']
            )
            
            if 'discovered_models' not in st.session_state:
                st.session_state.discovered_models = {}
            
            new_count = 0
            for model_id, model_info in discovered.items():
                # ç¢ºä¿ä¸æœƒé‡è¤‡è¨ˆæ•¸
                if model_id not in BASE_FLUX_MODELS and model_id not in st.session_state.discovered_models:
                    new_count += 1
                st.session_state.discovered_models[model_id] = model_info
            
            # é‡ç½®å·²é¸æ“‡çš„æ¨¡å‹ä»¥ç¢ºä¿ä½¿ç”¨æ–°çš„æ¨¡å‹åˆ—è¡¨
            if 'selected_model' in st.session_state:
                current_model = st.session_state.selected_model
                all_models = merge_models()
                if current_model not in all_models:
                    del st.session_state.selected_model
            
            # è¨­ç½®æ¨¡å‹æ›´æ–°æ¨™èªŒ
            st.session_state.models_updated = True
            
            # æ ¹æ“šç™¼ç¾çµæœé¡¯ç¤ºç›¸æ‡‰æ¶ˆæ¯
            if new_count > 0:
                progress_placeholder.success(f"âœ… ç™¼ç¾ {new_count} å€‹æ–°çš„æ¨¡å‹ï¼")
            elif discovered:
                progress_placeholder.info("â„¹ï¸ å·²åˆ·æ–°æ¨¡å‹åˆ—è¡¨ï¼Œæœªç™¼ç¾æ–°æ¨¡å‹ã€‚")
            else:
                progress_placeholder.warning("âš ï¸ æœªç™¼ç¾ä»»ä½•å…¼å®¹æ¨¡å‹ã€‚")
            
            # å»¶é²å¾Œæ¸…é™¤æ¶ˆæ¯ä¸¦é‡æ–°é‹è¡Œæ‡‰ç”¨
            time.sleep(2)
            progress_placeholder.empty()
            rerun_app()


# åˆå§‹åŒ–
init_session_state()
client = init_api_client()

config = st.session_state.api_config
provider = config.get('provider')
is_key_required = provider not in ["Pollinations.ai"]
api_configured = (not is_key_required) or (config.get('api_key') and config.get('api_key') != 'N/A')

# å´é‚Šæ¬„
with st.sidebar:
    show_api_settings()
    st.markdown("---")
    
    if api_configured:
        st.success(f"ğŸŸ¢ {provider} API å·²é…ç½®")
        
        # é¡¯ç¤º Pollinations.ai èªè­‰ç‹€æ…‹
        if provider == "Pollinations.ai":
            auth_mode = config.get('pollinations_auth_mode', 'free')
            auth_status = {
                'free': 'ğŸ†“ å…è²»æ¨¡å¼',
                'referrer': f'ğŸŒ åŸŸåèªè­‰: {config.get("pollinations_referrer", "æœªè¨­ç½®")}',
                'token': 'ğŸ”‘ Token èªè­‰'
            }
            st.caption(f"èªè­‰ç‹€æ…‹: {auth_status[auth_mode]}")
        
        if st.button("ğŸ” ç™¼ç¾æ¨¡å‹", use_container_width=True):
            auto_discover_models()
    else:
        st.error("ğŸ”´ API æœªé…ç½®")

# ä¸»æ¨™é¡Œ
st.title("ğŸ¨ Flux AI åœ–åƒç”Ÿæˆå™¨ Pro - å®Œæ•´ç‰ˆ")

# é é¢å°èˆª
tab1, tab2, tab3 = st.tabs(["ğŸš€ åœ–åƒç”Ÿæˆ", "ğŸ“š æ­·å²è¨˜éŒ„", "â­ æ”¶è—å¤¾"])

# åœ–åƒç”Ÿæˆé é¢
with tab1:
    if not api_configured:
        st.warning("âš ï¸ è«‹å…ˆåœ¨å´é‚Šæ¬„é…ç½® API")
        st.info("é…ç½®å®Œæˆå¾Œå³å¯é–‹å§‹ç”Ÿæˆåœ–åƒ")
    else:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ¨ åœ–åƒç”Ÿæˆ")
            
            # ä½¿ç”¨åˆä½µå¾Œçš„æ¨¡å‹åˆ—è¡¨
            all_models = merge_models()
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦æç¤ºç”¨æˆ¶ç™¼ç¾æ¨¡å‹
            if not all_models:
                st.warning("âš ï¸ å°šæœªç™¼ç¾ä»»ä½•æ¨¡å‹ï¼Œè«‹é»æ“Šå´é‚Šæ¬„çš„ã€Œç™¼ç¾æ¨¡å‹ã€æŒ‰éˆ•")
            else:
                # å¦‚æœæ¨¡å‹åˆ—è¡¨è¢«æ›´æ–°ï¼Œé¡¯ç¤ºæç¤º
                if st.session_state.get('models_updated', False):
                    st.info(f"ğŸ”„ æ¨¡å‹åˆ—è¡¨å·²æ›´æ–°ï¼Œå…±ç™¼ç¾ {len(all_models)} å€‹å¯ç”¨æ¨¡å‹")
                    st.session_state.models_updated = False  # é‡ç½®æ¨™èªŒ
                
                # æ¨¡å‹é¸æ“‡
                model_options = list(all_models.keys())
                
                # è™•ç†é‡æ–°ç”Ÿæˆæ™‚çš„æ¨¡å‹é¸æ“‡
                regenerate_model = getattr(st.session_state, 'regenerate_model', None)
                if regenerate_model and regenerate_model in model_options:
                    selected_model_key = regenerate_model
                elif 'selected_model' in st.session_state and st.session_state.selected_model in model_options:
                    selected_model_key = st.session_state.selected_model
                else:
                    selected_model_key = model_options[0]
                    st.session_state.selected_model = selected_model_key

                selected_model = st.selectbox(
                    "é¸æ“‡æ¨¡å‹:",
                    options=model_options,
                    index=model_options.index(selected_model_key),
                    format_func=lambda x: f"{all_models[x].get('icon', 'ğŸ¤–')} {all_models[x].get('name', x)}" + 
                                         (" ğŸ”" if all_models[x].get('auth_required', False) else ""),
                    key="model_selector"
                )
                
                st.session_state.selected_model = selected_model
                
                # é¡¯ç¤ºæ¨¡å‹ä¿¡æ¯å’Œèªè­‰è­¦å‘Š
                model_info = all_models[selected_model]
                description = model_info.get('description', 'N/A')
                st.info(f"**{model_info.get('name')}**: {description}")
                
                # æª¢æŸ¥èªè­‰è¦æ±‚
                if model_info.get('auth_required', False) and provider == "Pollinations.ai":
                    auth_mode = config.get('pollinations_auth_mode', 'free')
                    if auth_mode == 'free':
                        st.warning("âš ï¸ æ­¤æ¨¡å‹éœ€è¦èªè­‰æ‰èƒ½ä½¿ç”¨ã€‚è«‹åœ¨å´é‚Šæ¬„é…ç½® Pollinations.ai èªè­‰ï¼ˆåŸŸåæˆ– Tokenï¼‰ã€‚")
                
                # æª¢æŸ¥é‡æ–°ç”Ÿæˆç‹€æ…‹
                default_prompt = ""
                if hasattr(st.session_state, 'regenerate_prompt'):
                    default_prompt = st.session_state.regenerate_prompt
                    delattr(st.session_state, 'regenerate_prompt')
                    if hasattr(st.session_state, 'regenerate_model'):
                        delattr(st.session_state, 'regenerate_model')
                
                # æç¤ºè©è¼¸å…¥
                prompt_value = st.text_area(
                    "è¼¸å…¥æç¤ºè©:",
                    value=default_prompt,
                    height=120,
                    placeholder="æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„åœ–åƒï¼Œä¾‹å¦‚ï¼šA majestic dragon flying over ancient mountains during sunset, highly detailed, fantasy art style"
                )
                
                # é«˜ç´šè¨­ç½®
                with st.expander("ğŸ”§ é«˜ç´šè¨­ç½®"):
                    col_size, col_num = st.columns(2)
                    
                    with col_size:
                        size_options = {
                            "1024x1024": "æ­£æ–¹å½¢ (1:1)",
                            "1152x896": "æ©«å‘ (4:3.5)",
                            "896x1152": "ç›´å‘ (3.5:4)",
                            "1344x768": "å¯¬å± (16:9)",
                            "768x1344": "è¶…é«˜ (9:16)"
                        }
                        selected_size = st.selectbox(
                            "åœ–åƒå°ºå¯¸",
                            options=list(size_options.keys()),
                            format_func=lambda x: f"{x} - {size_options[x]}",
                            index=0
                        )
                    
                    with col_num:
                        # Pollinations.ai åƒ…æ”¯æŒå–®å¼µç”Ÿæˆ
                        num_images = 1 if provider == "Pollinations.ai" else st.slider("ç”Ÿæˆæ•¸é‡", 1, 4, 1)
                        if provider == "Pollinations.ai":
                            st.caption("Pollinations.ai åƒ…æ”¯æŒå–®å¼µåœ–åƒç”Ÿæˆã€‚")
                
                # ç”ŸæˆæŒ‰éˆ•
                generate_ready = prompt_value.strip() and api_configured
                
                generate_btn = st.button(
                    "ğŸš€ ç”Ÿæˆåœ–åƒ",
                    type="primary",
                    use_container_width=True,
                    disabled=not generate_ready
                )
                
                if not generate_ready:
                    if not prompt_value.strip():
                        st.warning("âš ï¸ è«‹è¼¸å…¥æç¤ºè©")
                    elif not api_configured:
                        st.error("âŒ è«‹é…ç½® API")
                
                # åœ–åƒç”Ÿæˆé‚è¼¯
                if generate_btn and generate_ready:
                    config = st.session_state.api_config
                    
                    with st.spinner(f"ğŸ¨ ä½¿ç”¨ {model_info.get('name', selected_model)} æ­£åœ¨ç”Ÿæˆåœ–åƒ..."):
                        # é¡¯ç¤ºé€²åº¦ä¿¡æ¯
                        progress_info = st.empty()
                        progress_info.info(f"â³ æ¨¡å‹: {model_info.get('name')} | å°ºå¯¸: {selected_size} | æ•¸é‡: {num_images}")
                        
                        generation_params = {
                            "model": selected_model,
                            "prompt": prompt_value,
                            "n": num_images,
                            "size": selected_size
                        }
                        
                        success, result = generate_images_with_retry(
                            client, config['provider'], config['api_key'], 
                            config['base_url'], **generation_params
                        )
                        
                        progress_info.empty()
                        
                        if success:
                            response = result
                            image_urls = [img.url for img in response.data]
                            
                            metadata = {
                                "size": selected_size,
                                "num_images": len(image_urls),
                                "model_name": model_info.get('name', selected_model),
                                "api_provider": config['provider'],
                                "generation_time": time.time()
                            }
                            
                            add_to_history(prompt_value, selected_model, image_urls, metadata)
                            st.success(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(response.data)} å¼µåœ–åƒï¼")
                            
                            # é¡¯ç¤ºç”Ÿæˆçš„åœ–åƒ
                            if len(response.data) == 1:
                                # å–®å¼µåœ–åƒï¼Œå…¨å¯¬é¡¯ç¤º
                                st.subheader("ğŸ¨ ç”Ÿæˆçµæœ")
                                image_id = f"{st.session_state.generation_history[0]['id']}_0"
                                display_image_with_actions(
                                    response.data[0].url,
                                    image_id,
                                    st.session_state.generation_history[0]
                                )
                            else:
                                # å¤šå¼µåœ–åƒï¼Œç¶²æ ¼é¡¯ç¤º
                                st.subheader("ğŸ¨ ç”Ÿæˆçµæœ")
                                cols = st.columns(min(num_images, 2))
                                for i, image_data in enumerate(response.data):
                                    with cols[i % len(cols)]:
                                        st.markdown(f"**åœ–åƒ {i+1}**")
                                        image_id = f"{st.session_state.generation_history[0]['id']}_{i}"
                                        display_image_with_actions(
                                            image_data.url,
                                            image_id,
                                            st.session_state.generation_history[0]
                                        )
                        else:
                            st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {result}")
                            
                            # æä¾›éŒ¯èª¤è§£æ±ºå»ºè­°
                            error_suggestions = {
                                "401": "ğŸ” æª¢æŸ¥ API å¯†é‘°æ˜¯å¦æ­£ç¢º",
                                "403": "ğŸš« æª¢æŸ¥ API å¯†é‘°æ¬Šé™",
                                "404": "ğŸ” æª¢æŸ¥æ¨¡å‹åç¨±æˆ– API ç«¯é»æ˜¯å¦æ­£ç¢º",
                                "429": "â³ è«‹æ±‚éæ–¼é »ç¹ï¼Œç¨å¾Œå†è©¦",
                                "500": "ğŸ”§ æœå‹™å™¨éŒ¯èª¤ï¼Œè«‹ç¨å¾Œé‡è©¦æˆ–æª¢æŸ¥èªè­‰è¨­ç½®",
                                "Access to": "ğŸ” æ¨¡å‹éœ€è¦èªè­‰ï¼Œè«‹é…ç½® Pollinations.ai èªè­‰ä¿¡æ¯"
                            }
                            
                            for error_code, suggestion in error_suggestions.items():
                                if error_code in str(result):
                                    st.info(f"ğŸ’¡ å»ºè­°: {suggestion}")
                                    break
        
        with col2:
            st.subheader("â„¹ï¸ ç”Ÿæˆä¿¡æ¯")
            
            all_models = merge_models()
            base_count = len([m for m in all_models.values() if m.get('source') == 'base'])
            discovered_count = len(all_models) - base_count
            
            col_stat1, col_stat2 = st.columns(2)
            with col_stat1:
                st.metric("å¯ç”¨æ¨¡å‹", len(all_models), f"{discovered_count} å€‹å·²ç™¼ç¾")
            with col_stat2:
                st.metric("ç”Ÿæˆè¨˜éŒ„", len(st.session_state.generation_history))
            
            st.markdown("### ğŸ“‹ ä½¿ç”¨å»ºè­°")
            st.markdown("""
            **æç¤ºè©å„ªåŒ–æŠ€å·§:**
            - ğŸ¯ **å…·é«”åŒ–**: ä½¿ç”¨å…·é«”æè¿°è€ŒéæŠ½è±¡æ¦‚å¿µ (ä¾‹å¦‚ï¼š"a golden retriever puppy" vs "a dog")ã€‚
            - ğŸ¨ **é¢¨æ ¼åŒ–**: åŠ å…¥è—è¡“é¢¨æ ¼é—œéµè© (ä¾‹å¦‚ï¼š`cinematic lighting`, `Van Gogh style`, `cyberpunk`)ã€‚
            - ğŸ“ **æ§‹åœ–**: æŒ‡å®šæ§‹åœ–å’Œè¦–è§’ (ä¾‹å¦‚ï¼š`wide-angle shot`, `from a low angle`, `portrait`)ã€‚
            - ğŸŒˆ **å…‰å½±è‰²å½©**: æè¿°è‰²å½©å’Œå…‰ç·šæ•ˆæœ (ä¾‹å¦‚ï¼š`vibrant colors`, `dramatic lighting`, `morning mist`)ã€‚
            
            **Pollinations.ai èªè­‰:**
            - ğŸ†“ **å…è²»æ¨¡å¼**: åŸºç¤æ¨¡å‹ç„¡éœ€èªè­‰
            - ğŸŒ **åŸŸåèªè­‰**: è¼¸å…¥æ‚¨çš„æ‡‰ç”¨åŸŸåä»¥å­˜å–æ›´å¤šæ¨¡å‹
            - ğŸ”‘ **Token èªè­‰**: åœ¨ [auth.pollinations.ai](https://auth.pollinations.ai) ç²å– token
            
            **Koyeb éƒ¨ç½²ç‰¹è‰²:**
            - ğŸš€ **Scale-to-Zero**: æ ¹æ“šæµé‡è‡ªå‹•ç¸®æ”¾æ‡‰ç”¨ï¼Œç¯€çœæˆæœ¬ã€‚
            - ğŸŒ **å…¨çƒ CDN åŠ é€Ÿ**: å…§ç½® CDN ç‚ºå…¨çƒç”¨æˆ¶æä¾›ä½å»¶é²è¨ªå•ã€‚
            - ğŸ“Š **å¯¦æ™‚ç›£æ§**: æä¾›æ‡‰ç”¨æ€§èƒ½å’Œè³‡æºä½¿ç”¨æƒ…æ³çš„å¯¦æ™‚å„€è¡¨æ¿ã€‚
            - ğŸ”’ **å®‰å…¨ç’°å¢ƒ**: è‡ªå‹• SSL åŠ å¯†å’Œå®‰å…¨çš„ API å¯†é‘°ç®¡ç†ã€‚
            """)

# æ­·å²è¨˜éŒ„é é¢
with tab2:
    st.subheader("ğŸ“š ç”Ÿæˆæ­·å²")
    
    if st.session_state.generation_history:
        # æœç´¢å’Œéæ¿¾
        col_search, col_clear = st.columns([3, 1])
        with col_search:
            search_term = st.text_input("ğŸ” æœç´¢æ­·å²è¨˜éŒ„", placeholder="è¼¸å…¥é—œéµè©æœç´¢æç¤ºè©...")
        with col_clear:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ­·å²è¨˜éŒ„", use_container_width=True):
                 if st.checkbox("ç¢ºèªæ¸…ç©ºæ‰€æœ‰æ­·å²è¨˜éŒ„", key="confirm_clear_history"):
                    st.session_state.generation_history = []
                    st.success("å·²æ¸…ç©ºæ‰€æœ‰æ­·å²è¨˜éŒ„")
                    time.sleep(1)
                    rerun_app()

        filtered_history = st.session_state.generation_history
        if search_term:
            filtered_history = [
                item for item in st.session_state.generation_history
                if search_term.lower() in item['prompt'].lower()
            ]
        
        st.info(f"é¡¯ç¤º {len(filtered_history)} / {len(st.session_state.generation_history)} æ¢è¨˜éŒ„")
        
        for item in filtered_history:
            with st.expander(
                f"ğŸ¨ {item['prompt'][:60]}{'...' if len(item['prompt']) > 60 else ''} | {item['timestamp'].strftime('%m-%d %H:%M')}"
            ):
                col_info, col_actions = st.columns([3, 1])
                
                with col_info:
                    st.markdown(f"**æç¤ºè©**: {item['prompt']}")
                    all_models = merge_models()
                    model_name = all_models.get(item['model'], {}).get('name', item['model'])
                    st.markdown(f"**æ¨¡å‹**: {model_name}")
                    st.markdown(f"**æ™‚é–“**: {item['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                    
                    if 'metadata' in item:
                        metadata = item['metadata']
                        st.markdown(f"**å°ºå¯¸**: {metadata.get('size', 'N/A')}")
                        st.markdown(f"**APIæä¾›å•†**: {metadata.get('api_provider', 'N/A')}")
                
                with col_actions:
                    if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆ", key=f"regen_{item['id']}", use_container_width=True):
                        st.session_state.regenerate_prompt = item['prompt']
                        st.session_state.regenerate_model = item['model']
                        rerun_app()
                
                # é¡¯ç¤ºåœ–åƒ
                if item['images']:
                    cols = st.columns(min(len(item['images']), 3))
                    for i, img_url in enumerate(item['images']):
                        with cols[i % len(cols)]:
                            display_image_with_actions(img_url, f"history_{item['id']}_{i}", item)
    else:
        st.info("ğŸ“­ å°šç„¡ç”Ÿæˆæ­·å²ï¼Œé–‹å§‹ç”Ÿæˆä¸€äº›åœ–åƒå§ï¼")

# æ”¶è—å¤¾é é¢
with tab3:
    st.subheader("â­ æˆ‘çš„æ”¶è—")
    
    if st.session_state.favorite_images:
        # æ‰¹é‡æ“ä½œ
        col_batch1, col_batch2 = st.columns(2)
        with col_batch1:
            st.button("ğŸ“¥ æ‰¹é‡ä¸‹è¼‰ (é–‹ç™¼ä¸­)", use_container_width=True, disabled=True)
        with col_batch2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ”¶è—", use_container_width=True):
                if st.checkbox("ç¢ºèªæ¸…ç©ºæ‰€æœ‰æ”¶è—", key="confirm_clear_favorites"):
                    st.session_state.favorite_images = []
                    st.success("å·²æ¸…ç©ºæ‰€æœ‰æ”¶è—")
                    time.sleep(1)
                    rerun_app()
        
        st.markdown("---")
        # é¡¯ç¤ºæ”¶è—çš„åœ–åƒ
        cols = st.columns(3)
        # æŒ‰æ™‚é–“å€’åºé¡¯ç¤º
        sorted_favorites = sorted(st.session_state.favorite_images, key=lambda x: x['timestamp'], reverse=True)

        for i, fav in enumerate(sorted_favorites):
            with cols[i % 3]:
                display_image_with_actions(fav['image_url'], fav['id'], fav.get('history_item'))
                
                # é¡¯ç¤ºæ”¶è—ä¿¡æ¯
                if fav.get('history_item'):
                    st.caption(f"ğŸ’­ {fav['history_item']['prompt'][:40]}...")
                st.caption(f"â­ æ”¶è—æ–¼: {fav['timestamp'].strftime('%Y-%m-%d %H:%M')}")
    else:
        st.info("â­ å°šç„¡æ”¶è—åœ–åƒï¼Œåœ¨ç”Ÿæˆçš„åœ–åƒä¸Šé»æ“Š â˜† æŒ‰éˆ•ä¾†æ·»åŠ æ”¶è—ï¼")

# é è…³
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; margin-top: 2rem;">
    ğŸš€ <strong>éƒ¨ç½²åœ¨ Koyeb</strong> | 
    ğŸ¨ <strong>Powered by Flux & Generative AI</strong> | 
    âš¡ <strong>è‡ªå‹•ç¸®æ”¾</strong> | 
    ğŸŒ <strong>å…¨çƒåŠ é€Ÿ</strong>
    <br><br>
    <small>å®Œæ•´çš„åœ–åƒç”Ÿæˆã€æ¨¡å‹ç™¼ç¾ã€æ­·å²ç®¡ç†åŠŸèƒ½</small>
</div>
""", unsafe_allow_html=True)
