import streamlit as st
import torch
from diffusers import FluxPipeline
from huggingface_hub import login
import os
import time
from PIL import Image
import io
import base64

# é é¢é…ç½®
st.set_page_config(
    page_title="Flux AI Studio",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾© CSS æ¨£å¼
st.markdown("""
<style>
.main-header {
    background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    padding: 2rem;
    border-radius: 10px;
    color: white;
    text-align: center;
    margin-bottom: 2rem;
}

.generation-card {
    border: 1px solid #e6e6e6;
    border-radius: 10px;
    padding: 1rem;
    margin: 1rem 0;
    background: white;
}

.gpu-status {
    position: fixed;
    top: 70px;
    right: 20px;
    background: rgba(255,255,255,0.95);
    padding: 10px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    font-size: 0.8rem;
}

.parameter-section {
    background: #f8f9fa;
    padding: 1rem;
    border-radius: 8px;
    margin: 1rem 0;
}
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ– Hugging Face
@st.cache_resource
def init_model():
    """åˆå§‹åŒ–ä¸¦ç·©å­˜ Flux æ¨¡å‹"""
    hf_token = os.getenv('HF_TOKEN')
    if hf_token:
        login(token=hf_token)
    
    try:
        # æ ¹æ“šå¯ç”¨ GPU å…§å­˜é¸æ“‡æ¨¡å‹
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory // (1024**3)
            if gpu_memory >= 40:  # A100 40GB+
                model_id = "black-forest-labs/FLUX.1-dev"
                torch_dtype = torch.bfloat16
            else:  # è¼ƒå°çš„ GPU
                model_id = "black-forest-labs/FLUX.1-schnell"
                torch_dtype = torch.float16
        else:
            st.error("éœ€è¦ GPU æ”¯æŒ")
            return None
        
        pipeline = FluxPipeline.from_pretrained(
            model_id,
            torch_dtype=torch_dtype,
            cache_dir="/tmp/flux_models"
        )
        pipeline.to("cuda")
        
        return pipeline, model_id
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
        return None, None

def generate_image(pipeline, prompt, negative_prompt="", **kwargs):
    """ç”Ÿæˆåœ–åƒ"""
    try:
        with torch.no_grad():
            if "schnell" in pipeline.config._name_or_path.lower():
                # Schnell ç‰ˆæœ¬ä¸ä½¿ç”¨ guidance_scale
                kwargs.pop('guidance_scale', None)
                image = pipeline(
                    prompt=prompt,
                    num_inference_steps=kwargs.get('num_inference_steps', 4),
                    height=kwargs.get('height', 1024),
                    width=kwargs.get('width', 1024),
                    generator=kwargs.get('generator', None)
                ).images[0]
            else:
                # Dev ç‰ˆæœ¬ä½¿ç”¨å®Œæ•´åƒæ•¸
                image = pipeline(
                    prompt=prompt,
                    negative_prompt=negative_prompt if negative_prompt else None,
                    num_inference_steps=kwargs.get('num_inference_steps', 28),
                    guidance_scale=kwargs.get('guidance_scale', 7.5),
                    height=kwargs.get('height', 1024),
                    width=kwargs.get('width', 1024),
                    generator=kwargs.get('generator', None)
                ).images[0]
        
        return image
    except Exception as e:
        st.error(f"åœ–åƒç”Ÿæˆå¤±æ•—: {e}")
        return None

def image_to_base64(image):
    """å°‡ PIL åœ–åƒè½‰æ›ç‚º base64"""
    buffer = io.BytesIO()
    image.save(buffer, format="PNG")
    img_str = base64.b64encode(buffer.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"

def main():
    # ä¸»æ¨™é¡Œ
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ¨ Flux AI Studio</h1>
        <p>Professional AI Image Generation on Koyeb GPU Infrastructure</p>
    </div>
    """, unsafe_allow_html=True)
    
    # åˆå§‹åŒ–æ¨¡å‹
    model_result = init_model()
    if model_result[0] is None:
        st.stop()
    
    pipeline, model_name = model_result
    
    # GPU ç‹€æ…‹é¡¯ç¤º
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory // (1024**3)
        st.markdown(f"""
        <div class="gpu-status">
            <strong>ğŸš€ GPU ç‹€æ…‹</strong><br>
            {gpu_name}<br>
            {gpu_memory}GB VRAM<br>
            æ¨¡å‹: {model_name.split('/')[-1]}
        </div>
        """, unsafe_allow_html=True)
    
    # å´é‚Šæ¬„é…ç½®
    with st.sidebar:
        st.header("ğŸ›ï¸ ç”Ÿæˆåƒæ•¸")
        
        # åŸºæœ¬åƒæ•¸
        st.subheader("åŸºæœ¬è¨­ç½®")
        
        # æ¨¡å‹ä¿¡æ¯
        st.info(f"**ç•¶å‰æ¨¡å‹**: {model_name.split('/')[-1]}")
        
        # åœ–åƒå°ºå¯¸
        col1, col2 = st.columns(2)
        with col1:
            width = st.selectbox("å¯¬åº¦", [512, 768, 1024, 1280], index=2)
        with col2:
            height = st.selectbox("é«˜åº¦", [512, 768, 1024, 1280], index=2)
        
        # ç”Ÿæˆåƒæ•¸
        if "dev" in model_name.lower():
            num_steps = st.slider("æ¨ç†æ­¥æ•¸", 1, 50, 28)
            guidance_scale = st.slider("å¼•å°æ¯”ä¾‹", 0.1, 20.0, 7.5)
        else:
            num_steps = st.slider("æ¨ç†æ­¥æ•¸", 1, 8, 4)
            guidance_scale = None
        
        # é«˜ç´šè¨­ç½®
        with st.expander("ğŸ”§ é«˜ç´šè¨­ç½®"):
            seed = st.number_input("éš¨æ©Ÿç¨®å­", -1, 2147483647, -1)
            batch_size = st.slider("æ‰¹é‡ç”Ÿæˆ", 1, 4, 1)
            
        # é è¨­é¢¨æ ¼
        st.subheader("ğŸ¨ é¢¨æ ¼é è¨­")
        style_presets = {
            "ç„¡": "",
            "æ”å½±é¢¨æ ¼": ", professional photography, high resolution, detailed",
            "æ•¸ä½è—è¡“": ", digital art, concept art, trending on artstation",
            "æ²¹ç•«é¢¨æ ¼": ", oil painting, classical art style, fine art",
            "ç§‘å¹»é¢¨æ ¼": ", sci-fi, futuristic, cyberpunk, neon lights",
            "å‹•æ¼«é¢¨æ ¼": ", anime style, manga, japanese art style"
        }
        
        selected_style = st.selectbox("é¸æ“‡é¢¨æ ¼", list(style_presets.keys()))
        style_suffix = style_presets[selected_style]
        
        # è³‡æºç›£æ§
        st.subheader("ğŸ“Š è³‡æºç›£æ§")
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated(0) / (1024**3)
            memory_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            memory_percent = (memory_used / memory_total) * 100
            
            st.metric("GPU å…§å­˜", f"{memory_used:.1f}GB", f"{memory_percent:.1f}%")
            
            if st.button("ğŸ§¹ æ¸…ç† GPU å…§å­˜"):
                torch.cuda.empty_cache()
                st.success("GPU å…§å­˜å·²æ¸…ç†")
    
    # ä¸»ç•Œé¢
    col_main, col_history = st.columns([2, 1])
    
    with col_main:
        st.subheader("ğŸ“ æç¤ºè©è¼¸å…¥")
        
        # ä¸»æç¤ºè©
        prompt = st.text_area(
            "ä¸»æç¤ºè©:",
            placeholder="ä¾‹å¦‚: A majestic dragon flying over ancient mountains during sunset",
            height=120,
            help="è©³ç´°æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„åœ–åƒ"
        )
        
        # è² é¢æç¤ºè© (åƒ…é©ç”¨æ–¼ dev æ¨¡å‹)
        if "dev" in model_name.lower():
            negative_prompt = st.text_area(
                "è² é¢æç¤ºè© (å¯é¸):",
                placeholder="ä¾‹å¦‚: blurry, low quality, distorted",
                height=60,
                help="æè¿°æ‚¨ä¸å¸Œæœ›å‡ºç¾åœ¨åœ–åƒä¸­çš„å…ƒç´ "
            )
        else:
            negative_prompt = ""
        
        # æç¤ºè©æ¨¡æ¿
        st.subheader("ğŸ’¡ æç¤ºè©æ¨¡æ¿")
        
        template_categories = {
            "é¢¨æ™¯æ”å½±": [
                "A breathtaking mountain landscape at sunrise with mist rolling through valleys",
                "Serene lake reflecting autumn colors with a wooden pier extending into calm water",
                "Dense forest path with sunlight filtering through ancient trees"
            ],
            "äººç‰©è‚–åƒ": [
                "Professional headshot of a confident business person in modern office setting",
                "Artistic portrait with dramatic lighting and atmospheric background",
                "Candid street photography style portrait with urban bokeh background"
            ],
            "ç§‘å¹»/å¥‡å¹»": [
                "Futuristic cityscape with flying vehicles and neon-lit skyscrapers at night",
                "Magical forest with glowing creatures and ethereal light beams",
                "Space station orbiting a distant planet with nebula in background"
            ],
            "è—è¡“é¢¨æ ¼": [
                "Abstract geometric composition with vibrant colors and flowing lines",
                "Minimalist design with clean lines and balanced negative space",
                "Vintage poster art with retro colors and typography elements"
            ]
        }
        
        selected_category = st.selectbox("é¸æ“‡æ¨¡æ¿é¡åˆ¥:", list(template_categories.keys()))
        selected_template = st.selectbox(
            "é¸æ“‡å…·é«”æ¨¡æ¿:", 
            ["è‡ªå®šç¾©"] + template_categories[selected_category]
        )
        
        if selected_template != "è‡ªå®šç¾©":
            prompt = selected_template + style_suffix
        elif style_suffix:
            prompt = prompt + style_suffix
        
        # ç”ŸæˆæŒ‰éˆ•å€åŸŸ
        col_gen1, col_gen2, col_gen3 = st.columns([2, 1, 1])
        
        with col_gen1:
            generate_btn = st.button(
                "ğŸš€ ç”Ÿæˆåœ–åƒ",
                type="primary",
                use_container_width=True,
                disabled=not prompt.strip()
            )
        
        with col_gen2:
            if st.button("ğŸ² éš¨æ©Ÿæç¤ºè©", use_container_width=True):
                import random
                all_templates = [t for templates in template_categories.values() for t in templates]
                prompt = random.choice(all_templates) + style_suffix
                st.rerun()
        
        with col_gen3:
            estimated_time = "30-60ç§’" if "dev" in model_name.lower() else "5-15ç§’"
            st.metric("é ä¼°æ™‚é–“", estimated_time)
        
        # åœ–åƒç”Ÿæˆ
        if generate_btn and prompt.strip():
            with st.spinner(f"ğŸ¨ æ­£åœ¨ä½¿ç”¨ {model_name.split('/')[-1]} ç”Ÿæˆåœ–åƒ..."):
                start_time = time.time()
                
                # æº–å‚™ç”Ÿæˆåƒæ•¸
                generator = torch.Generator().manual_seed(seed) if seed >= 0 else None
                
                params = {
                    'height': height,
                    'width': width,
                    'num_inference_steps': num_steps,
                    'generator': generator
                }
                
                if guidance_scale is not None:
                    params['guidance_scale'] = guidance_scale
                
                # æ‰¹é‡ç”Ÿæˆ
                images = []
                for i in range(batch_size):
                    if batch_size > 1:
                        st.write(f"ç”Ÿæˆç¬¬ {i+1}/{batch_size} å¼µåœ–åƒ...")
                    
                    image = generate_image(pipeline, prompt, negative_prompt, **params)
                    if image:
                        images.append(image)
                
                generation_time = time.time() - start_time
                
                if images:
                    st.success(f"âœ… æˆåŠŸç”Ÿæˆ {len(images)} å¼µåœ–åƒï¼è€—æ™‚: {generation_time:.1f}ç§’")
                    
                    # é¡¯ç¤ºåœ–åƒ
                    if len(images) == 1:
                        st.image(images[0], caption=prompt, use_column_width=True)
                    else:
                        # ç¶²æ ¼é¡¯ç¤ºå¤šå¼µåœ–åƒ
                        cols = st.columns(min(len(images), 2))
                        for i, image in enumerate(images):
                            with cols[i % 2]:
                                st.image(image, caption=f"åœ–åƒ {i+1}", use_column_width=True)
                    
                    # ä¿å­˜åˆ°æœƒè©±ç‹€æ…‹
                    if 'generated_images' not in st.session_state:
                        st.session_state.generated_images = []
                    
                    for image in images:
                        st.session_state.generated_images.append({
                            'image': image,
                            'prompt': prompt,
                            'timestamp': time.strftime('%H:%M:%S'),
                            'params': {
                                'model': model_name.split('/')[-1],
                                'size': f"{width}x{height}",
                                'steps': num_steps,
                                'guidance': guidance_scale
                            }
                        })
                    
                    # ä¸‹è¼‰é¸é …
                    if len(images) == 1:
                        img_buffer = io.BytesIO()
                        images[0].save(img_buffer, format="PNG")
                        img_buffer.seek(0)
                        
                        st.download_button(
                            "ğŸ“¥ ä¸‹è¼‰åœ–åƒ",
                            data=img_buffer,
                            file_name=f"flux_generated_{int(time.time())}.png",
                            mime="image/png"
                        )
                
                # æ¸…ç†å…§å­˜
                torch.cuda.empty_cache()
    
    with col_history:
        st.subheader("ğŸ“š ç”Ÿæˆæ­·å²")
        
        if 'generated_images' in st.session_state and st.session_state.generated_images:
            # é¡¯ç¤ºæœ€è¿‘ç”Ÿæˆçš„åœ–åƒ
            for i, item in enumerate(reversed(st.session_state.generated_images[-5:])):
                with st.expander(f"åœ–åƒ {len(st.session_state.generated_images)-i} - {item['timestamp']}"):
                    st.image(item['image'], use_column_width=True)
                    st.caption(item['prompt'][:100] + "..." if len(item['prompt']) > 100 else item['prompt'])
                    
                    # åƒæ•¸ä¿¡æ¯
                    params = item['params']
                    st.write(f"**æ¨¡å‹**: {params['model']}")
                    st.write(f"**å°ºå¯¸**: {params['size']}")
                    st.write(f"**æ­¥æ•¸**: {params['steps']}")
                    if params['guidance']:
                        st.write(f"**å¼•å°**: {params['guidance']}")
            
            # æ¸…ç©ºæ­·å²æŒ‰éˆ•
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ­·å²"):
                st.session_state.generated_images = []
                st.rerun()
        else:
            st.info("é‚„æ²’æœ‰ç”Ÿæˆåœ–åƒã€‚é–‹å§‹å‰µä½œæ‚¨çš„ç¬¬ä¸€å¼µåœ–åƒå§ï¼")
        
        # ä½¿ç”¨çµ±è¨ˆ
        st.subheader("ğŸ“Š ä½¿ç”¨çµ±è¨ˆ")
        total_generated = len(st.session_state.get('generated_images', []))
        st.metric("ç¸½ç”Ÿæˆæ•¸é‡", total_generated)
        
        if total_generated > 0:
            avg_time = "45ç§’" if "dev" in model_name.lower() else "10ç§’"
            st.metric("å¹³å‡ç”Ÿæˆæ™‚é–“", avg_time)

if __name__ == "__main__":
    main()
