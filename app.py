import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Optional, Tuple
import time
import random
import json
import sqlite3
import uuid
import zipfile
import psutil
import os
import re

# å…¼å®¹æ€§å‡½æ•¸
def rerun_app():
    """å…¼å®¹ä¸åŒ Streamlit ç‰ˆæœ¬çš„é‡æ–°é‹è¡Œå‡½æ•¸"""
    if hasattr(st, 'rerun'):
        st.rerun()
    elif hasattr(st, 'experimental_rerun'):
        st.experimental_rerun()
    else:
        st.stop()

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="Flux AI åœ–åƒç”Ÿæˆå™¨ Pro - å®Œæ•´ç‰ˆ",
    page_icon="ğŸ¨",
    layout="wide"
)

# API æä¾›å•†é…ç½®
API_PROVIDERS = {
    "OpenAI Compatible": {
        "name": "OpenAI Compatible API",
        "base_url_default": "https://api.openai.com/v1",
        "key_prefix": "sk-",
        "description": "OpenAI å®˜æ–¹æˆ–å…¼å®¹çš„ API æœå‹™",
        "icon": "ğŸ¤–"
    },
    "Navy": {
        "name": "Navy API",
        "base_url_default": "https://api.navy/v1", 
        "key_prefix": "sk-",
        "description": "Navy æä¾›çš„ AI åœ–åƒç”Ÿæˆæœå‹™",
        "icon": "âš“"
    },
    "Hugging Face": {
        "name": "Hugging Face Inference",
        "base_url_default": "https://api-inference.huggingface.co",
        "key_prefix": "hf_",
        "description": "Hugging Face Inference API",
        "icon": "ğŸ¤—"
    },
    "Together AI": {
        "name": "Together AI",
        "base_url_default": "https://api.together.xyz/v1",
        "key_prefix": "",
        "description": "Together AI å¹³å°",
        "icon": "ğŸ¤"
    },
    "Fireworks AI": {
        "name": "Fireworks AI",
        "base_url_default": "https://api.fireworks.ai/inference/v1",
        "key_prefix": "",
        "description": "Fireworks AI å¿«é€Ÿæ¨ç†",
        "icon": "ğŸ†"
    },
    "Custom": {
        "name": "è‡ªå®šç¾© API",
        "base_url_default": "",
        "key_prefix": "",
        "description": "è‡ªå®šç¾©çš„ API ç«¯é»",
        "icon": "ğŸ”§"
    }
}

# åŸºç¤ Flux æ¨¡å‹é…ç½®
BASE_FLUX_MODELS = {
    "flux.1-schnell": {
        "name": "FLUX.1 Schnell",
        "description": "æœ€å¿«çš„ç”Ÿæˆé€Ÿåº¦ï¼Œé–‹æºæ¨¡å‹",
        "icon": "âš¡",
        "type": "å¿«é€Ÿç”Ÿæˆ",
        "test_prompt": "A simple cat sitting on a table",
        "expected_size": "1024x1024",
        "priority": 1,
        "source": "base"
    },
    "flux.1-dev": {
        "name": "FLUX.1 Dev", 
        "description": "é–‹ç™¼ç‰ˆæœ¬ï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡è³ªé‡",
        "icon": "ğŸ”§",
        "type": "é–‹ç™¼ç‰ˆæœ¬",
        "test_prompt": "A beautiful landscape with mountains",
        "expected_size": "1024x1024",
        "priority": 2,
        "source": "base"
    },
    "flux.1.1-pro": {
        "name": "FLUX.1.1 Pro",
        "description": "æ”¹é€²çš„æ——è‰¦æ¨¡å‹ï¼Œæœ€ä½³å“è³ª",
        "icon": "ğŸ‘‘",
        "type": "æ——è‰¦ç‰ˆæœ¬",
        "test_prompt": "Professional portrait of a person in business attire",
        "expected_size": "1024x1024",
        "priority": 3,
        "source": "base"
    },
    "flux.1-kontext-pro": {
        "name": "FLUX.1 Kontext Pro",
        "description": "æ”¯æŒåœ–åƒç·¨è¼¯å’Œä¸Šä¸‹æ–‡ç†è§£",
        "icon": "ğŸ¯",
        "type": "ç·¨è¼¯å°ˆç”¨",
        "test_prompt": "Abstract geometric shapes in vibrant colors",
        "expected_size": "1024x1024",
        "priority": 4,
        "source": "base"
    }
}

# æ¨¡å‹è‡ªå‹•ç™¼ç¾è¦å‰‡
FLUX_MODEL_PATTERNS = {
    r'flux[\.\-]?1[\.\-]?schnell': {
        "name_template": "FLUX.1 Schnell",
        "icon": "âš¡",
        "type": "å¿«é€Ÿç”Ÿæˆ",
        "priority_base": 100
    },
    r'flux[\.\-]?1[\.\-]?dev': {
        "name_template": "FLUX.1 Dev",
        "icon": "ğŸ”§", 
        "type": "é–‹ç™¼ç‰ˆæœ¬",
        "priority_base": 200
    },
    r'flux[\.\-]?1[\.\-]?pro': {
        "name_template": "FLUX.1 Pro",
        "icon": "ğŸ‘‘",
        "type": "å°ˆæ¥­ç‰ˆæœ¬",
        "priority_base": 300
    },
    r'flux[\.\-]?1[\.\-]?kontext': {
        "name_template": "FLUX.1 Kontext",
        "icon": "ğŸ¯",
        "type": "ä¸Šä¸‹æ–‡ç†è§£",
        "priority_base": 400
    }
}

# æä¾›å•†ç‰¹å®šçš„æ¨¡å‹ç«¯é»
HF_FLUX_ENDPOINTS = [
    "black-forest-labs/FLUX.1-schnell",
    "black-forest-labs/FLUX.1-dev",
    "black-forest-labs/FLUX.1.1-pro",
]

def auto_discover_flux_models(client, provider: str, api_key: str, base_url: str) -> Dict[str, Dict]:
    """è‡ªå‹•ç™¼ç¾ Flux æ¨¡å‹"""
    discovered_models = {}
    
    try:
        if provider == "Hugging Face":
            for endpoint in HF_FLUX_ENDPOINTS:
                model_id = endpoint.split('/')[-1]
                model_info = analyze_model_name(model_id, endpoint)
                model_info['source'] = 'huggingface'
                model_info['endpoint'] = endpoint
                discovered_models[model_id] = model_info
        else:
            response = client.models.list()
            for model in response.data:
                model_id = model.id.lower()
                if is_flux_model(model_id):
                    model_info = analyze_model_name(model.id)
                    model_info['source'] = 'api_discovery'
                    discovered_models[model.id] = model_info
        return discovered_models
    except Exception as e:
        st.warning(f"æ¨¡å‹è‡ªå‹•ç™¼ç¾å¤±æ•—: {str(e)}")
        return {}

def is_flux_model(model_name: str) -> bool:
    """æª¢æŸ¥æ¨¡å‹åç¨±æ˜¯å¦ç‚º Flux æ¨¡å‹"""
    model_lower = model_name.lower()
    flux_keywords = ['flux', 'black-forest-labs']
    return any(keyword in model_lower for keyword in flux_keywords)

def analyze_model_name(model_id: str, full_path: str = None) -> Dict:
    """åˆ†ææ¨¡å‹åç¨±ä¸¦ç”Ÿæˆæ¨¡å‹ä¿¡æ¯"""
    model_lower = model_id.lower()
    
    for pattern, info in FLUX_MODEL_PATTERNS.items():
        if re.search(pattern, model_lower):
            analyzed_info = {
                "name": info["name_template"],
                "icon": info["icon"],
                "type": info["type"],
                "description": f"è‡ªå‹•ç™¼ç¾çš„ {info['name_template']} æ¨¡å‹",
                "test_prompt": "A beautiful scene with detailed elements",
                "expected_size": "1024x1024",
                "priority": info["priority_base"] + hash(model_id) % 100,
                "auto_discovered": True
            }
            
            if full_path:
                analyzed_info["full_path"] = full_path
                if '/' in full_path:
                    author = full_path.split('/')[0]
                    analyzed_info["name"] += f" ({author})"
            
            return analyzed_info
    
    return {
        "name": model_id.replace('-', ' ').replace('_', ' ').title(),
        "icon": "ğŸ¤–",
        "type": "è‡ªå‹•ç™¼ç¾",
        "description": f"è‡ªå‹•ç™¼ç¾çš„æ¨¡å‹: {model_id}",
        "test_prompt": "A detailed and beautiful image",
        "expected_size": "1024x1024", 
        "priority": 999,
        "auto_discovered": True,
        "full_path": full_path if full_path else model_id
    }

def merge_models() -> Dict[str, Dict]:
    """åˆä½µåŸºç¤æ¨¡å‹å’Œè‡ªå‹•ç™¼ç¾çš„æ¨¡å‹"""
    discovered = st.session_state.get('discovered_models', {})
    merged_models = BASE_FLUX_MODELS.copy()
    
    for model_id, model_info in discovered.items():
        if model_id not in merged_models:
            merged_models[model_id] = model_info
    
    return merged_models

def validate_api_key(api_key: str, base_url: str, provider: str) -> Tuple[bool, str]:
    """é©—è­‰ API å¯†é‘°æ˜¯å¦æœ‰æ•ˆ"""
    try:
        if provider == "Hugging Face":
            headers = {"Authorization": f"Bearer {api_key}"}
            test_url = f"{base_url}/models/black-forest-labs/FLUX.1-schnell"
            response = requests.get(test_url, headers=headers, timeout=10)
            if response.status_code == 200:
                return True, "Hugging Face API å¯†é‘°é©—è­‰æˆåŠŸ"
            else:
                return False, f"HTTP {response.status_code}: é©—è­‰å¤±æ•—"
        else:
            test_client = OpenAI(api_key=api_key, base_url=base_url)
            response = test_client.models.list()
            return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "Unauthorized" in error_msg:
            return False, "API å¯†é‘°ç„¡æ•ˆæˆ–å·²éæœŸ"
        elif "403" in error_msg or "Forbidden" in error_msg:
            return False, "API å¯†é‘°æ²’æœ‰è¶³å¤ æ¬Šé™"
        elif "404" in error_msg:
            return False, "API ç«¯é»ä¸å­˜åœ¨æˆ–ä¸æ­£ç¢º"
        elif "timeout" in error_msg.lower():
            return False, "API é€£æ¥è¶…æ™‚"
        else:
            return False, f"API é©—è­‰å¤±æ•—: {error_msg[:100]}"

def test_model_availability(client, model_name: str, provider: str, api_key: str, base_url: str, test_prompt: str = None) -> Dict:
    """æ¸¬è©¦ç‰¹å®šæ¨¡å‹çš„å¯ç”¨æ€§"""
    all_models = merge_models()
    if test_prompt is None:
        test_prompt = all_models.get(model_name, {}).get('test_prompt', 'A simple test image')
    
    test_result = {
        'model': model_name,
        'available': False,
        'response_time': 0,
        'error': None,
        'details': {}
    }
    
    try:
        start_time = time.time()
        
        if provider == "Hugging Face":
            headers = {"Authorization": f"Bearer {api_key}"}
            data = {"inputs": test_prompt}
            
            model_info = all_models.get(model_name, {})
            endpoint_path = model_info.get('full_path', f"black-forest-labs/{model_name}")
            
            response = requests.post(
                f"{base_url}/models/{endpoint_path}",
                headers=headers,
                json=data,
                timeout=30
            )
            end_time = time.time()
            response_time = end_time - start_time
            
            if response.status_code == 200:
                test_result.update({
                    'available': True,
                    'response_time': response_time,
                    'details': {
                        'status_code': response.status_code,
                        'test_prompt': test_prompt,
                        'endpoint': endpoint_path
                    }
                })
            else:
                test_result.update({
                    'available': False,
                    'error': f"HTTP {response.status_code}",
                    'details': {'status_code': response.status_code}
                })
        else:
            response = client.images.generate(
                model=model_name,
                prompt=test_prompt,
                n=1,
                size="1024x1024"
            )
            end_time = time.time()
            response_time = end_time - start_time
            
            test_result.update({
                'available': True,
                'response_time': response_time,
                'details': {
                    'image_count': len(response.data),
                    'test_prompt': test_prompt,
                    'image_url': response.data[0].url if response.data else None
                }
            })
            
    except Exception as e:
        error_msg = str(e)
        test_result.update({
            'available': False,
            'error': error_msg,
            'details': {
                'error_type': 'generation_failed',
                'test_prompt': test_prompt
            }
        })
    
    return test_result

def generate_images_with_retry(client, provider: str, api_key: str, base_url: str, **params) -> Tuple[bool, any]:
    """å¸¶é‡è©¦æ©Ÿåˆ¶çš„åœ–åƒç”Ÿæˆ"""
    max_retries = 3
    base_delay = 2
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                st.info(f"ğŸ”„ å˜—è©¦é‡æ–°ç”Ÿæˆ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡)")
            
            if provider == "Hugging Face":
                # Hugging Face API èª¿ç”¨
                headers = {"Authorization": f"Bearer {api_key}"}
                data = {"inputs": params.get("prompt", "")}
                
                model_name = params.get("model", "FLUX.1-schnell")
                all_models = merge_models()
                model_info = all_models.get(model_name, {})
                endpoint_path = model_info.get('full_path', f"black-forest-labs/{model_name}")
                
                response = requests.post(
                    f"{base_url}/models/{endpoint_path}",
                    headers=headers,
                    json=data,
                    timeout=60
                )
                
                if response.status_code == 200:
                    # æ¨¡æ“¬ OpenAI éŸ¿æ‡‰æ ¼å¼
                    class MockResponse:
                        def __init__(self, image_data):
                            self.data = [type('obj', (object,), {
                                'url': f"data:image/png;base64,{base64.b64encode(image_data).decode()}"
                            })()]
                    
                    return True, MockResponse(response.content)
                else:
                    raise Exception(f"HTTP {response.status_code}: {response.text}")
            else:
                # OpenAI Compatible API èª¿ç”¨
                response = client.images.generate(**params)
                return True, response
            
        except Exception as e:
            error_msg = str(e)
            if attempt < max_retries - 1:
                should_retry = False
                if any(code in error_msg for code in ["500", "502", "503", "429"]):
                    should_retry = True
                elif "timeout" in error_msg.lower():
                    should_retry = True
                
                if should_retry:
                    delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                    st.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å˜—è©¦å¤±æ•—ï¼Œ{delay:.1f} ç§’å¾Œé‡è©¦...")
                    time.sleep(delay)
                    continue
                else:
                    return False, error_msg
            else:
                return False, error_msg
    
    return False, "æ‰€æœ‰é‡è©¦å‡å¤±æ•—"

def init_session_state():
    """åˆå§‹åŒ–æœƒè©±ç‹€æ…‹"""
    if 'api_config' not in st.session_state:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
    
    if 'generation_history' not in st.session_state:
        st.session_state.generation_history = []
    
    if 'favorite_images' not in st.session_state:
        st.session_state.favorite_images = []
    
    if 'model_test_results' not in st.session_state:
        st.session_state.model_test_results = {}
    
    if 'discovered_models' not in st.session_state:
        st.session_state.discovered_models = {}

def add_to_history(prompt: str, model: str, images: List[str], metadata: Dict):
    """æ·»åŠ ç”Ÿæˆè¨˜éŒ„åˆ°æ­·å²"""
    history_item = {
        "timestamp": datetime.datetime.now(),
        "prompt": prompt,
        "model": model,
        "images": images,
        "metadata": metadata,
        "id": str(uuid.uuid4())
    }
    st.session_state.generation_history.insert(0, history_item)
    
    # é™åˆ¶æ­·å²è¨˜éŒ„æ•¸é‡
    if len(st.session_state.generation_history) > 50:
        st.session_state.generation_history = st.session_state.generation_history[:50]

def display_image_with_actions(image_url: str, image_id: str, history_item: Dict = None):
    """é¡¯ç¤ºåœ–åƒå’Œç›¸é—œæ“ä½œ"""
    try:
        # è™•ç† base64 åœ–åƒ
        if image_url.startswith('data:image'):
            base64_data = image_url.split(',')[1]
            img_data = base64.b64decode(base64_data)
            img = Image.open(BytesIO(img_data))
        else:
            img_response = requests.get(image_url, timeout=10)
            img = Image.open(BytesIO(img_response.content))
            img_data = img_response.content
        
        st.image(img, use_column_width=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            img_buffer = BytesIO()
            img.save(img_buffer, format='PNG')
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰",
                data=img_buffer.getvalue(),
                file_name=f"flux_generated_{image_id}.png",
                mime="image/png",
                key=f"download_{image_id}",
                use_container_width=True
            )
        
        with col2:
            is_favorite = any(fav['id'] == image_id for fav in st.session_state.favorite_images)
            if st.button(
                "â­ å·²æ”¶è—" if is_favorite else "â˜† æ”¶è—",
                key=f"favorite_{image_id}",
                use_container_width=True
            ):
                if is_favorite:
                    st.session_state.favorite_images = [
                        fav for fav in st.session_state.favorite_images if fav['id'] != image_id
                    ]
                    st.success("å·²å–æ¶ˆæ”¶è—")
                else:
                    favorite_item = {
                        "id": image_id,
                        "image_url": image_url,
                        "timestamp": datetime.datetime.now(),
                        "history_item": history_item
                    }
                    st.session_state.favorite_images.append(favorite_item)
                    st.success("å·²åŠ å…¥æ”¶è—")
                rerun_app()
        
        with col3:
            if history_item and st.button(
                "ğŸ”„ é‡æ–°ç”Ÿæˆ",
                key=f"regenerate_{image_id}",
                use_container_width=True
            ):
                st.session_state.regenerate_prompt = history_item['prompt']
                st.session_state.regenerate_model = history_item['model']
                rerun_app()
    
    except Exception as e:
        st.error(f"åœ–åƒé¡¯ç¤ºéŒ¯èª¤: {str(e)}")

def init_api_client():
    """åˆå§‹åŒ– API å®¢æˆ¶ç«¯"""
    if 'api_config' in st.session_state and st.session_state.api_config.get('api_key'):
        config = st.session_state.api_config
        if config['provider'] == "Hugging Face":
            return None
        try:
            return OpenAI(
                api_key=config['api_key'],
                base_url=config['base_url']
            )
        except Exception:
            return None
    return None

def show_api_settings():
    """é¡¯ç¤º API è¨­ç½®ç•Œé¢"""
    st.subheader("ğŸ”‘ API è¨­ç½®")
    
    provider_options = list(API_PROVIDERS.keys())
    current_provider = st.session_state.api_config.get('provider', 'Navy')
    selected_provider = st.selectbox(
        "é¸æ“‡ API æä¾›å•†",
        options=provider_options,
        index=provider_options.index(current_provider) if current_provider in provider_options else 1,
        format_func=lambda x: f"{API_PROVIDERS[x]['icon']} {API_PROVIDERS[x]['name']}"
    )
    
    provider_info = API_PROVIDERS[selected_provider]
    st.info(f"ğŸ“‹ {provider_info['description']}")
    
    current_key = st.session_state.api_config.get('api_key', '')
    masked_key = '*' * 20 + current_key[-8:] if len(current_key) > 8 else ''
    
    api_key_input = st.text_input(
        "API å¯†é‘°",
        value="",
        type="password",
        placeholder=f"è«‹è¼¸å…¥ {provider_info['name']} çš„ API å¯†é‘°...",
        help=f"API å¯†é‘°é€šå¸¸ä»¥ '{provider_info['key_prefix']}' é–‹é ­"
    )
    
    if current_key and not api_key_input:
        st.caption(f"ğŸ” ç•¶å‰å¯†é‘°: {masked_key}")
    
    base_url_input = st.text_input(
        "API ç«¯é» URL",
        value=st.session_state.api_config.get('base_url', provider_info['base_url_default']),
        placeholder=provider_info['base_url_default'],
        help="API æœå‹™çš„åŸºç¤ URL"
    )
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        save_btn = st.button("ğŸ’¾ ä¿å­˜è¨­ç½®", type="primary")
    
    with col2:
        test_btn = st.button("ğŸ§ª æ¸¬è©¦é€£æ¥")
    
    with col3:
        clear_btn = st.button("ğŸ—‘ï¸ æ¸…é™¤è¨­ç½®", type="secondary")
    
    if save_btn:
        if not api_key_input and not current_key:
            st.error("âŒ è«‹è¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            final_api_key = api_key_input if api_key_input else current_key
            st.session_state.api_config = {
                'provider': selected_provider,
                'api_key': final_api_key,
                'base_url': base_url_input,
                'validated': False
            }
            st.success("âœ… API è¨­ç½®å·²ä¿å­˜")
            rerun_app()
    
    if test_btn:
        test_api_key = api_key_input if api_key_input else current_key
        if not test_api_key:
            st.error("âŒ è«‹å…ˆè¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            with st.spinner("æ­£åœ¨æ¸¬è©¦ API é€£æ¥..."):
                is_valid, message = validate_api_key(test_api_key, base_url_input, selected_provider)
                if is_valid:
                    st.success(f"âœ… {message}")
                    st.session_state.api_config['validated'] = True
                else:
                    st.error(f"âŒ {message}")
                    st.session_state.api_config['validated'] = False
    
    if clear_btn:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
        st.success("ğŸ—‘ï¸ API è¨­ç½®å·²æ¸…é™¤")
        rerun_app()

def auto_discover_models():
    """åŸ·è¡Œè‡ªå‹•æ¨¡å‹ç™¼ç¾"""
    if 'api_config' not in st.session_state or not st.session_state.api_config.get('api_key'):
        st.error("âŒ è«‹å…ˆé…ç½® API å¯†é‘°")
        return
    
    config = st.session_state.api_config
    
    with st.spinner("ğŸ” æ­£åœ¨è‡ªå‹•ç™¼ç¾ Flux æ¨¡å‹..."):
        if config['provider'] == "Hugging Face":
            client = None
        else:
            client = OpenAI(
                api_key=config['api_key'],
                base_url=config['base_url']
            )
        
        discovered = auto_discover_flux_models(
            client, config['provider'], config['api_key'], config['base_url']
        )
        
        if 'discovered_models' not in st.session_state:
            st.session_state.discovered_models = {}
        
        new_count = 0
        for model_id, model_info in discovered.items():
            if model_id not in st.session_state.discovered_models:
                new_count += 1
            st.session_state.discovered_models[model_id] = model_info
        
        if new_count > 0:
            st.success(f"âœ… ç™¼ç¾ {new_count} å€‹æ–°çš„ Flux æ¨¡å‹ï¼")
        else:
            st.info("â„¹ï¸ æœªç™¼ç¾æ–°çš„ Flux æ¨¡å‹")
        
        rerun_app()

# åˆå§‹åŒ–
init_session_state()
client = init_api_client()
api_configured = client is not None or (st.session_state.api_config.get('provider') == "Hugging Face" and st.session_state.api_config.get('api_key'))

# å´é‚Šæ¬„
with st.sidebar:
    show_api_settings()
    st.markdown("---")
    
    if api_configured:
        st.success("ğŸŸ¢ API å·²é…ç½®")
        if st.button("ğŸ” ç™¼ç¾æ¨¡å‹", use_container_width=True):
            auto_discover_models()
    else:
        st.error("ğŸ”´ API æœªé…ç½®")

# ä¸»æ¨™é¡Œ
st.title("ğŸ¨ Flux AI åœ–åƒç”Ÿæˆå™¨ Pro - å®Œæ•´ç‰ˆ")

# é é¢å°èˆª
tab1, tab2, tab3 = st.tabs(["ğŸš€ åœ–åƒç”Ÿæˆ", "ğŸ“š æ­·å²è¨˜éŒ„", "â­ æ”¶è—å¤¾"])

# åœ–åƒç”Ÿæˆé é¢
with tab1:
    if not api_configured:
        st.warning("âš ï¸ è«‹å…ˆåœ¨å´é‚Šæ¬„é…ç½® API å¯†é‘°")
        st.info("é…ç½®å®Œæˆå¾Œå³å¯é–‹å§‹ç”Ÿæˆåœ–åƒ")
    else:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ¨ åœ–åƒç”Ÿæˆ")
            
            # ä½¿ç”¨åˆä½µå¾Œçš„æ¨¡å‹åˆ—è¡¨
            all_models = merge_models()
            
            if not all_models:
                st.warning("âš ï¸ å°šæœªç™¼ç¾ä»»ä½•æ¨¡å‹ï¼Œè«‹é»æ“Šå´é‚Šæ¬„çš„ã€Œç™¼ç¾æ¨¡å‹ã€æŒ‰éˆ•")
            else:
                # æ¨¡å‹é¸æ“‡
                model_options = list(all_models.keys())
                if 'selected_model' not in st.session_state:
                    st.session_state.selected_model = model_options[0]
                
                if st.session_state.selected_model not in model_options:
                    st.session_state.selected_model = model_options[0]
                
                selected_model = st.selectbox(
                    "é¸æ“‡æ¨¡å‹:",
                    options=model_options,
                    index=model_options.index(st.session_state.selected_model),
                    format_func=lambda x: f"{all_models[x].get('icon', 'ğŸ¤–')} {all_models[x].get('name', x)}"
                )
                
                st.session_state.selected_model = selected_model
                
                # é¡¯ç¤ºæ¨¡å‹ä¿¡æ¯
                model_info = all_models[selected_model]
                st.info(f"**{model_info.get('name')}**: {model_info.get('description', 'N/A')}")
                
                # æª¢æŸ¥é‡æ–°ç”Ÿæˆç‹€æ…‹
                default_prompt = ""
                if hasattr(st.session_state, 'regenerate_prompt'):
                    default_prompt = st.session_state.regenerate_prompt
                    if hasattr(st.session_state, 'regenerate_model') and st.session_state.regenerate_model in model_options:
                        st.session_state.selected_model = st.session_state.regenerate_model
                        selected_model = st.session_state.selected_model
                    delattr(st.session_state, 'regenerate_prompt')
                    if hasattr(st.session_state, 'regenerate_model'):
                        delattr(st.session_state, 'regenerate_model')
                
                # æç¤ºè©è¼¸å…¥
                prompt = st.text_area(
                    "è¼¸å…¥æç¤ºè©:",
                    value=default_prompt,
                    height=120,
                    placeholder="æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„åœ–åƒï¼Œä¾‹å¦‚ï¼šA majestic dragon flying over ancient mountains during sunset, highly detailed, fantasy art style"
                )
                
                # é«˜ç´šè¨­ç½®
                with st.expander("ğŸ”§ é«˜ç´šè¨­ç½®"):
                    col_size, col_num = st.columns(2)
                    
                    with col_size:
                        size_options = {
                            "1024x1024": "æ­£æ–¹å½¢ (1:1)",
                            "1152x896": "æ©«å‘ (4:3.5)",
                            "896x1152": "ç›´å‘ (3.5:4)",
                            "1344x768": "å¯¬å± (16:9)",
                            "768x1344": "è¶…é«˜ (9:16)"
                        }
                        selected_size = st.selectbox(
                            "åœ–åƒå°ºå¯¸",
                            options=list(size_options.keys()),
                            format_func=lambda x: f"{x} - {size_options[x]}",
                            index=0
                        )
                    
                    with col_num:
                        num_images = st.slider("ç”Ÿæˆæ•¸é‡", 1, 4, 1)
                
                # å¿«é€Ÿæç¤ºè©æ¨¡æ¿
                st.subheader("ğŸ’¡ å¿«é€Ÿæç¤ºè©æ¨¡æ¿")
                
                prompt_categories = {
                    "äººç‰©è‚–åƒ": [
                        "Professional headshot of a businesswoman in modern office",
                        "Portrait of an elderly man with wise eyes and gentle smile",
                        "Young artist with paint-splattered apron in creative studio"
                    ],
                    "è‡ªç„¶é¢¨æ™¯": [
                        "Sunset over snow-capped mountains with alpine lake reflection",
                        "Tropical beach with crystal clear turquoise water and palm trees",
                        "Autumn forest with golden leaves and morning mist"
                    ],
                    "è—è¡“å‰µä½œ": [
                        "Abstract geometric composition with vibrant colors and flowing lines",
                        "Watercolor painting of blooming cherry blossoms in spring",
                        "Digital art of a majestic dragon made of flowing water elements"
                    ],
                    "ç§‘å¹»å¹»æƒ³": [
                        "Futuristic cityscape with flying vehicles and neon-lit skyscrapers",
                        "Space station orbiting a distant planet with nebula background",
                        "Cyberpunk street scene with holographic advertisements and rain"
                    ]
                }
                
                category = st.selectbox("é¸æ“‡é¡åˆ¥", list(prompt_categories.keys()))
                
                cols = st.columns(len(prompt_categories[category]))
                for i, template_prompt in enumerate(prompt_categories[category]):
                    with cols[i]:
                        if st.button(
                            template_prompt[:25] + "...",
                            key=f"template_{category}_{i}",
                            use_container_width=True,
                            help=template_prompt
                        ):
                            st.session_state.quick_prompt = template_prompt
                            rerun_app()
                
                # æ‡‰ç”¨å¿«é€Ÿæç¤ºè©
                if hasattr(st.session_state, 'quick_prompt'):
                    prompt = st.session_state.quick_prompt
                    delattr(st.session_state, 'quick_prompt')
                    rerun_app()
                
                # ç”ŸæˆæŒ‰éˆ•
                generate_ready = prompt.strip() and api_configured
                
                generate_btn = st.button(
                    "ğŸš€ ç”Ÿæˆåœ–åƒ",
                    type="primary",
                    use_container_width=True,
                    disabled=not generate_ready
                )
                
                if not generate_ready:
                    if not prompt.strip():
                        st.warning("âš ï¸ è«‹è¼¸å…¥æç¤ºè©")
                    elif not api_configured:
                        st.error("âŒ è«‹é…ç½® API å¯†é‘°")
                
                # åœ–åƒç”Ÿæˆé‚è¼¯
                if generate_btn and generate_ready:
                    config = st.session_state.api_config
                    
                    with st.spinner(f"ğŸ¨ ä½¿ç”¨ {model_info.get('name', selected_model)} æ­£åœ¨ç”Ÿæˆåœ–åƒ..."):
                        # é¡¯ç¤ºé€²åº¦ä¿¡æ¯
                        progress_info = st.empty()
                        progress_info.info(f"â³ æ¨¡å‹: {model_info.get('name')} | å°ºå¯¸: {selected_size} | æ•¸é‡: {num_images}")
                        
                        generation_params = {
                            "model": selected_model,
                            "prompt": prompt,
                            "n": num_images,
                            "size": selected_size
                        }
                        
                        success, result = generate_images_with_retry(
                            client, config['provider'], config['api_key'], 
                            config['base_url'], **generation_params
                        )
                        
                        progress_info.empty()
                        
                        if success:
                            response = result
                            image_urls = [img.url for img in response.data]
                            
                            metadata = {
                                "size": selected_size,
                                "num_images": num_images,
                                "model_name": model_info.get('name', selected_model),
                                "api_provider": config['provider'],
                                "generation_time": time.time()
                            }
                            
                            add_to_history(prompt, selected_model, image_urls, metadata)
                            st.success(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(response.data)} å¼µåœ–åƒï¼")
                            
                            # é¡¯ç¤ºç”Ÿæˆçš„åœ–åƒ
                            if len(response.data) == 1:
                                # å–®å¼µåœ–åƒï¼Œå…¨å¯¬é¡¯ç¤º
                                st.subheader("ğŸ¨ ç”Ÿæˆçµæœ")
                                image_id = f"{st.session_state.generation_history[0]['id']}_0"
                                display_image_with_actions(
                                    response.data[0].url,
                                    image_id,
                                    st.session_state.generation_history[0]
                                )
                            else:
                                # å¤šå¼µåœ–åƒï¼Œç¶²æ ¼é¡¯ç¤º
                                st.subheader("ğŸ¨ ç”Ÿæˆçµæœ")
                                cols = st.columns(min(num_images, 2))
                                for i, image_data in enumerate(response.data):
                                    with cols[i % len(cols)]:
                                        st.markdown(f"**åœ–åƒ {i+1}**")
                                        image_id = f"{st.session_state.generation_history[0]['id']}_{i}"
                                        display_image_with_actions(
                                            image_data.url,
                                            image_id,
                                            st.session_state.generation_history[0]
                                        )
                        else:
                            st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {result}")
                            
                            # æä¾›éŒ¯èª¤è§£æ±ºå»ºè­°
                            error_suggestions = {
                                "401": "ğŸ” æª¢æŸ¥ API å¯†é‘°æ˜¯å¦æ­£ç¢º",
                                "403": "ğŸš« æª¢æŸ¥ API å¯†é‘°æ¬Šé™",
                                "404": "ğŸ” æª¢æŸ¥æ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢º",
                                "429": "â³ è«‹æ±‚éæ–¼é »ç¹ï¼Œç¨å¾Œå†è©¦",
                                "500": "ğŸ”§ æœå‹™å™¨éŒ¯èª¤ï¼Œè«‹ç¨å¾Œé‡è©¦"
                            }
                            
                            for error_code, suggestion in error_suggestions.items():
                                if error_code in str(result):
                                    st.info(f"ğŸ’¡ å»ºè­°: {suggestion}")
                                    break
        
        with col2:
            st.subheader("â„¹ï¸ ç”Ÿæˆä¿¡æ¯")
            
            all_models = merge_models()
            base_count = len([m for m in all_models.values() if m.get('source') == 'base'])
            discovered_count = len([m for m in all_models.values() if m.get('auto_discovered')])
            
            col_stat1, col_stat2 = st.columns(2)
            with col_stat1:
                st.metric("å¯ç”¨æ¨¡å‹", len(all_models))
            with col_stat2:
                st.metric("ç”Ÿæˆè¨˜éŒ„", len(st.session_state.generation_history))
            
            st.markdown("### ğŸ“‹ ä½¿ç”¨å»ºè­°")
            st.markdown("""
            **æç¤ºè©å„ªåŒ–æŠ€å·§:**
            - ğŸ¯ ä½¿ç”¨å…·é«”æè¿°è€ŒéæŠ½è±¡æ¦‚å¿µ
            - ğŸ¨ åŠ å…¥è—è¡“é¢¨æ ¼é—œéµè©
            - ğŸ“ æŒ‡å®šæ§‹åœ–å’Œè¦–è§’
            - ğŸŒˆ æè¿°è‰²å½©å’Œå…‰ç·šæ•ˆæœ
            
            **Koyeb éƒ¨ç½²ç‰¹è‰²:**
            - ğŸš€ Scale-to-Zero è‡ªå‹•ç¸®æ”¾
            - ğŸŒ å…¨çƒ CDN åŠ é€Ÿ
            - ğŸ“Š å¯¦æ™‚è³‡æºç›£æ§
            - ğŸ”’ å®‰å…¨çš„ API ç®¡ç†
            """)

# æ­·å²è¨˜éŒ„é é¢
with tab2:
    st.subheader("ğŸ“š ç”Ÿæˆæ­·å²")
    
    if st.session_state.generation_history:
        # æœç´¢åŠŸèƒ½
        search_term = st.text_input("ğŸ” æœç´¢æ­·å²è¨˜éŒ„", placeholder="è¼¸å…¥é—œéµè©æœç´¢æç¤ºè©...")
        
        filtered_history = st.session_state.generation_history
        if search_term:
            filtered_history = [
                item for item in st.session_state.generation_history
                if search_term.lower() in item['prompt'].lower()
            ]
        
        st.info(f"é¡¯ç¤º {len(filtered_history)} / {len(st.session_state.generation_history)} æ¢è¨˜éŒ„")
        
        for item in filtered_history:
            with st.expander(
                f"ğŸ¨ {item['prompt'][:60]}{'...' if len(item['prompt']) > 60 else ''} | {item['timestamp'].strftime('%m-%d %H:%M')}"
            ):
                col_info, col_actions = st.columns([3, 1])
                
                with col_info:
                    st.markdown(f"**æç¤ºè©**: {item['prompt']}")
                    all_models = merge_models()
                    model_name = all_models.get(item['model'], {}).get('name', item['model'])
                    st.markdown(f"**æ¨¡å‹**: {model_name}")
                    st.markdown(f"**æ™‚é–“**: {item['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                    
                    if 'metadata' in item:
                        metadata = item['metadata']
                        st.markdown(f"**å°ºå¯¸**: {metadata.get('size', 'N/A')}")
                        st.markdown(f"**æ•¸é‡**: {metadata.get('num_images', 'N/A')}")
                
                with col_actions:
                    if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆ", key=f"regen_{item['id']}"):
                        st.session_state.regenerate_prompt = item['prompt']
                        st.session_state.regenerate_model = item['model']
                        rerun_app()
                
                # é¡¯ç¤ºåœ–åƒ
                if item['images']:
                    cols = st.columns(min(len(item['images']), 3))
                    for i, img_url in enumerate(item['images']):
                        with cols[i % len(cols)]:
                            display_image_with_actions(img_url, f"history_{item['id']}_{i}", item)
    else:
        st.info("ğŸ“­ å°šç„¡ç”Ÿæˆæ­·å²ï¼Œé–‹å§‹ç”Ÿæˆä¸€äº›åœ–åƒå§ï¼")

# æ”¶è—å¤¾é é¢
with tab3:
    st.subheader("â­ æˆ‘çš„æ”¶è—")
    
    if st.session_state.favorite_images:
        # æ‰¹é‡æ“ä½œ
        col_batch1, col_batch2 = st.columns(2)
        with col_batch1:
            if st.button("ğŸ“¥ æ‰¹é‡ä¸‹è¼‰", use_container_width=True):
                st.info("ğŸš§ æ‰¹é‡ä¸‹è¼‰åŠŸèƒ½é–‹ç™¼ä¸­")
        with col_batch2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ”¶è—", use_container_width=True):
                if st.checkbox("ç¢ºèªæ¸…ç©ºæ‰€æœ‰æ”¶è—", key="confirm_clear_favorites"):
                    st.session_state.favorite_images = []
                    st.success("å·²æ¸…ç©ºæ‰€æœ‰æ”¶è—")
                    rerun_app()
        
        # é¡¯ç¤ºæ”¶è—çš„åœ–åƒ
        cols = st.columns(3)
        for i, fav in enumerate(st.session_state.favorite_images):
            with cols[i % 3]:
                display_image_with_actions(fav['image_url'], fav['id'], fav.get('history_item'))
                
                # é¡¯ç¤ºæ”¶è—ä¿¡æ¯
                if fav.get('history_item'):
                    st.caption(f"ğŸ’­ {fav['history_item']['prompt'][:40]}...")
                st.caption(f"â­ æ”¶è—æ–¼: {fav['timestamp'].strftime('%m-%d %H:%M')}")
    else:
        st.info("â­ å°šç„¡æ”¶è—åœ–åƒï¼Œåœ¨ç”Ÿæˆçš„åœ–åƒä¸Šé»æ“Šæ”¶è—æŒ‰éˆ•ä¾†æ·»åŠ æ”¶è—ï¼")

# é è…³
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; margin-top: 2rem;">
    ğŸš€ <strong>éƒ¨ç½²åœ¨ Koyeb</strong> | 
    ğŸ¨ <strong>Powered by Flux AI</strong> | 
    âš¡ <strong>è‡ªå‹•ç¸®æ”¾</strong> | 
    ğŸŒ <strong>å…¨çƒåŠ é€Ÿ</strong>
    <br><br>
    <small>å®Œæ•´çš„åœ–åƒç”Ÿæˆã€æ¨¡å‹ç™¼ç¾ã€æ­·å²ç®¡ç†åŠŸèƒ½</small>
</div>
""", unsafe_allow_html=True)
